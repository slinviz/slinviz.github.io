<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lin on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/</link>
    <description>Recent content in Lin on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cache与Checkpoint</title>
      <link>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</link>
      <pubDate>Sat, 27 Feb 2021 19:34:05 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</guid>
      <description>1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。
1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：
   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：</description>
    </item>
    
    <item>
      <title>文件管理</title>
      <link>https://slinviz.github.io/pbasic/os/os-fs/</link>
      <pubDate>Sat, 27 Feb 2021 12:14:50 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/os/os-fs/</guid>
      <description>1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.</description>
    </item>
    
    <item>
      <title>TCP协议</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcp/</link>
      <pubDate>Sat, 27 Feb 2021 10:35:35 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcp/</guid>
      <description>1. TCP数据包 </description>
    </item>
    
    <item>
      <title>TCP与UDP协议的区别</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</link>
      <pubDate>Sat, 27 Feb 2021 10:21:24 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</guid>
      <description>1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。
2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。
对比 </description>
    </item>
    
    <item>
      <title>OSI与TCP/IP架构</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-arch/</link>
      <pubDate>Sat, 27 Feb 2021 09:05:55 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-arch/</guid>
      <description>1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。
  物理层
 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。
   数据链路层
 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。
   网络层
 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。
   传输层
 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。
   会话层
 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。
   表示层
 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。
   应用层
 主要是一些终端应用。如FTP、WEB等。
   网络模型与物理设备
实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。
  网络接口层
 指出主机必须通过某种协议与网络相连。</description>
    </item>
    
    <item>
      <title>Mermaidtest</title>
      <link>https://slinviz.github.io/papers/mermaidtest/</link>
      <pubDate>Fri, 26 Feb 2021 22:50:38 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/mermaidtest/</guid>
      <description>Test Mermaid Pie   document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers &#34;Dogs&#34; : 386 &#34;Cats&#34; : 85 &#34;Rats&#34; : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?</description>
    </item>
    
    <item>
      <title>TPDS</title>
      <link>https://slinviz.github.io/papers/TPDS/</link>
      <pubDate>Fri, 26 Feb 2021 19:42:14 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TPDS/</guid>
      <description>背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。
目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。
方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：
 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值
2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。
3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。
4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。
评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器
LeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://slinviz.github.io/bigdata/hadoop/overview/</link>
      <pubDate>Sat, 13 Feb 2021 20:38:25 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/overview/</guid>
      <description>1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。
 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景
 特别适合写一次，读多次的场景
大规模数据 流数据（写一次，读多次）
商用硬件
 Hadoop不适用的场景
 低延时数据访问 大量小文件 频繁修改文件
  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。
简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。
HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。
进程：NameNode, SecondaryNameNode, DataNode
数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。
读取策略：尽量读取距离最近的副本。
安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。
HDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2
通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。
健壮性
 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。
集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。
 NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等</description>
    </item>
    
    <item>
      <title>数据库与SQL</title>
      <link>https://slinviz.github.io/database/dbsql/</link>
      <pubDate>Wed, 03 Feb 2021 21:43:48 +0800</pubDate>
      
      <guid>https://slinviz.github.io/database/dbsql/</guid>
      <description>1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；
数据库管理系统DBMS：用来管理数据库的计算机软件；
SQL：Structured Query Language 即结构化查询语言;
使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。
DBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。
SQL  SQL可分为DDL、DML和DCL。
 DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  </description>
    </item>
    
    <item>
      <title>Mvn Repo Modify</title>
      <link>https://slinviz.github.io/plang/scala/mvn-repo/</link>
      <pubDate>Fri, 08 Jan 2021 14:37:20 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/scala/mvn-repo/</guid>
      <description>可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.
${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.
&amp;lt;!-- path to the local repository default ${user.home}/.m2/repository --&amp;gt; &amp;lt;localRepository&amp;gt;/path/to/local/repo&amp;lt;/localRepository&amp;gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.
&amp;lt;!-- &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;mirrorId&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;repositoryId&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;Human readable name for this mirror&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://my.repository.com/repo/path&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;mirror&amp;gt; .... &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; --&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;alimaven&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;central&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;aliyun maven&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; </description>
    </item>
    
  </channel>
</rss>