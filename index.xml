<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lin on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/</link>
    <description>Recent content in Lin on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Object 类</title>
      <link>https://slinviz.github.io/plang/java/basic/object/</link>
      <pubDate>Mon, 01 Mar 2021 14:52:19 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/basic/object/</guid>
      <description>java.lang.Object 是Java类的最顶层，也是Java中唯一一个没有父类的类。其他的类要么显式的声明继承自其他类，要么隐式的继承Object类。  Java 中Object类不做为接口的父类。因为Java中的接口不能从java中的类继承，至少不能直接继承。 明确指明某个类继承自Object，即class SomeClass extends Object后，该类不能再继承其他类，Java仅支持单继承。   Object类中定义的方法如下：
  document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object{ +equales() boolean +hashCode() int +toString() String +getClass() Class~~ #finalize() void #clone() Object +notify() void +notifyAll() void +wait() void +wait(long timeout) void +wait(long timeout, int nanos) void }  equals与==  ==：作用是判断两个对象的地址是否相等，即这两个对象是否是同一个对象。对于基本类型，其比较的是值，对于对象比较的是地址。 equales方法：判断两个对象是否相等，有两种情况：  类没有覆写该方法，调用该方法时等价于使用== 类覆写了equales()方法，一般覆写后是判断两个对象的内容是否相等。    覆写equales()方法时一定要覆写hashCode()方法
hashCode() 方法返回该对象的哈希码给调用者。</description>
    </item>
    
    <item>
      <title>Java Error和Exception</title>
      <link>https://slinviz.github.io/plang/java/basic/exceptions/</link>
      <pubDate>Mon, 01 Mar 2021 13:30:04 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/basic/exceptions/</guid>
      <description>Java中如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。此时JVM会抛出一个封装了错误信息的对象，方法会立刻退出同时不返回任何值。
Java 中的“异常”可以分为Error（错误）和Exception（异常）两大类，它们都是Throwable的子类。其中：
 Error： Java运行时系统的内部错误或资源耗尽。当出现这样的错误，JVM会告知用户出现错误，并终止程序。 Exception： 异常可分为编译阶段的CheckedException和程序正常运行过程中抛出的RuntimeException两大类。  CheckedException：继承自java.lang.Exception类，一般是外部错误，发生在编译阶段，Java编译期会强制程序去捕获此类异常（要求使用try{}catch{}finally{}显式的去包裹可能出现这类异常的代码段）。 RuntimeException：运行时异常，如空指针，数组索引越界等，还有CheckedException，出现这类异常一定是程序错误。      document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object class Throwable class Error class Exception class RuntimeException Object 异常处理  throw 主动从方法中抛出异常交给上层调用处理。 throws 声明函数可能出现的异常。      throw throws     使用位置 方法内部 方法声明后   功能 抛出具体的异常对象，执行到throw方法调用接收，返回异常给上层调用 声明可能出现的异常，让调用者知道该方法可能出现的异常   是否处理异常 不处理，抛出异常给上层调用 不处理，指明可能出现的异常    使用对比：</description>
    </item>
    
    <item>
      <title>Leetcode刷题记录</title>
      <link>https://slinviz.github.io/pbasic/dsalg/leetcode/</link>
      <pubDate>Sat, 27 Feb 2021 22:55:43 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/dsalg/leetcode/</guid>
      <description>1. 滑动窗口 解决有序数列连续和问题。限定窗口滑动方向，例如左右窗口只能向右滑动，区间设置为左闭右开。那么左窗口滑动缩小区间，右窗口滑动扩大窗口。</description>
    </item>
    
    <item>
      <title>Cache与Checkpoint</title>
      <link>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</link>
      <pubDate>Sat, 27 Feb 2021 19:34:05 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</guid>
      <description>1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。
1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：
   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：</description>
    </item>
    
    <item>
      <title>文件管理</title>
      <link>https://slinviz.github.io/pbasic/os/os-fs/</link>
      <pubDate>Sat, 27 Feb 2021 12:14:50 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/os/os-fs/</guid>
      <description>1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.</description>
    </item>
    
    <item>
      <title>TCP协议</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcp/</link>
      <pubDate>Sat, 27 Feb 2021 10:35:35 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcp/</guid>
      <description>1. TCP 数据包 2. TCP 三次握手 3. TCP 四次挥手 4. TCP 如何保证传输可靠  4.1 ARQ 协议 4.2 滑动窗口和流量控制 4.3 拥塞控制  4.3.1 慢开始 4.3.2 拥塞控制 4.3.3 快重传和快恢复       1. TCP 数据包 TCP数据包主要由报头和数据（可选）组成，其报头长度在20B-60B，具体结构如下图：
2. TCP 三次握手 TCP连接需要进行三次握手的目的是建立可靠的通信通道，需要确认发送方和接收方的收发都是正常的。
 第一次握手：client什么都不能确认；server确认自己接收正常，client发送正常 第二次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常，client发送正常 第三次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常和发送正常，client接收正常和发送正常  3. TCP 四次挥手 TCP断开连接需要进行四次挥手，原因在于TCP建立的连接是双向通道，双方之间既可以向对方发送数据也可以接收对方发送的数据，相当于是建立了两条单向通道，当一方发起断开连接的请求并受到对方的确认后会进入半关闭状态，需要等到另一方发送完数据并发出释放连接的请求，释放请求确认后才能完全关闭TCP连接。
4. TCP 如何保证传输可靠  应用数据被分割成TCP认为最适合传输的数据块 TCP对发送的每一个数据包进行编号，接收方对收到的数据包进行排序，然后就有序的数据包交给应用层处理 校验和：TCP计算报头和数据的校验和，并将其放在报头中一起发送，接收方对收到的数据进行校验，如果校验出错则会丢弃这个数据包并不确认收到这个数据包 TCP接收端会丢弃重复的数据 流量控制：TCP使用大小可变的滑动窗口协议来进行流量控制，每一方都有固定大小的缓存空间，双方只接受缓存空间内容纳的数据。 拥塞控制机制：当网络拥塞时，减少数据发送 ARQ协议：每发送一个分组就停止发送，等待对方发送确认。收到确认后再发送下一个分组。 超时重传：TCP每个发送一个段就启动一个计时器，当超过时间未收到确认就重传该段。  4.1 ARQ 协议 自动重传请求通过确认和超时两个机制在不可靠服务的基础上实现可靠的信息传输。
  停止等待ARQ协议</description>
    </item>
    
    <item>
      <title>TCP与UDP协议的区别</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</link>
      <pubDate>Sat, 27 Feb 2021 10:21:24 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</guid>
      <description>1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。
2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。
对比 </description>
    </item>
    
    <item>
      <title>OSI与TCP/IP架构</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-arch/</link>
      <pubDate>Sat, 27 Feb 2021 09:05:55 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-arch/</guid>
      <description>1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。
  物理层
 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。
   数据链路层
 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。
   网络层
 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。
   传输层
 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。
   会话层
 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。
   表示层
 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。
   应用层
 主要是一些终端应用。如FTP、WEB等。
   网络模型与物理设备
实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。
  网络接口层
 指出主机必须通过某种协议与网络相连。</description>
    </item>
    
    <item>
      <title>Mermaidtest</title>
      <link>https://slinviz.github.io/papers/mermaidtest/</link>
      <pubDate>Fri, 26 Feb 2021 22:50:38 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/mermaidtest/</guid>
      <description>Test Mermaid Pie   document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers &#34;Dogs&#34; : 386 &#34;Cats&#34; : 85 &#34;Rats&#34; : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?</description>
    </item>
    
    <item>
      <title>TPDS</title>
      <link>https://slinviz.github.io/papers/TPDS/</link>
      <pubDate>Fri, 26 Feb 2021 19:42:14 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TPDS/</guid>
      <description>背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。
目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。
方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：
 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值
2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。
3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。
4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。
评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器
LeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://slinviz.github.io/bigdata/hadoop/overview/</link>
      <pubDate>Sat, 13 Feb 2021 20:38:25 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/overview/</guid>
      <description>1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。
 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景
 特别适合写一次，读多次的场景
大规模数据 流数据（写一次，读多次）
商用硬件
 Hadoop不适用的场景
 低延时数据访问 大量小文件 频繁修改文件
  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。
简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。
HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。
进程：NameNode, SecondaryNameNode, DataNode
数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。
读取策略：尽量读取距离最近的副本。
安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。
HDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2
通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。
健壮性
 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。
集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。
 NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等</description>
    </item>
    
    <item>
      <title>数据库与SQL</title>
      <link>https://slinviz.github.io/database/dbsql/</link>
      <pubDate>Wed, 03 Feb 2021 21:43:48 +0800</pubDate>
      
      <guid>https://slinviz.github.io/database/dbsql/</guid>
      <description>1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；
数据库管理系统DBMS：用来管理数据库的计算机软件；
SQL：Structured Query Language 即结构化查询语言;
使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。
DBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。
SQL  SQL可分为DDL、DML和DCL。
 DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  </description>
    </item>
    
    <item>
      <title>Mvn Repo Modify</title>
      <link>https://slinviz.github.io/plang/scala/mvn-repo/</link>
      <pubDate>Fri, 08 Jan 2021 14:37:20 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/scala/mvn-repo/</guid>
      <description>可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.
${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.
&amp;lt;!-- path to the local repository default ${user.home}/.m2/repository --&amp;gt; &amp;lt;localRepository&amp;gt;/path/to/local/repo&amp;lt;/localRepository&amp;gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.
&amp;lt;!-- &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;mirrorId&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;repositoryId&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;Human readable name for this mirror&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://my.repository.com/repo/path&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;mirror&amp;gt; .... &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; --&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;alimaven&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;central&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;aliyun maven&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; </description>
    </item>
    
  </channel>
</rss>