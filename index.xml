<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lin on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/</link>
    <description>Recent content in Lin on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>定义比较</title>
      <link>https://slinviz.github.io/plang/java/basic/compare/</link>
      <pubDate>Sat, 06 Mar 2021 15:15:47 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/basic/compare/</guid>
      <description>Comparable vs. Comparator     java.lang.Comparable java.util.Comparator     类型 接口 接口   使用时机 定义类时实现 类定义完成后，重新定义比较器   功能 实现类的 自然序 可定义多种比较方式   覆盖方法 public int compareTo(T o) public int compare(T o1, T o2)   实现次数 只能实现一次（类定义时） 可定义多个比较器类    Comparable 接口 java.lang.Comparable 在类定义的时候实现，可用于设定对象的默认排序（自然序），需要覆写public int compareTo(T o)方法。
import java.lang.Comparable; import java.util.Comparator; import java.util.List; import java.util.ArrayList; import java.util.Collections; public class Person implements Comparable&amp;lt;Person&amp;gt; { String name; int age; public Person(String name, int age){ super(); this.</description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>https://slinviz.github.io/plang/java/jvm/</link>
      <pubDate>Thu, 04 Mar 2021 14:23:35 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/jvm/</guid>
      <description>类加载机制 类加载过程  1. 加载 2. 验证 3. 准备 4. 解析 5. 初始化   类加载器  1. 类与类加载器 2. 双亲委派模型  双亲委派模型的工作过程   3. 破坏双亲委派模型   Reference   类加载机制  虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。
 类的生命周期包括：加载、验证、准备、解析、初始化、使用和卸载，其中验证、准备、和解析统称为连接。
加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的。解析阶段可以在初始化阶段之后（java运行时绑定），阶段间通常是相互交叉地混合式进行的。  必须立即对类进行初始化的5中情况：
 遇到new, getstatic, putstatic, invokestatic 这个4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。即使用new关键字实例化对象、读取或者设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。 使用java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 初始化一个类的时候，如果发现其父类还没进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户指定要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 使用 JDK 1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。   对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。如下代码只会输出：SuperClass init!  class SuperClass { static { System.</description>
    </item>
    
    <item>
      <title>[转载]Apache Spark 内存管理详解</title>
      <link>https://slinviz.github.io/bigdata/spark/storage/</link>
      <pubDate>Thu, 04 Mar 2021 11:50:08 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/storage/</guid>
      <description>本文是对原文Apache Spark 内存管理详解的转载并做了部分排版修改，后续会加入一些自己的理解和补充。   0. 序言 1. 堆内和堆外内存规划  1.1 堆内内存 1.2 堆外内存 1.3 内存管理接口   2. 内存空间分配  2.1 静态内存管理 2.2 统一内存管理   3. 存储内存管理  3.1 RDD 的持久化机制 3.2 RDD 缓存的过程 3.3 淘汰和落盘   4. 执行内存管理  4.1 多任务间内存分配 4.2 Shuffle 的内存占用   结束语 参考资源 Reference   0. 序言 Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文旨在梳理出 Spark 内存管理的脉络，抛砖引玉，引出读者对这个话题的深入探讨。本文中阐述的原理基于 Spark 2.1 版本，阅读本文需要读者有一定的 Spark 和 Java 基础，了解 RDD、Shuffle、JVM 等相关概念。</description>
    </item>
    
    <item>
      <title>HDFS</title>
      <link>https://slinviz.github.io/bigdata/hadoop/hdfs/</link>
      <pubDate>Wed, 03 Mar 2021 14:08:44 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/hdfs/</guid>
      <description>HDFS 架构  1. NameNode  1.1 fsimage 和 editlog   2. SecondaryNameNode 3. DataNode 4. 数据流水线复制 5. 安全模式 6. 文件存储空间回收 7. HDFS 的健壮性   NameNode 高并发保障技术  1. 双缓存（Double-Buffer）机制 2. 分段加锁机制  2.1 加锁 2.2 多线程并发 2.3 批量数据刷磁盘和网络优化     部署 Hadoop 集群  0. 安装和配置环境变量 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 2. 启动集群 2.1 格式化 NameNode 2.2 启动 Hadoop 集群 3. 创建目录并存储文件   Reference   HDFS 架构 HDFS 是 Hadoop 的分布式文件系统，非常适合存储大文件和写入一次读取多次的文件，具有高吞吐量、高容错等特性，支持扩展到上千台商业服务器上。目前许多大数据处理平台（例如 Spark，Hive，Hbase等）都将 HDFS 作为底层的文件存储。</description>
    </item>
    
    <item>
      <title>Scala 基本数据类型和流程控制</title>
      <link>https://slinviz.github.io/plang/scala/basic/</link>
      <pubDate>Wed, 03 Mar 2021 09:11:44 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/scala/basic/</guid>
      <description>Scala 基本数据类型   Scala 基本数据类型 Byte, Short, Int, Long, Float, Double, Char, Boolean, String, RichInt, RichDouble, StringOps
格式化字符串
printf(&amp;#34;Hello, %s! You are %d years old.%n&amp;#34;, name, age) print(f&amp;#34;Hello, ${name}! In six months, you&amp;#39;ll be ${age+0.5}%7.2f years old.%n&amp;#34;) print(s&amp;#34;$$$price&amp;#34;) println(raw&amp;#34;\n is a new line&amp;#34;) ; // \n is a new line  在 Scala 中，变量或函数的类型总是写在变量或函数名称的后面。 在 Scala 中， 仅当同一行代码中存在多条语句时才需要用分号;隔开。 Scala 中的操作符实际上是方法，Java中不能对操作符进行重载，但Scala允许定义操作符。   Scala中的类通常都有一个伴生对象，里面定义的方法类似于java中的静态方法。</description>
    </item>
    
    <item>
      <title>YARN</title>
      <link>https://slinviz.github.io/bigdata/hadoop/yarn/</link>
      <pubDate>Tue, 02 Mar 2021 20:58:50 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/yarn/</guid>
      <description>集群资源管理者-YARN YARN（Yet Another Resource Negotiator）是 Hadoop 2.0 引入的集群资源管理系统。用户可以将多种服务框架部署在YARN上，由YARN进行统一的管理和资源分配。
YARN 框架 ResourceManager-RM RM 是整个集群资源的主要管理者和协调者，RM 负责对用户提交的应用程序分配资源。资源分配根据应用程序优先级，队列容量，ACLs，数据位置等信息做出决策，然后以共享的、安全的、多租户的方式制定策略，调度集群资源。
NodeManager-NM NM 负责管理当前节点的管理者，负责节点资源监视和节点健康跟踪，它还负责当前节点内所有容器的生命周期管理。具体如下：
 NM 启动时向 RM 注册并定时发送心跳信息，等待 RM 的命令； 维护Container生命周期，监控container的资源使用情况； 管理任务运行时的相关依赖，根据ApplicationMaster的需要，在启动container之前将程序及其依赖拷贝到本地。  ApplicationMaster-AM 在用户提交一个Application时，YARN 会启动一个轻量级进程ApplicationMaster， 负责协调来自RM的资源，并通过NM监视容器内资源的使用情况，同时负责任务的监控与容错。具体如下：
 根据Application运行状态动态决定资源需求； 向RM申请资源并监控申请的资源的使用情况； 跟踪任务进度和状态，报告资源使用情况和应用的进度信息； 复杂任务的容错。  Container Container是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、网络、磁盘等。当AM向RM申请资源时，RM为AM返回的资源使用Container表示的。YARN会为每个任务分配一个 Container，该任务只能使用该Container中描述的资源。AM可以在Container中运行任何类型的任务。如MapReduce中的Map Task和Reduce Task。
YARN 工作原理 概述  Client通过 RM 向YARN提交Application； RM 选择一个 NM， 然后启动一个 Container 运行 ApplicationMaster； ApplicationMaster 根据实际需求向 RM 申请更多的 Container 资源，（如果任务很小，AM 会选择在自己的 JVM 中运行任务）； AM 根据获取到的 Container 资源执行分布式任务计算。  详述 </description>
    </item>
    
    <item>
      <title>操作系统</title>
      <link>https://slinviz.github.io/pbasic/os/os/</link>
      <pubDate>Tue, 02 Mar 2021 08:44:01 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/os/os/</guid>
      <description>1. 什么是操作系统？  操作系统是管理计算机硬件和软件资源的程序，是计算机的基石。 OS本质上是配置在计算机硬件上的第一层软件，用于管理计算机硬件和软件资源。 OS做为用户和计算机硬件系统之间的接口，屏蔽了硬件层的复杂性。操作系统就像是硬件使用的负责人，统筹着各种相关事项。 操作系统内核是操作系统的核心部分，它负责系统的内存管理，硬件设备管理，文件系统管理和应用程序管理。内核是连接应用程序和硬件之间的桥梁，决定着系统的性能和稳定性。  2. 什么是系统调用？ 根据进程访问资源的特点，可以将进程在系统上的运行分为两个级别：
 用户态：用户态运行的进程可以直接读取用户程序的数据 系统态：系统态运行的进程几乎可以访问计算机的任何资源，不受限制  一般情况下用户程序都是运行在用户态，当需要调用操作系统的系统态级别的子功能的时候就需要系统调用了。也就是说用户程序中凡是与系统态级别的资源的操作，如文件管理、进程控制、内存管理等，就需要通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。
系统调用按功能大致可分为：
 设备管理：完成设备的请求或释放，以及设备的启动等功能。 文件管理：完成文件读、写、创建和删除等功能。 内存管理：完成内存的分配，回收，虚拟地址转换等功能。 进程控制：完成进程的创建，撤销，阻塞以及唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。  </description>
    </item>
    
    <item>
      <title>进程和线程</title>
      <link>https://slinviz.github.io/pbasic/os/os-process/</link>
      <pubDate>Tue, 02 Mar 2021 08:36:34 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/os/os-process/</guid>
      <description>1. 基本概念 2. 进程和线程的区别 3. 进程的状态 4. 进程间通信方式  4.1 管道/匿名管道 4.2 有名管道 4.3 信号 4.4 消息队列 4.5 信号量 4.6 共享内存 4.7 套接字   5. 线程间同步 6. 进程调度算法  6.1 先到先服务（FCFS）调度算法 6.2 短作业优先（SJF）调度算法 6.3 时间片轮转（RR）调度算法 6.4 多级反馈队列调度算法 6.5 优先级调度算法   Reference:   1. 基本概念   进程（Process）
进程是一个动态的概念，通常指的是进程实体 = PCB + 程序段 + 数据段。PCB主要包括程序计数器，程序上下文，程序资源（文件、信号等）等。
  线程（Thread）
线程实际上是进程内部的一条执行序列（执行流），执行序列是指一组有序指令加数据的集合，执行序列是以函数为单位的。线程是一种轻量级的进程。线程一定是在进程内部进行活动的，并且每一个线程都拥有一个独立的计数器、进程栈和一组进程寄存器。强调一点，进程调度的对象是线程，而不是进程。
  协程（Coroutine） 协程是一种用户态的轻量级线程，调度由用户控制，拥有自己独立的寄存器上下文和栈。协程的切换效率比线程还要高，协程和线程的区别包括：
   线程是由CPU调度，而协程是由用户调度 线程存在安全问题，协程比线程较安全 线程使用同步机制，协程使用异步机制  管程（Monitor）</description>
    </item>
    
    <item>
      <title>Object 类</title>
      <link>https://slinviz.github.io/plang/java/basic/object/</link>
      <pubDate>Mon, 01 Mar 2021 14:52:19 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/basic/object/</guid>
      <description>java.lang.Object 是Java类的最顶层，也是Java中唯一一个没有父类的类。其他的类要么显式的声明继承自其他类，要么隐式的继承Object类。  Java 中Object类不做为接口的父类。因为Java中的接口不能从java中的类继承，至少不能直接继承。 明确指明某个类继承自Object，即class SomeClass extends Object后，该类不能再继承其他类，Java仅支持单继承。   Object类中定义的方法如下：
  document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object{ +equales() boolean +hashCode() int +toString() String +getClass() Class~~ #finalize() void #clone() Object +notify() void +notifyAll() void +wait() void +wait(long timeout) void +wait(long timeout, int nanos) void }  equals与==  ==：作用是判断两个对象的地址是否相等，即这两个对象是否是同一个对象。对于基本类型，其比较的是值，对于对象比较的是地址。 equales方法：判断两个对象是否相等，有两种情况：  类没有覆写该方法，调用该方法时等价于使用== 类覆写了equales()方法，一般覆写后是判断两个对象的内容是否相等。    覆写equales()方法时一定要覆写hashCode()方法
hashCode() 方法返回该对象的哈希码给调用者。</description>
    </item>
    
    <item>
      <title>Java Error和Exception</title>
      <link>https://slinviz.github.io/plang/java/basic/exceptions/</link>
      <pubDate>Mon, 01 Mar 2021 13:30:04 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/java/basic/exceptions/</guid>
      <description>Java中如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。此时JVM会抛出一个封装了错误信息的对象，方法会立刻退出同时不返回任何值。
Java 中的“异常”可以分为Error（错误）和Exception（异常）两大类，它们都是Throwable的子类。其中：
 Error： Java运行时系统的内部错误或资源耗尽。当出现这样的错误，JVM会告知用户出现错误，并终止程序。 Exception： 异常可分为编译阶段的CheckedException和程序正常运行过程中抛出的RuntimeException两大类。  CheckedException：继承自java.lang.Exception类，一般是外部错误，发生在编译阶段，Java编译期会强制程序去捕获此类异常（要求使用try{}catch{}finally{}显式的去包裹可能出现这类异常的代码段）。 RuntimeException：运行时异常，如空指针，数组索引越界等，还有CheckedException，出现这类异常一定是程序错误。      document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object class Throwable class Error class Exception class RuntimeException Object 异常处理  throw 主动从方法中抛出异常交给上层调用处理。 throws 声明函数可能出现的异常。      throw throws     使用位置 方法内部 方法声明后   功能 抛出具体的异常对象，执行到throw方法调用接收，返回异常给上层调用 声明可能出现的异常，让调用者知道该方法可能出现的异常   是否处理异常 不处理，抛出异常给上层调用 不处理，指明可能出现的异常    使用对比：</description>
    </item>
    
    <item>
      <title>Leetcode刷题记录</title>
      <link>https://slinviz.github.io/pbasic/dsalg/leetcode/</link>
      <pubDate>Sat, 27 Feb 2021 22:55:43 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/dsalg/leetcode/</guid>
      <description>1. 滑动窗口 解决有序数列连续和问题。限定窗口滑动方向，例如左右窗口只能向右滑动，区间设置为左闭右开。那么左窗口滑动缩小区间，右窗口滑动扩大窗口。</description>
    </item>
    
    <item>
      <title>Cache与Checkpoint</title>
      <link>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</link>
      <pubDate>Sat, 27 Feb 2021 19:34:05 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</guid>
      <description>1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。
1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：
   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：</description>
    </item>
    
    <item>
      <title>文件管理</title>
      <link>https://slinviz.github.io/pbasic/os/os-fs/</link>
      <pubDate>Sat, 27 Feb 2021 12:14:50 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/os/os-fs/</guid>
      <description>1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.</description>
    </item>
    
    <item>
      <title>TCP协议</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcp/</link>
      <pubDate>Sat, 27 Feb 2021 10:35:35 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcp/</guid>
      <description>1. TCP 数据包 2. TCP 三次握手 3. TCP 四次挥手 4. TCP 如何保证传输可靠  4.1 ARQ 协议 4.2 滑动窗口和流量控制 4.3 拥塞控制  4.3.1 慢开始 4.3.2 拥塞控制 4.3.3 快重传和快恢复       1. TCP 数据包 TCP数据包主要由报头和数据（可选）组成，其报头长度在20B-60B，具体结构如下图：
2. TCP 三次握手 TCP连接需要进行三次握手的目的是建立可靠的通信通道，需要确认发送方和接收方的收发都是正常的。
 第一次握手：client什么都不能确认；server确认自己接收正常，client发送正常 第二次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常，client发送正常 第三次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常和发送正常，client接收正常和发送正常  3. TCP 四次挥手 TCP断开连接需要进行四次挥手，原因在于TCP建立的连接是双向通道，双方之间既可以向对方发送数据也可以接收对方发送的数据，相当于是建立了两条单向通道，当一方发起断开连接的请求并受到对方的确认后会进入半关闭状态，需要等到另一方发送完数据并发出释放连接的请求，释放请求确认后才能完全关闭TCP连接。
4. TCP 如何保证传输可靠  应用数据被分割成TCP认为最适合传输的数据块 TCP对发送的每一个数据包进行编号，接收方对收到的数据包进行排序，然后就有序的数据包交给应用层处理 校验和：TCP计算报头和数据的校验和，并将其放在报头中一起发送，接收方对收到的数据进行校验，如果校验出错则会丢弃这个数据包并不确认收到这个数据包 TCP接收端会丢弃重复的数据 流量控制：TCP使用大小可变的滑动窗口协议来进行流量控制，每一方都有固定大小的缓存空间，双方只接受缓存空间内容纳的数据。 拥塞控制机制：当网络拥塞时，减少数据发送 ARQ协议：每发送一个分组就停止发送，等待对方发送确认。收到确认后再发送下一个分组。 超时重传：TCP每个发送一个段就启动一个计时器，当超过时间未收到确认就重传该段。  4.1 ARQ 协议 自动重传请求通过确认和超时两个机制在不可靠服务的基础上实现可靠的信息传输。
  停止等待ARQ协议</description>
    </item>
    
    <item>
      <title>TCP与UDP协议的区别</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</link>
      <pubDate>Sat, 27 Feb 2021 10:21:24 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-tcpudp/</guid>
      <description>1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。
2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。
对比 </description>
    </item>
    
    <item>
      <title>OSI与TCP/IP架构</title>
      <link>https://slinviz.github.io/pbasic/cn/cn-arch/</link>
      <pubDate>Sat, 27 Feb 2021 09:05:55 +0800</pubDate>
      
      <guid>https://slinviz.github.io/pbasic/cn/cn-arch/</guid>
      <description>1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。
  物理层
 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。
   数据链路层
 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。
   网络层
 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。
   传输层
 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。
   会话层
 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。
   表示层
 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。
   应用层
 主要是一些终端应用。如FTP、WEB等。
   网络模型与物理设备
实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。
  网络接口层
 指出主机必须通过某种协议与网络相连。</description>
    </item>
    
    <item>
      <title>Mermaidtest</title>
      <link>https://slinviz.github.io/papers/mermaidtest/</link>
      <pubDate>Fri, 26 Feb 2021 22:50:38 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/mermaidtest/</guid>
      <description>Test Mermaid Pie   document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers &#34;Dogs&#34; : 386 &#34;Cats&#34; : 85 &#34;Rats&#34; : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?</description>
    </item>
    
    <item>
      <title>TPDS</title>
      <link>https://slinviz.github.io/papers/TPDS/</link>
      <pubDate>Fri, 26 Feb 2021 19:42:14 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TPDS/</guid>
      <description>背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。
目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。
方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：
 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值
2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。
3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。
4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。
评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器
LeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://slinviz.github.io/bigdata/hadoop/overview/</link>
      <pubDate>Sat, 13 Feb 2021 20:38:25 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/overview/</guid>
      <description>1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。
 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景
 特别适合写一次，读多次的场景
大规模数据 流数据（写一次，读多次）
商用硬件
 Hadoop不适用的场景
 低延时数据访问 大量小文件 频繁修改文件
  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。
简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。
HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。
进程：NameNode, SecondaryNameNode, DataNode
数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。
读取策略：尽量读取距离最近的副本。
安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。
HDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2
通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。
健壮性
 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。
集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。
 NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等</description>
    </item>
    
    <item>
      <title>数据库与SQL</title>
      <link>https://slinviz.github.io/database/dbsql/</link>
      <pubDate>Wed, 03 Feb 2021 21:43:48 +0800</pubDate>
      
      <guid>https://slinviz.github.io/database/dbsql/</guid>
      <description>1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；
数据库管理系统DBMS：用来管理数据库的计算机软件；
SQL：Structured Query Language 即结构化查询语言;
使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。
DBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。
SQL  SQL可分为DDL、DML和DCL。
 DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  </description>
    </item>
    
    <item>
      <title>Mvn Repo Modify</title>
      <link>https://slinviz.github.io/plang/scala/mvn-repo/</link>
      <pubDate>Fri, 08 Jan 2021 14:37:20 +0800</pubDate>
      
      <guid>https://slinviz.github.io/plang/scala/mvn-repo/</guid>
      <description>可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.
${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.
&amp;lt;!-- path to the local repository default ${user.home}/.m2/repository --&amp;gt; &amp;lt;localRepository&amp;gt;/path/to/local/repo&amp;lt;/localRepository&amp;gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.
&amp;lt;!-- &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;mirrorId&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;repositoryId&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;Human readable name for this mirror&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://my.repository.com/repo/path&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;mirror&amp;gt; .... &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; --&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;alimaven&amp;lt;/id&amp;gt; &amp;lt;mirrorOf&amp;gt;central&amp;lt;/mirrorOf&amp;gt; &amp;lt;name&amp;gt;aliyun maven&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt; &amp;lt;/mirror&amp;gt; &amp;lt;/mirrors&amp;gt; </description>
    </item>
    
  </channel>
</rss>