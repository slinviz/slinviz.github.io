<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/bigdata/spark/</link>
    <description>Recent content in Spark on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/bigdata/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cache与Checkpoint</title>
      <link>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</link>
      <pubDate>Sat, 27 Feb 2021 19:34:05 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</guid>
      <description>1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。
1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：
   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：</description>
    </item>
    
  </channel>
</rss>