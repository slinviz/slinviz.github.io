<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/bigdata/spark/</link>
    <description>Recent content in Spark on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/bigdata/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[转载]Apache Spark 内存管理详解</title>
      <link>https://slinviz.github.io/bigdata/spark/storage/</link>
      <pubDate>Thu, 04 Mar 2021 11:50:08 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/storage/</guid>
      <description>本文是对原文Apache Spark 内存管理详解的转载并做了部分排版修改，后续会加入一些自己的理解和补充。   0. 序言 1. 堆内和堆外内存规划  1.1 堆内内存 1.2 堆外内存 1.3 内存管理接口   2. 内存空间分配  2.1 静态内存管理 2.2 统一内存管理   3. 存储内存管理  3.1 RDD 的持久化机制 3.2 RDD 缓存的过程 3.3 淘汰和落盘   4. 执行内存管理  4.1 多任务间内存分配 4.2 Shuffle 的内存占用   结束语 参考资源 Reference   0. 序言 Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文旨在梳理出 Spark 内存管理的脉络，抛砖引玉，引出读者对这个话题的深入探讨。本文中阐述的原理基于 Spark 2.1 版本，阅读本文需要读者有一定的 Spark 和 Java 基础，了解 RDD、Shuffle、JVM 等相关概念。</description>
    </item>
    
    <item>
      <title>Cache与Checkpoint</title>
      <link>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</link>
      <pubDate>Sat, 27 Feb 2021 19:34:05 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/spark/cache-checkpoint/</guid>
      <description>1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。
1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：
   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：</description>
    </item>
    
  </channel>
</rss>