<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/bigdata/hadoop/</link>
    <description>Recent content in Hadoop on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/bigdata/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HDFS</title>
      <link>https://slinviz.github.io/bigdata/hadoop/hdfs/</link>
      <pubDate>Wed, 03 Mar 2021 14:08:44 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/hdfs/</guid>
      <description>HDFS 架构  1. NameNode  1.1 fsimage 和 editlog   2. SecondaryNameNode 3. DataNode 4. 数据流水线复制 5. 安全模式 6. 文件存储空间回收 7. HDFS 的健壮性   NameNode 高并发保障技术  1. 双缓存（Double-Buffer）机制 2. 分段加锁机制  2.1 加锁 2.2 多线程并发 2.3 批量数据刷磁盘和网络优化     部署 Hadoop 集群  0. 安装和配置环境变量 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 2. 启动集群 2.1 格式化 NameNode 2.2 启动 Hadoop 集群 3. 创建目录并存储文件   Reference   HDFS 架构 HDFS 是 Hadoop 的分布式文件系统，非常适合存储大文件和写入一次读取多次的文件，具有高吞吐量、高容错等特性，支持扩展到上千台商业服务器上。目前许多大数据处理平台（例如 Spark，Hive，Hbase等）都将 HDFS 作为底层的文件存储。</description>
    </item>
    
    <item>
      <title>YARN</title>
      <link>https://slinviz.github.io/bigdata/hadoop/yarn/</link>
      <pubDate>Tue, 02 Mar 2021 20:58:50 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/yarn/</guid>
      <description>集群资源管理者-YARN YARN（Yet Another Resource Negotiator）是 Hadoop 2.0 引入的集群资源管理系统。用户可以将多种服务框架部署在YARN上，由YARN进行统一的管理和资源分配。
YARN 框架 ResourceManager-RM RM 是整个集群资源的主要管理者和协调者，RM 负责对用户提交的应用程序分配资源。资源分配根据应用程序优先级，队列容量，ACLs，数据位置等信息做出决策，然后以共享的、安全的、多租户的方式制定策略，调度集群资源。
NodeManager-NM NM 负责管理当前节点的管理者，负责节点资源监视和节点健康跟踪，它还负责当前节点内所有容器的生命周期管理。具体如下：
 NM 启动时向 RM 注册并定时发送心跳信息，等待 RM 的命令； 维护Container生命周期，监控container的资源使用情况； 管理任务运行时的相关依赖，根据ApplicationMaster的需要，在启动container之前将程序及其依赖拷贝到本地。  ApplicationMaster-AM 在用户提交一个Application时，YARN 会启动一个轻量级进程ApplicationMaster， 负责协调来自RM的资源，并通过NM监视容器内资源的使用情况，同时负责任务的监控与容错。具体如下：
 根据Application运行状态动态决定资源需求； 向RM申请资源并监控申请的资源的使用情况； 跟踪任务进度和状态，报告资源使用情况和应用的进度信息； 复杂任务的容错。  Container Container是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、网络、磁盘等。当AM向RM申请资源时，RM为AM返回的资源使用Container表示的。YARN会为每个任务分配一个 Container，该任务只能使用该Container中描述的资源。AM可以在Container中运行任何类型的任务。如MapReduce中的Map Task和Reduce Task。
YARN 工作原理 概述  Client通过 RM 向YARN提交Application； RM 选择一个 NM， 然后启动一个 Container 运行 ApplicationMaster； ApplicationMaster 根据实际需求向 RM 申请更多的 Container 资源，（如果任务很小，AM 会选择在自己的 JVM 中运行任务）； AM 根据获取到的 Container 资源执行分布式任务计算。  详述 </description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://slinviz.github.io/bigdata/hadoop/overview/</link>
      <pubDate>Sat, 13 Feb 2021 20:38:25 +0800</pubDate>
      
      <guid>https://slinviz.github.io/bigdata/hadoop/overview/</guid>
      <description>1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。
 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景
 特别适合写一次，读多次的场景
大规模数据 流数据（写一次，读多次）
商用硬件
 Hadoop不适用的场景
 低延时数据访问 大量小文件 频繁修改文件
  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。
简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。
HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。
进程：NameNode, SecondaryNameNode, DataNode
数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。
读取策略：尽量读取距离最近的副本。
安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。
HDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2
通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。
健壮性
 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。
集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。
 NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等</description>
    </item>
    
  </channel>
</rss>