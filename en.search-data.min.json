[{"id":0,"href":"/bigdata/hadoop/hdfs/","title":"HDFS","parent":"Hadoop","content":"  HDFS 架构  1. NameNode  1.1 fsimage 和 editlog   2. SecondaryNameNode 3. DataNode 4. 数据流水线复制 5. 安全模式 6. 文件存储空间回收 7. HDFS 的健壮性   NameNode 高并发保障技术  1. 双缓存（Double-Buffer）机制 2. 分段加锁机制  2.1 加锁 2.2 多线程并发 2.3 批量数据刷磁盘和网络优化     部署 Hadoop 集群  0. 安装和配置环境变量 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 2. 启动集群 2.1 格式化 NameNode 2.2 启动 Hadoop 集群 3. 创建目录并存储文件   Reference   HDFS 架构 HDFS 是 Hadoop 的分布式文件系统，非常适合存储大文件和写入一次读取多次的文件，具有高吞吐量、高容错等特性，支持扩展到上千台商业服务器上。目前许多大数据处理平台（例如 Spark，Hive，Hbase等）都将 HDFS 作为底层的文件存储。\nHDFS 采用 Master/Slave 架构，主要由单个 NameNode（Master）和多个 DataNode（Slave）组成，为了提高 NameNode 的效率，还引入了 SecondaryNameNode。\nHDFS 具有以下特点：\n 核心架构的目标：实现错误检测和快速、自动的恢复（硬件错误是常态不是异常）； 简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题； HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。  1. NameNode  NameNode 负责管理整个HDFS集群的元数据和执行有关文件系统命名空间的操作：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等。 NameNode 负责监控 DataNode 的状态。DataNode 定期向 NameNode 发送心跳和块状态抱够。 NameNode 还负责接收来自 Client 的各种请求，并作出相应的应答。  HDFS 的文件系统命名空间 的层次结构与大多数文件系统类似 (如 Linux)， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。NameNode 负责维护文件系统名称空间，记录对名称空间或其属性的任何更改。  HDFS 的元数据存储在 NameManger 的 内存中，同时持久化保存在本地磁盘文件fsimage（命名空间镜像文件）和 editlog（操作日志文件）中。  HDFS 把文件分成固定大小的块 Block，并根据冗余系数（默认replication 为3）存储到集群中。数据块副本存放策略是机架感知：大多数情况下副本系数为3，HDFS 的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。读取策略是尽量读取距离近的副本。\nHadoop 1.x : blocksize = 64M Hadoop 2.x : blocksize = 128M 1.1 fsimage 和 editlog fsimage 是内存命名空间元数据在外存的镜像文件。editlog 文件则记录着用户多文件的各自操作记录，当客户端对 HDFS 中的文件进行新增或者修改等操作是，操作记录首先被记入 editlog 文件中，当操作成功后将相应的元数据更新到内存中，以防止发生意外导致丢失内存中的数据。editlog 只能顺序追加记录，fsimage和editlog两个文件结合可以构造出完整的内存数据.NameNode 每次重启时将editlog里的操作日志读到内存中回放即可恢复元数据。\n2. SecondaryNameNode 为了保证当 NameNode 出现故障之后不丢失数据或能快速恢复 HDFS 的元数据，引入了 SecondaryNameNode，它主要负责定期合并 fsimage 和 editlog ，维护和 NameNode 相同的元数据。必要时候可以作为 NameNode 的热备份。\n在高可用（HA）情况下，主节点（Active NameNode）每次修改元数据都会生成一条 editlog 记录，该日志记录既写入磁盘文件（NameNode 本地的editlog 文件）也写入JournalNodes集群，然后 SecondaryNameNode 从 JournalNodes 集群拉取操作日志并应用到自己的文件目录树中，跟主节点保持一致，每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode 将完整的元数据写入到自己的磁盘文件fsimage，即checkpoint操作，之后再将 fsimage 上传到主节点（Active NameNode），并清空editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据，然后再将新的editlog里的少量修改操作记录放回内存中即可。\n3. DataNode  DataNode 是 HDFS 中实际存储和读写数据块的节点，一个 Block 会在多个 DataNode 中进行冗余备份，而一个 DataNode 对于一个块最多只包含一个备份。 DataNode 还负责提供来自客户端的读写请求，执行块的创建，删除等操作。 DataNode 会定期向 NameNode 发送心跳信号和块状态报告。  心跳信号（Heartbeat）：表明当前 DataNode 节点正常工作 块状态报告（Block Report）：包含该DataNode上所有数据块的列表   DataNode 之间也会相互通信，执行数据块的复制任务，同时在客户端执行写操作的时候，DataNode 之间需要相互配置，以保证写操作的一致性。 DataNode 还会接收和执行来自 NameNode 的命令，如删除某些数据块或把数据块复制到另一个 DataNode。  4. 数据流水线复制 当Client 向 HDFS 文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从 NameNode 获取一个 Datanode 的列表用于存放副本； 然后客户端开始向第一个 Datanode 传输数据，第一个 Datanode 一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个 Datanode 节点； 第二个Datanode 也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个 Datanode。 最后，第三个 Datanode 接收数据并存储在本地。   因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个 Datanode 复制到下一个。\n通信协议\nHDFS 的通信协议都是建立在TCP/IP协议之上，Client 与 NameNode 之间使用ClientProtocol，DataNode 与 NameNode 之间使用DatanodeProtocal。\n 5. 安全模式 处于安全模式的 NameNode 是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数，当 NameNode 检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（参数可配置）的数据块被 NameNode 检测确认是安全之后（加上一个额外的30秒等待时间），NameNode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他 DataNode上。\n6. 文件存储空间回收  文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从 HDFS 中删除。实际上，HDFS 会将这个文件重命名转移到.Trash 目录，保存时间可配置，默认是6个小时。 减少副本系数：当一个文件的副本系数被减小后，NameNode 会选择过剩的副本删除。下次心跳检测时会将该信息传递给 DataNode。DataNode遂即移除相应的数据块，释放存储空间。  7. HDFS 的健壮性  磁盘数据错误，心跳检测和重新复制：当 DataNode 宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制； 集群均衡：自动将数据移动到其它空闲的 DataNode 上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据； 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个 HDFS 命名空间下，客户端获取和进行检验，如果不对则读取其它副本； 元数据磁盘错误恢复：支持维护多个fsimage 和editlog，修改同步到副本上。  NameNode 高并发保障技术 1. 双缓存（Double-Buffer）机制 NameNode 在写入editlog的过程中如果只对同一块内存缓冲，同时存在大量写入和读出是不可能的，因为不能并发读写同一块共享内存数据！因此 HDFS 在读写editlog时采取了 Double-Buffer 双缓冲机制，将一块内存缓冲分成两个部分：\n 一部分用于写入操作日志 另一部分用于读取后写入磁盘和 JournalNodes 集群  2. 分段加锁机制 2.1 加锁  首先各个线程依次第一次获取锁，生成顺序递增的txid，然后将edit log写入内存双缓冲的区域1，接着就立马第一次释放锁; 趁着这个空隙，后面的线程就可以再次立马第一次获取锁，然后立即写自己的edit log到内存缓冲；写内存那么快，可能才耗时几十微妙，接着就立马第一次释放锁； 接着各个线程竞争第二次获取锁，有线程获取到锁之后，就判断是否有其他线程在写磁盘和网络？如果没有，那么这个幸运儿线程直接交换双缓冲的区域1和区域2，接着第二次释放锁。这个过程相当快速，内存里判断几个条件，耗时不了几微秒； 现在内存缓冲区已经被交换了，后面的线程可以立马快速的依次获取锁，然后将edit log写入内存缓冲的区域2，而内存缓冲区域1中的数据被锁定了，不能写；  2.2 多线程并发 接着，之前那个幸运儿线程将内存缓冲的区域1中的数据读取出来（此时没线程写区域1了，都在写区域2），将里面的edti log都写入磁盘文件，以及通过网络写入JournalNodes集群。这个过程可是很耗时的！但是做过优化了，在写磁盘和网络的过程中，是不持有锁的！因此后面的线程可以快速的第一次获取锁后，立马写入内存缓冲的区域2，然后释放锁。这个时候大量的线程都可以快速的写入内存，没有阻塞和卡顿！  2.3 批量数据刷磁盘和网络优化 在幸运儿线程把数据写磁盘和网络的过程中，排在后面的大量线程快速的第一次获取锁，写内存缓冲区域2，释放锁，之后，这些线程第二次获取到锁后会发现有人在写磁盘，所以会立即释放锁，然后休眠1秒后再次尝试获取锁。此时大量的线程并发过来的话，都会在这里快速的第二次获取锁，然后发现有人在写磁盘和网络，快速的释放锁，休眠。这个过程不会长时间的阻塞其他线程！因为都会快速的释放锁，所以后面的线程还是可以迅速的第一次获取锁后写内存缓冲！而且这时，一定会有很多线程发现，好像之前那个幸运儿线程的txid是排在自己之后的，那么肯定就把自己的edit log从缓冲里写入磁盘和网络了。这些线程甚至都不会休眠等待，直接就会返回后去干别的事情了，压根儿不会卡在这里。 然后那个幸运儿线程写完磁盘和网络之后，就会唤醒之前休眠的那些线程。那些线程会依次排队再第二次获取锁后进入判断，发现没有线程在写磁盘和网络了！然后就会再判断，有没有排在自己之后的线程已经将自己的edti log写入磁盘和网络了。如果有的话，就直接返回了。没有的话，那么就成为第二个幸运儿线程，交换两块缓冲区，区域1和区域2交换一下。然后释放锁，自己开始将区域2的数据写入磁盘和网络。这个时候后面的线程如果要写edits log的，还是可以第一次获取锁后立马写内存缓冲再释放锁，以此类推。  部署 Hadoop 集群 由于机器有限，这里将 Hadoop 的主要组件 HDFS、MapReduce 和 YARN 都部署到了同一台机器上，并且重点关注启动 HDFS 并存储文件到 HDFS 的过程。\n0. 安装和配置环境变量 从 Apache Hadoop Releases 页面下载相应的 Hadoop 文件包，这里下载的是hadoop-2.7.7。下载完成之后解压并配置相应的环境变量 HADOOP_HOME 并将 ${HADOOP_HOME}/bin 将入到系统搜索路径 PATH 中。注意，JDK 等也需要配置。\n$ tar -zxf hadoop-2.7.7.tar.gz -C /usr/local 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 修改 ${HADOOP_HOME}/etc/hadoop 目录下的 Hadoop 相关配置文件，主要包括 core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml 等。注意，集群的节点在 ${HADOOP_HOME}/etc/hadoop/slaves 中配置。\n在多机分布式模式下，还需要将配置文件分发到各个节点。\ncore-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/usr/local/hadoop/tmp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   hdfs-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   mapred-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.framework.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;yarn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   yarn-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.hostname\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;localhost\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    2. 启动集群 2.1 格式化 NameNode 在启动集群之前，建议先在 NameNode上执行 hdfs namenode -format 命令格式化 HDFS 文件系统。格式化完毕后可以看到在 ${hadoop.tmp.dir} 目录下生成了 dfs/name 目录，其中包括 fsimage 和 seen_txid （transactionid）。\n$ hdfs namenode -format # format the DFS filesystem # The contents in ${hadoop.tmp.dir} after above command . └── tmp └── dfs └── name └── current ├── VERSION ├── fsimage_0000000000000000000 ├── fsimage_0000000000000000000.md5 └── seen_txid 2.2 启动 Hadoop 集群 格式化完成后即可运行 ${HADOOP_HOME}/sbin/start-all.sh 脚本一次性启动集群的所有组件，包括 HDFS 的 NameNode, SecondaryNameNode, DataNode 和 YARN 的 ResourceManager, NodeManager 进程。\n# Start HDFS MapReduce and YARN $ ${HADOOP_HOME}/sbin/start-all.sh # Process $ jps 70689 SecondaryNameNode 70803 ResourceManager 70582 DataNode 70889 NodeManager 70495 NameNode 71870 Jps 因为这里将所有组件都部署到了同一台机器下，所有可以在${hadoop.tmp.dir} 目录下看到为 NameNode, SecondaryNameNode, DataNode 创建的目录。\n NameNode : name SecondaryNameNode : namesecondary DataNode : data  nm-local-dir 目录是 NodeManager 创建的目录，用于缓存用户程序和相应的配置文件。\n对于 NameNode, SecondaryNameNode ，它们主要是存储和维护 HDFS 的元数据 fsimage 和操作日志 editlog，而 DataNode 主要是存储实际的数据块 Block，此处暂时还未向文件系统写入数据，因此暂时没有对应的数据块文件。\n3. 创建目录并存储文件 经过以上几步后集群就以及正常启动了，下面下 HDFS 中写入一个文件。首先，创建一个 data 目录，然后将 test.txt 上传到文件系统中，最后使用 hdfs dfs cat data/test.txt 查看文件的内容。\n$ hdfs dfs -mkdir -p data $ hdfs dfs -put test.txt data/ $ hdfs dfs -cat data/test.txt 从浏览器中查看 HDFS 的相关信息，如集群节点的状态等，也可以直接在浏览器中浏览文件系统的内容，如下，虽然只存了很小的一个文件（33B），但 HDFS 还是分配了一个 128M 的数据块。\n再次查看 ${hadoop.tmp.dir} 目录， 可以发现 dfs/data 目录的子目录中已经写入了数据块文件，它们存储的就是刚才上传到 HDFS 中的 test.txt 的实际数据。因为这里设置的 replication 为1，并且test.txt也只需要一个数据块即可存储，所以这里只能看到一个数据块文件（和保存它的元数据信息文件）。\nReference  https://juejin.cn/post/6844903992066048014 https://zhuanlan.zhihu.com/p/37219709 https://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-HDFS.md https://www.cnblogs.com/52mm/p/p13.html https://juejin.cn/post/6844903713966915598  "},{"id":1,"href":"/plang/scala/basic/","title":"Scala 基本数据类型和流程控制","parent":"Scala","content":"  Scala 基本数据类型   Scala 基本数据类型 Byte, Short, Int, Long, Float, Double, Char, Boolean, String, RichInt, RichDouble, StringOps\n格式化字符串\nprintf(\u0026#34;Hello, %s! You are %d years old.%n\u0026#34;, name, age) print(f\u0026#34;Hello, ${name}! In six months, you\u0026#39;ll be ${age+0.5}%7.2f years old.%n\u0026#34;) print(s\u0026#34;$$$price\u0026#34;)  在 Scala 中，变量或函数的类型总是写在变量或函数名称的后面。 在 Scala 中， 仅当同一行代码中存在多条语句时才需要用分号;隔开。 Scala 中的操作符实际上是方法，且不能对操作符进行重载，但允许定义操作符。   "},{"id":2,"href":"/bigdata/hadoop/yarn/","title":"YARN","parent":"Hadoop","content":"集群资源管理者-YARN YARN（Yet Another Resource Negotiator）是 Hadoop 2.0 引入的集群资源管理系统。用户可以将多种服务框架部署在YARN上，由YARN进行统一的管理和资源分配。\nYARN 框架 ResourceManager-RM RM 是整个集群资源的主要管理者和协调者，RM 负责对用户提交的应用程序分配资源。资源分配根据应用程序优先级，队列容量，ACLs，数据位置等信息做出决策，然后以共享的、安全的、多租户的方式制定策略，调度集群资源。\nNodeManager-NM NM 负责管理当前节点的管理者，负责节点资源监视和节点健康跟踪，它还负责当前节点内所有容器的生命周期管理。具体如下：\n NM 启动时向 RM 注册并定时发送心跳信息，等待 RM 的命令； 维护Container生命周期，监控container的资源使用情况； 管理任务运行时的相关依赖，根据ApplicationMaster的需要，在启动container之前将程序及其依赖拷贝到本地。  ApplicationMaster-AM 在用户提交一个Application时，YARN 会启动一个轻量级进程ApplicationMaster， 负责协调来自RM的资源，并通过NM监视容器内资源的使用情况，同时负责任务的监控与容错。具体如下：\n 根据Application运行状态动态决定资源需求； 向RM申请资源并监控申请的资源的使用情况； 跟踪任务进度和状态，报告资源使用情况和应用的进度信息； 复杂任务的容错。  Container Container是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、网络、磁盘等。当AM向RM申请资源时，RM为AM返回的资源使用Container表示的。YARN会为每个任务分配一个 Container，该任务只能使用该Container中描述的资源。AM可以在Container中运行任何类型的任务。如MapReduce中的Map Task和Reduce Task。\nYARN 工作原理 概述  Client通过 RM 向YARN提交Application； RM 选择一个 NM， 然后启动一个 Container 运行 ApplicationMaster； ApplicationMaster 根据实际需求向 RM 申请更多的 Container 资源，（如果任务很小，AM 会选择在自己的 JVM 中运行任务）； AM 根据获取到的 Container 资源执行分布式任务计算。  详述 "},{"id":3,"href":"/pbasic/os/os/","title":"操作系统","parent":"操作系统OS","content":"1. 什么是操作系统？  操作系统是管理计算机硬件和软件资源的程序，是计算机的基石。 OS本质上是配置在计算机硬件上的第一层软件，用于管理计算机硬件和软件资源。 OS做为用户和计算机硬件系统之间的接口，屏蔽了硬件层的复杂性。操作系统就像是硬件使用的负责人，统筹着各种相关事项。 操作系统内核是操作系统的核心部分，它负责系统的内存管理，硬件设备管理，文件系统管理和应用程序管理。内核是连接应用程序和硬件之间的桥梁，决定着系统的性能和稳定性。  2. 什么是系统调用？ 根据进程访问资源的特点，可以将进程在系统上的运行分为两个级别：\n 用户态：用户态运行的进程可以直接读取用户程序的数据 系统态：系统态运行的进程几乎可以访问计算机的任何资源，不受限制  一般情况下用户程序都是运行在用户态，当需要调用操作系统的系统态级别的子功能的时候就需要系统调用了。也就是说用户程序中凡是与系统态级别的资源的操作，如文件管理、进程控制、内存管理等，就需要通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。\n系统调用按功能大致可分为：\n 设备管理：完成设备的请求或释放，以及设备的启动等功能。 文件管理：完成文件读、写、创建和删除等功能。 内存管理：完成内存的分配，回收，虚拟地址转换等功能。 进程控制：完成进程的创建，撤销，阻塞以及唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。  "},{"id":4,"href":"/pbasic/os/os-process/","title":"进程和线程","parent":"操作系统OS","content":"  1. 基本概念 2. 进程和线程的区别 3. 进程的状态 4. 进程间通信方式  4.1 管道/匿名管道 4.2 有名管道 4.3 信号 4.4 消息队列 4.5 信号量 4.6 共享内存 4.7 套接字   5. 线程间同步 6. 进程调度算法  6.1 先到先服务（FCFS）调度算法 6.2 短作业优先（SJF）调度算法 6.3 时间片轮转（RR）调度算法 6.4 多级反馈队列调度算法 6.5 优先级调度算法     1. 基本概念   进程（Process）\n进程是一个动态的概念，通常指的是进程实体 = PCB + 程序段 + 数据段。PCB主要包括程序计数器，程序上下文，程序资源（文件、信号等）等。\n  线程（Thread）\n线程实际上是进程内部的一条执行序列（执行流），执行序列是指一组有序指令加数据的集合，执行序列是以函数为单位的。线程是一种轻量级的进程。线程一定是在进程内部进行活动的，并且每一个线程都拥有一个独立的计数器、进程栈和一组进程寄存器。强调一点，进程调度的对象是线程，而不是进程。\n  协程（Coroutine） 协程是一种用户态的轻量级线程，调度由用户控制，拥有自己独立的寄存器上下文和栈。协程的切换效率比线程还要高，协程和线程的区别包括：\n   线程是由CPU调度，而协程是由用户调度 线程存在安全问题，协程比线程较安全 线程使用同步机制，协程使用异步机制  管程（Monitor）\n管程是一种程序设计语言结构部分，是代表共享资源的数据结构，以及对该共享数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块。管程被请求和释放 资源的进程所调用。本质上，管程是一种抽象数据结构（ADT）。  2. 进程和线程的区别  进程是系统资源分配的最小单位，线程是CPU调度的最小单位 一个进程可以包含多个线程，一个线程只能属于一个进程 进程创建的资源消耗比线程创建的资源消耗大很多 进程切换的效率比线程切换的效率低很多 系统中的进程相互独立，而同一个进程内的线程只有自己的程序计数器和栈区，其他空间共享 进程间通信必须借助外部手段，同一个进程内线程间通信可以借助共享空间 进程间不存在安全问题，同一个进程内的线程间存在安全问题  3. 进程的状态 一般情况下，将进程分为以下5中状态：\n 创建（New）: 进程正在被创建，尚未到达就绪转态 就绪（Ready）：准备运行状态，除了处理器以外的所有资源均已获得，一旦得到处理器资源即可运行 运行（Running）：进程正在处理器上运行 阻塞（waiting）：进程正在等待某一事件而暂停或等待某一资源可用或等待I/O操作完成。即使处理器空闲，进程也不能运行 结束（Terminated）：进程正在从系统中消失，可能是正常结束也可能是其他原因中断退出  4. 进程间通信方式 系统中的进程相互独立，通信需要借助外部手段。大概有7种方式实现进程间通信：\n4.1 管道/匿名管道 匿名管道\n4.2 有名管道 4.3 信号 4.4 消息队列 4.5 信号量 4.6 共享内存 4.7 套接字 5. 线程间同步 6. 进程调度算法 6.1 先到先服务（FCFS）调度算法 6.2 短作业优先（SJF）调度算法 6.3 时间片轮转（RR）调度算法 6.4 多级反馈队列调度算法 6.5 优先级调度算法 Reference:\n https://blog.csdn.net/love10_1314/article/details/97282627 《计算机操作系统》 汤小丹，第三版 进程间通信IPC (InterProcess Communication)  "},{"id":5,"href":"/plang/java/basic/object/","title":"Object 类","parent":"Java 基础","content":"java.lang.Object 是Java类的最顶层，也是Java中唯一一个没有父类的类。其他的类要么显式的声明继承自其他类，要么隐式的继承Object类。  Java 中Object类不做为接口的父类。因为Java中的接口不能从java中的类继承，至少不能直接继承。 明确指明某个类继承自Object，即class SomeClass extends Object后，该类不能再继承其他类，Java仅支持单继承。   Object类中定义的方法如下：\n  document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object{ +equales() boolean +hashCode() int +toString() String +getClass() Class~~ #finalize() void #clone() Object +notify() void +notifyAll() void +wait() void +wait(long timeout) void +wait(long timeout, int nanos) void }  equals与==  ==：作用是判断两个对象的地址是否相等，即这两个对象是否是同一个对象。对于基本类型，其比较的是值，对于对象比较的是地址。 equales方法：判断两个对象是否相等，有两种情况：  类没有覆写该方法，调用该方法时等价于使用== 类覆写了equales()方法，一般覆写后是判断两个对象的内容是否相等。    覆写equales()方法时一定要覆写hashCode()方法\nhashCode() 方法返回该对象的哈希码给调用者。\n 如果两个对象相等，那么它们的哈希码一定是相等的 反过来，两个对象具有相同的哈希码，这两个对象却不一定是相等的 hashCode() 默认行为是对堆上的对象产生独特值，如果没有覆写，那么这两个对象无论如何都不会相等 同时覆写这两个方法可以保证对象的功能兼容于Hash集合   Reference:\n Do Interfaces really inherit the Object class in Java? Java：Object类详解  "},{"id":6,"href":"/plang/java/basic/exceptions/","title":"Java Error和Exception","parent":"Java 基础","content":"Java中如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。此时JVM会抛出一个封装了错误信息的对象，方法会立刻退出同时不返回任何值。\nJava 中的“异常”可以分为Error（错误）和Exception（异常）两大类，它们都是Throwable的子类。其中：\n Error： Java运行时系统的内部错误或资源耗尽。当出现这样的错误，JVM会告知用户出现错误，并终止程序。 Exception： 异常可分为编译阶段的CheckedException和程序正常运行过程中抛出的RuntimeException两大类。  CheckedException：继承自java.lang.Exception类，一般是外部错误，发生在编译阶段，Java编译期会强制程序去捕获此类异常（要求使用try{}catch{}finally{}显式的去包裹可能出现这类异常的代码段）。 RuntimeException：运行时异常，如空指针，数组索引越界等，还有CheckedException，出现这类异常一定是程序错误。      document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object class Throwable class Error class Exception class RuntimeException Object 异常处理  throw 主动从方法中抛出异常交给上层调用处理。 throws 声明函数可能出现的异常。      throw throws     使用位置 方法内部 方法声明后   功能 抛出具体的异常对象，执行到throw方法调用接收，返回异常给上层调用 声明可能出现的异常，让调用者知道该方法可能出现的异常   是否处理异常 不处理，抛出异常给上层调用 不处理，指明可能出现的异常    使用对比：\nthrow\nclass ThrowExample{ public void throwTest() { try{ ... throw new ArithmeticException(\u0026#34;Divided zero!\u0026#34;); } catch(ArithmeticException ex){ ex.printStackTrace(); } } }   throws\nclass ThrowsExample{ public void throwsTest() throws NumberFormatException, NullPointerException { // method body  ... } }    Reference:\nhttps://mermaid-js.github.io/mermaid/#/classDiagram\n"},{"id":7,"href":"/pbasic/dsalg/leetcode/","title":"Leetcode刷题记录","parent":"数据结构与算法","content":"1. 滑动窗口 解决有序数列连续和问题。限定窗口滑动方向，例如左右窗口只能向右滑动，区间设置为左闭右开。那么左窗口滑动缩小区间，右窗口滑动扩大窗口。\n"},{"id":8,"href":"/bigdata/spark/cache-checkpoint/","title":"Cache与Checkpoint","parent":"Spark","content":"  1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。\n1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：\n   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：\n 尽量保持RDD的默认存储级别（MEMORY_ONLY），这是CPU效率最高的选项，允许RDD上的操作尽可能快地运行。 如果不是，可尝试使用MEMORY_ONLY_SER并选择一个快的序列化库，以使对象的空间效率更高，但访问速度仍然相当快，仅适用于Java和Scala API。 尽量不要将RDD缓存到磁盘，除非用于计算RDD非常消耗资源或者可以过滤掉大量数据。否则，重新计算分区的速度可能与从磁盘读取分区的速度一样快。 如果需要快速的故障恢复能力，使用复制的存储级别(XXX_2)。所有存储级别都通过重新计算丢失的数据来提供完全的容错能力，但是复制的存储级别具有冗余备份，一般情况下不需要等待重新计算丢失的分区。  1.2 Cache细节 通常情况下，被频繁地重复使用RDD需要进行Cache以提高效率。因为用户只能与Driver程序打交道，因此Cache一个RDD需要用户在编程的时候显式的调用rdd.cache() 或者rdd.persist(storagelevel)进行缓存。 用户只能cache程序代码中显式存在的rdd，对于那些Transformation中\u0026quot;隐式\u0026quot;生成的RDD，如ShuffledRDD，MapPartitionsRDD是不能被cache的。    缓存RDD Partition\nSpark Cache RDD发生在第一次计算RDD时，在将要计算RDD Partition时（而不是已经计算得到一个record时），就去判断Partition是否需要被Cache，如果需要Cache的话，就先将Partition计算出来，然后缓存到内存。\n  取cached RDD Partition\n下次计算(一般是同一application 的下一个 job 计算)时如果用到 cached RDD，task 会直接去 blockManager 的 memoryStore 中读取。具体地讲，当要计算某个 rdd 中的 partition 时候(通过调用 rdd.iterator())会先去 blockManager 里 面查找是否已经被 cache 了，如果 partition 被 cache 在本地，就直接使用 blockManager.getLocal() 去本地 memoryStore 里读取。如果该 partition 被其他节点上 blockManager cache 了，会通过 blockManager.getRemote() 去其他节点上读取，读 取过程如下图。\n  获取 cached partitions 的存储位置 partition 被 cache 后其所在节点上的 blockManager 会通知 driver 上的 blockMangerMasterActor 说某 rdd 的 partition 已经被我 cache 了，这个信息会存储在 blockMangerMasterActor 的 blockLocations: HashMap中。等到 task 执行需要 cached rdd 的时候，会调用 blockManagerMaster 的 getLocations(blockId) 去询问某 partition 的存储位置，这个询问信息会发到 driver 那里，driver 查询 blockLocations 获得位 置信息并将信息送回。\n  读取其他节点上的 cached partition task 得到 cached partition 的位置信息后，将 GetBlock(blockId) 的请求通过 connectionManager 发送到目标节点。目标节点收到请求后从本地 blockManager 那里的 memoryStore 读取 cached partition，最后发送回来。\n    2. Checkpoint机制 Spark中的Checkpoint机制是设计来对RDD进行持久化存储的（除非手动删除，否则它将永久存在于文件系统中，一般是缓存到HDFS中），因此可以跨Application使用，Cache机制中缓存到内存或磁盘中的RDD在application退出时就被清理掉了。  对于需要很长运算时间或运算量很大的rdd，computing chain过长或依赖其他rdd很多的rdd，可以选择对其进行Checkpoint。用户需要显式的调用rdd.checkpoint来对某个rdd设置检查点，sparkcontext.setCheckpointDir(dir)设置检查点目录。\n2.1 Checkpoint细节 不同于Cache 机制是每计算出一个要 cache 的 partition 就直接将其 cache 到内存中，Checkpoint 机制是等到 job 结束后另外启动专门的 job 来完成 checkpoint 。也就是说需要 checkpoint 的 RDD 会被计算两次。因此，在使用 rdd.checkpoint() 的时候，建议加上 rdd.cache()，这样第二次运行的 job 就不用再去计算该 rdd ，而是直接读取 cache 后写磁盘。\nRDD 需要经过 [ Initialized --\u0026gt; marked for checkpointing --\u0026gt; checkpointing in progress --\u0026gt; checkpointed ] 这几个阶段才能被 checkpoin。\n  Initialized 首先 driver program 需要使用 rdd.checkpoint() 去设定需要 checkpoint的rdd，检查点路径用sc.setCheckpointDir(dir)设置（一般设置HDFS目录），设定后该 rdd 就接受RDDCheckpointData 管理。\n  marked for checkpointing 初始化后RDDCheckpointData 会将管理的 rdd 标记为 MarkedForCheckpoint。\n  checkpointing in progress 每个 job 运行结束后Spark会调用 finalRdd.doCheckpoint()，finalRdd 会顺着 computing chain 回溯扫描，碰到要 checkpoint 的 RDD 就将其标记为 CheckpointingInProgress，然后将写磁盘(比如写 HDFS)需要的配置文件 (如 core-site.xml 等)broadcast 到其他 worker 节点上的 blockManager。完成以后，启动一个 job 来完成 checkpoint(使 用 rdd.context.runJob(rdd, CheckpointRDD.writeToFile(path.toString, broadcastedConf)))。\n  checkpointed job 完成 checkpoint 后，将该 rdd 的 dependency 全部清掉，并设定该 rdd 状态为 checkpointed。然后为该 rdd 强加一个依赖，设置该 rdd 的 parent rdd 为 CheckpointRDD，该 CheckpointRDD 负责以后读取在文件系统上的 checkpoint 文件，生成该 rdd 的 partition。\n  当调用 rdd.iterator() 去计算该 rdd 的 partition 的时候，会调用 computeOrReadCheckpoint(split: Partition) 去查看该 rdd 是 否被 checkpoint 过了，如果是，就调用该 rdd 的 parent rdd 的 iterator() 也就是 CheckpointRDD.iterator()，CheckpointRDD 负责读取文件系统上的文件，生成该 rdd 的 partition。\n3. Cache与Checkpoint的异同 Cache\n Cache机制中RDD Partition被缓存到内存或磁盘（或内存+磁盘），数据由blockManager管理。 Application退出后Cache在磁盘/内存中的RDD Partition会被清空。 Cache不会破坏RDD的Lineage，即RDD Partition丢失后可以根据计算链重新计算。 需要cache的 RDD 是在第一次计算得到时以Partition为单位进行缓存的。   Checkpoint\n Checkpoint机制中RDD Partition被持久化存储到文件系统（一般是HDFS）。 Application退出后Checkpoint的数据依旧存在，可以被其他应用使用。 Checkpoint会将RDD的依赖关系完全清除，并强加一个Parent RDD CheckpointRDD，需要时只能用CheckpointRDD从文件系统中读取数据，如果存储在文件系统上的数据被蓄意破坏，则需要重新启动该Application才能恢复计算。 Checkpoint发生在当前job结束后重新启动一个新的job来完成检查点的存储工作。    Reference：\n RDD Programming Guide Apache Spark 设计与实现  "},{"id":9,"href":"/pbasic/os/os-fs/","title":"文件管理","parent":"操作系统OS","content":"  1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.1 文件控制块和索引节点 4.2 文件目录结构  4.2.1 单级目录结构 4.2.2 两级目录 4.3.1 多级目录   4.3 目录查询技术  4.3.1 线性检索法 4.3.1 Hash检索法     5. 文件存储空间管理  5.1 空闲表法和空闲链表法 5.2 位示图法 5.3 成组链接法   6. 文件共享与文件保护  6.1 文件共享 6.2 文件保护  6.2.1 磁盘容错技术     7. 数据一致性控制  7.1 事务 7.2 检查点 7.3 并发控制     1. 文件和文件系统 文件系统的管理功能是通过将其所管理的程序和数据组织成一系列文件来实现的。\n1.1 文件层次关系 1.1.1 数据项 在文件系统中，数据项是最低级的数据组织形式，包括基本数据项和组合数据项。基本数据项是用于描述一个对象的某种属性的字符集，是数据组织中可以命名的最小逻辑数据单位，即原子数据，又称为数据元素或字段。组合数据项是有若干基本数据项组成的，简称组项。\n1.1.2 记录 记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。\n1.1.3 文件 文件是指由创建者所定义的、具有文件名的一组相关记录的集合，可分为有结构文件（若干相关记录组成的文件）和无结构文件（文件被看做字符流）。文件具有自己的属性：文件类型、文件长度、文件的物理位置、文件的创建时间等。\n1.2 文件类型  普通文件：由ASCII码或二进制码组成的字符文件。 目录文件：由文件目录组成，用来管理和实现文件系统功能的系统文件，通过目录文件可对其他文件的信息进行检索。 特殊文件：特指系统中的各类I/O设备，可分为块设备文件和字符设备文件。  1.3 文件系统模型 文件系统模型可分为三个层次：对象及其属性；对对象进行操纵和管理的软件集合；文件系统接口。\n对象及其属性\n文件管理系统管理的对象有：\n 文件：文件管理的直接对象 目录：方便对文件的存取和索引，每个目录项中必须含有文件名及该文件所在的物理地址（指针） 磁盘存储空间：文件和目录必定占用存储空间   对对象操纵和管理的软件集合\n文件系统的核心部分，主要功能包括：\n 文件存储空间的管理 文件目录的管理 文件逻辑地址和物理地址的转换机制 文件读写的管理 文件共享和保护   文件系统接口\n 命令接口 程序接口：系统调用   1.4 文件操作  创建文件：分配必要的外存空间，建立目录项 删除文件：从目录中查找对应的目录项并使之成为空项，回收该文件占用的存储空间 读文件 写文件 截断文件 设置文件读/写位置  2. 文件的逻辑结构 文件逻辑结构是用户视角的文件组织形式，它独立于文件的物理特性（存储方式）。文件逻辑结构可分为记录式文件（有结构文件）和流式文件（字符流）。\n2.1 记录式文件 2.1.1 顺序文件 由一系列记录按照某种顺序排列所形成的文件，其中的记录通常是定长记录。\n 文件记录可以按照写入时间排序（串结构），也可以按照关键字排序（顺序结构）。 对串结构文件查找每次必须从头开始 对顺序结构文件查找可以使用如折半查找、插值查找等算法 删除或增加记录需要移动其他记录  2.1.2 索引文件 当记录的长度可变时，通常建立一张索引表，并为每个记录设置一个表项。\n 顺序存取和直接实现方便 当记录较多时索引表需要较多额外存储资源  2.1.3 索引顺序文件 为文件建立一张索引表，为每组记录的第一个记录设置一个表项，组内组织为顺序结构，\n 组间索引，组内顺序  2.2 直接文件和哈希文件 2.2.1 直接文件 根据记录的键值对线性表或链表进行检索，已找到指定记录的物理地址，即记录键值本身觉得记录的物理地址。\n2.2.2 哈希文件 利用Hash函数将记录键值转换为相应记录的地址，通过目录表可实现文件存储空间的动态分配。\n3. 外存分配方式 3.1 连续分配方式 连续分配要求为每个文件分配一组相邻的盘块。一组盘块的地址定义了磁盘上的一段线性地址。\n 顺序访问容易、速度快 要求连续的存储空间，必须事先知道文件的长度，容易产生外部碎片  3.2 链接分配 通过每个盘块上的链接指针将同属于一个文件的多个离散盘块链接成一个链表，离散分配，消除外部碎片，提高外存利用率，增删改查方便。\n 隐式链接：每个盘块保护文件开始、文件结束盘块和下一个盘块的指针。 显式链接：将盘块指针显式的放在内存的一张链接表（文件分配表，FAT）中。 为提高效率，可以将连续的盘块组合为簇，以簇为分配单位。   FAT需要占用较大的内存空间 不能支持高效的直接存取  3.3 索引分配 3.3.1 单级索引分配 将每个文件对应的盘块号集中存放，为每个文件分配一个索引块（表），再把分配给该文件的所有盘块号都记录在索引块中。\n 支持直接访问 不会产生外部碎片 对小文件需要块索引利用率极低  3.3.2 多级索引分配 一级索引表 -\u0026gt; 二级索引表 -\u0026gt; 三级索引表 -\u0026gt; \u0026hellip; -\u0026gt; 盘块号\n3.3.3 混合索引分配 将多种索引分配方式相结合而形成的一种分配方式。\n 直接地址 一次间接地址 多次间接地址  4. 目录管理 对目录管理的基本要求：\n 按名存取 提高目录的检索速度 文件共享 运行文件重名  4.1 文件控制块和索引节点 文件控制块FCB：文件与文件控制块一一对应，一个文件控制块就是一个文件目录项。文件控制块的有序集合称为文件目录，通常一个文件目录可以被看做是一个文件，称为目录文件。\nFCB通常包含三类信息：基本信息、存取控制信息和使用信息。\n 基本信息：文件名，文件物理位置，文件逻辑结构（流式文件or记录式文件），文件物理结构（顺序文件、链接文件、索引文件） 存取控制信息：文件的存取权限（user, group, other） 使用信息：文件建立日期，修改日期，当前使用信息等。  索引节点（i节点）：将文件名和文件描述信息分开，使文件描述信息单独形成一个称为索引节点的数据结构。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i节点的指针所构成。\n 磁盘索引节点：存储在磁盘上的所有节点，主要包括文件标识符、文件类型、存取权限、物理地址等。 内存索引节点：存放于内存中的所有节点，当文件打开时将磁盘索引节点拷贝到内存中，增加索引节点编号，状态，访问计数，链接指针等信息。  4.2 文件目录结构 4.2.1 单级目录结构 整个文件系统仅建立一张目录表。缺点：查找速度慢、不允许重名、不便于文件共享。\n4.2.2 两级目录 系统建立一个主文件目录（MFD），并为每个用户单独建立一个用户文件目录(UFD)。两级目录提高了目录检索速度，不同的用户文件可以重名，可实现不同用户访问共享文件。\n4.3.1 多级目录 树形目录结构，主目录称为根目录，数据文件称为树叶，其他目录均作为树的节点。为提高文件系统的灵活性，允许一个目录文件中的目录项机作为目录文件的FCB，又是数据文件的FCB，增加一位指示位即可。\n 路径名：从根目录到当前访问的文件 当前目录：用户当前访问的目录  绝对路径：唯一，从根目录开始 相对路径：不唯一    4.3 目录查询技术 4.3.1 线性检索法 根据目录结构顺序检索。\n4.3.1 Hash检索法 建立文件目录的Hash表，先将文件名变换为文件目录的索引值，再利用该索引值到目录中查找。\n 可能存在冲突：不同文件名相同Hash值 不支持模式匹配功能  5. 文件存储空间管理 5.1 空闲表法和空闲链表法 空闲表法属于连续分配方式，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表，每个空闲区对于一个空闲表项。 外存存储空间分配的基本单位是磁盘块，而不是字节。  空闲链表法属于离散分配方式，将所有空闲盘区组成一条空闲链，可分为空闲盘块链表和空闲盘区链表。\n5.2 位示图法 位示图利用二进制位来表示磁盘中盘块的使用情况，0表示空闲，1表示已分配。\n5.3 成组链接法 将空闲盘块分组，取前面的组存储空闲的盘块组，类似于多级目录的形式。最后一组的最后一个盘块用于结尾标志。\n6. 文件共享与文件保护 6.1 文件共享  基于索引节点的文件共享 基于符号链接的文件共享  6.2 文件保护 影响文件安全性的主要因素：\n 人为因素：人有意或无意行为导致的数据破坏或丢失 系统因素：系统出现异常导致的数据破坏或丢失，如磁盘出现故障或损坏 自然因素：数据随时间发生溢出或逐渐消失  可采取的措施：\n 存取控制机制防止人为因素造成的文件不安全性 磁盘容错技术防止磁盘故障所造成的文件不安全性 后备系统防止自然因素导致的文件不安全性  6.2.1 磁盘容错技术  磁盘镜像 磁盘双工 基于集群的容错：双机热备份，公用磁盘  7. 数据一致性控制 7.1 事务 事务时用于访问和修改各种数据项的程序单位，可以看做是一系列相关读写操作。\n事务记录：\n 事务名 数据项名 旧值 新值  7.2 检查点 引入检查点，对事务记录表中的事务记录的清理工作周期化，每各一段时间进行事务记录清理。\n7.3 并发控制 "},{"id":10,"href":"/pbasic/cn/cn-tcp/","title":"TCP协议","parent":"计算机网络","content":"  1. TCP 数据包 2. TCP 三次握手 3. TCP 四次挥手 4. TCP 如何保证传输可靠  4.1 ARQ 协议 4.2 滑动窗口和流量控制 4.3 拥塞控制  4.3.1 慢开始 4.3.2 拥塞控制 4.3.3 快重传和快恢复       1. TCP 数据包 TCP数据包主要由报头和数据（可选）组成，其报头长度在20B-60B，具体结构如下图：\n2. TCP 三次握手 TCP连接需要进行三次握手的目的是建立可靠的通信通道，需要确认发送方和接收方的收发都是正常的。\n 第一次握手：client什么都不能确认；server确认自己接收正常，client发送正常 第二次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常，client发送正常 第三次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常和发送正常，client接收正常和发送正常  3. TCP 四次挥手 TCP断开连接需要进行四次挥手，原因在于TCP建立的连接是双向通道，双方之间既可以向对方发送数据也可以接收对方发送的数据，相当于是建立了两条单向通道，当一方发起断开连接的请求并受到对方的确认后会进入半关闭状态，需要等到另一方发送完数据并发出释放连接的请求，释放请求确认后才能完全关闭TCP连接。\n4. TCP 如何保证传输可靠  应用数据被分割成TCP认为最适合传输的数据块 TCP对发送的每一个数据包进行编号，接收方对收到的数据包进行排序，然后就有序的数据包交给应用层处理 校验和：TCP计算报头和数据的校验和，并将其放在报头中一起发送，接收方对收到的数据进行校验，如果校验出错则会丢弃这个数据包并不确认收到这个数据包 TCP接收端会丢弃重复的数据 流量控制：TCP使用大小可变的滑动窗口协议来进行流量控制，每一方都有固定大小的缓存空间，双方只接受缓存空间内容纳的数据。 拥塞控制机制：当网络拥塞时，减少数据发送 ARQ协议：每发送一个分组就停止发送，等待对方发送确认。收到确认后再发送下一个分组。 超时重传：TCP每个发送一个段就启动一个计时器，当超过时间未收到确认就重传该段。  4.1 ARQ 协议 自动重传请求通过确认和超时两个机制在不可靠服务的基础上实现可靠的信息传输。\n  停止等待ARQ协议\n 基本原理：每发送完一个分组就停止发送，等待收到对方的收到确认后再发送下一个分组，超时未收到确认则重新发送此分组 接收方收到重复的分组直接丢弃并发送收到确认 确认丢失：确认信息在传输过程中丢失，发送方重发分组，接收方丢弃分组并发送确认 确认迟到：确认信息在传输过程中迟到，发送方重发分组，接收方丢弃分组并发送确认，发送方丢弃重复的确认信息    连续ARQ协议\n 发送窗口：发送发维持一个发送窗口，发送窗口内的分组都可以发送而不必等待对方的确认消息 累积确认：接收方对按序到达的最后一个分组发送确认，表明到这个分组为止所有分组都已正确收到 回退N：不能向发送方反映接收方已收到的所有分组信息，若丢失则需要重新发送丢失的分组    4.2 滑动窗口和流量控制 TCP利用滑动窗口来实现流量控制。流量控制是为了控制发送方的发送速率，保证接收方来得及接收。TCP报头的窗口字段可以用来控制发送方的窗口大小，设置为0则发送方不能发送数据。\n4.3 拥塞控制 拥塞控制是为了防止过多的数据注入到网络中，使得网络中的路由器或链路过载。拥塞控制是一个全局的过程，涉及网络中的所有主机，路由器，以及其他与降低网络传输有关的因素。\n流量控制是对点到点通信量的控制，解决的是端到端的问题，即抑制发送方的发送速率使得接收方来得及处理收到的数据。  为了进行拥塞控制，TCP 发送方要维护一个拥塞窗口(cwnd)的状态变量，拥塞窗口的大小取决于网络的拥塞程度，是动态变化的。发送方让自己的发送窗口为拥塞窗口和接收方的接收窗口中较小的一个， 即 发送窗口 = min(拥塞窗口，接收方接收窗口)。\nTCP 拥塞控制采用了以下四种算法，慢开始、拥塞避免、快重传和快恢复。\n4.3.1 慢开始 从小到大逐渐增大拥塞窗口，每经过一个传播轮次，cwnd加倍，cwnd = cwnd * 2。\n4.3.2 拥塞控制 让拥塞窗口逐渐增大，每经过一个往返时间RTT就将拥塞窗口加1，cwnd = cwnd + 1。\n4.3.3 快重传和快恢复 快重传和恢复（FRR）能迅速恢复丢失的数据包。一般情况下，如果数据包丢失了，TCP会启用计时器来要求传输暂停，暂停期间没有新的或复制的数据发送。\n有了快重传和快恢复，接收方在收到一个不按顺序的数据段，它会立刻给发送方发送一个重复确认，如果发送方连续收到3个重复确认，它会假定重复确认指出的数据段丢失了，并立即重传这些丢失的数据段。\n只有单独的数据包丢失时，快速重传和恢复能最有效地工作；当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。\n"},{"id":11,"href":"/pbasic/cn/cn-tcpudp/","title":"TCP与UDP协议的区别","parent":"计算机网络","content":"1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。\n2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。\n对比 "},{"id":12,"href":"/tags/Architecture/","title":"Architecture","parent":"Tags","content":""},{"id":13,"href":"/categories/","title":"Categories","parent":"Lin","content":""},{"id":14,"href":"/categories/CN/","title":"CN","parent":"Categories","content":""},{"id":15,"href":"/pbasic/cn/cn-arch/","title":"OSI与TCP/IP架构","parent":"计算机网络","content":"  1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。\n  物理层\n 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。\n   数据链路层\n 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。\n   网络层\n 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。\n   传输层\n 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。\n   会话层\n 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。\n   表示层\n 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。\n   应用层\n 主要是一些终端应用。如FTP、WEB等。\n   网络模型与物理设备\n实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。\n  网络接口层\n 指出主机必须通过某种协议与网络相连。\n   网络层\n 整个体系的关键部分，其功能是使主机可以把分组发往任何网络，并使分组独立的传向目标。这些分组可能经过不同的网络，到达顺序与发送顺序也可能不同。\n   传输层\n 使源端和目的端的机器上的对等实体可以进行会话。这一层定义了两个端到端的传输协议TCP和UDP。\n   应用层\n 包含所有上层协议，如SMTP, FTP, DNS, NNTP, HTTP, TELNET等。\n   3. 5层模型 5层模型中和OSI 7层模型和TCP/IP 4层模型的优点，既简洁又能将概念阐述清楚。\n"},{"id":16,"href":"/tags/","title":"Tags","parent":"Lin","content":""},{"id":17,"href":"/papers/mermaidtest/","title":"Mermaidtest","parent":"Paper Review","content":"Test Mermaid Pie   document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?}; B --|Yes| C[OK]; C -- D[Rethink]; D -- B; B ----|No| E[End];  "},{"id":18,"href":"/papers/TPDS/","title":"TPDS","parent":"Paper Review","content":"背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。\n目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。\n方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：\n 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值\n2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。\n3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。\n4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。\n评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器\nLeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9\n"},{"id":19,"href":"/bigdata/hadoop/overview/","title":"Overview","parent":"Hadoop","content":"1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。\n 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景\n 特别适合写一次，读多次的场景\n大规模数据 流数据（写一次，读多次）\n商用硬件\n Hadoop不适用的场景\n 低延时数据访问 大量小文件 频繁修改文件\n  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。\n简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。\nHDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。\n进程：NameNode, SecondaryNameNode, DataNode\n数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。\n读取策略：尽量读取距离最近的副本。\n安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。\nHDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2\n通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。\n健壮性\n 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。\n集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。\n NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等\nEditlog 文件存储在磁盘中，顺序追加记录 NameNode每次重启时将Editlog里的操作日志读到内存中回放即可恢复元数据。\nfsimage磁盘文件 JournalNodes集群 主节点（Active NameNode）每次修改元数据都会生成一条Editlog，该log既写入磁盘文件也写入JournalNodes集群， 然后SecondaryNameNode从JournalNodes集群拉取Editlog并应用到自己的文件目录树中，跟主节点保持一致， 每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode将完整的元数据写入到磁盘文件fsimage，即checkpoint操作， 然后将fsimage上传到主节点，并清空Editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据， 然后再将新的Editlog里的少量修改放回内存中即可。 BlockSize: 64/128MB, numReplicas: 3\n流水线复制 当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。\n文件存储空间回收 文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，HDFS会将这个文件重命名转移到.Trash目录，保存时间可配置。\n减少副本系数：当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。\nNameNode高并发  NameNode写入Editlog的第一条原则：保证每一条log都有一个全局顺序递增的transactionid，标识其先后顺序。 写入Editlog包含两步：1. 写入本地磁盘。 2. 通过网络传输给JournalNodes集群。 分段加锁机制和Double-Buffer机制 设置两个内存缓冲区：一个缓冲区用于写入Editlog，另一个缓冲区用于读取后写入磁盘和JournalNodes集群，必要时交换两个缓冲区。 多线程并发吞吐量优化 缓冲数据批量输入磁盘+网络优化  DataNode 定期向NameNode发送心跳信号和块状态报告。\n 心跳信号：DataNode节点正常工作 块状态报告：包含该DataNode上所有数据块的列表  3. MapReduce 一种编程模型，用于大规模数据执行可靠容错的并行计算。\nMapReduce作业通常将输入数据集分割成独立的块，这些块由map任务以完全并行的方式进行处理。框架对映射的输出进行排序，然后将其输入到reduce任务中。通常，作业的输入和输出都存储在文件系统中，该框架负责调度任务、监视任务并重新执行失败的任务。 通常，计算节点和存储节点是相同的，MapReduce框架和Hadoop分布式文件系统在同一组节点上运行，这种配置允许框架在数据已经存在的节点上有效地调度任务，从而产生跨集群的非常高的聚合带宽。 MapReduce框架由单个主资源管理器、每个集群节点一个工作节点管理器和每个应用程序的MRAppMaster组成。\n(input) \u0026lt;k1, v1\u0026gt; -\u0026gt; map -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; combine -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; reduce -\u0026gt; \u0026lt;k3, v3\u0026gt; (output)\nMapReduce的主要构件\n Input： 分布式计算程序的数据输入源 Job：用户的每一个计算请求为一个Job Task：有JOb拆分而来的执行单位，分为Map Task和Reduce Task Map：指定一个映射函数，将一组键值对映射成一组新的键值对 Reduce：指定一个归约函数，用来保证所有映射的键值对中的每一个共享相同的键组 Output：计算之后的结果。  4. YARN 基本思想：将集群资源管理和作业调度/监控划分为单独的进程。 ResourceManager（RM）：全局资源管理 NodeManager（NM）：每台机器上的框架代理，负责监控容器及资源使用情况（CPU、内存、磁盘、网络）并像RM汇报。 ApplicationMaster（AM）：每个应用一个，与RM协商资源，与NM一起执行和监视任务。\n"},{"id":20,"href":"/database/dbsql/","title":"数据库与SQL","parent":"数据库","content":"1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；\n数据库管理系统DBMS：用来管理数据库的计算机软件；\nSQL：Structured Query Language 即结构化查询语言;\n使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。\nDBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。\nSQL  SQL可分为DDL、DML和DCL。\n DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  "},{"id":21,"href":"/plang/scala/mvn-repo/","title":"Mvn Repo Modify","parent":"Scala","content":"可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.\n${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.\n\u0026lt;!-- path to the local repository default ${user.home}/.m2/repository --\u0026gt; \u0026lt;localRepository\u0026gt;/path/to/local/repo\u0026lt;/localRepository\u0026gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.\n\u0026lt;!-- \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;mirrorId\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;repositoryId\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Human readable name for this mirror\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://my.repository.com/repo/path\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; .... \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; --\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; "},{"id":22,"href":"/bigdata/","title":"BigData","parent":"Lin","content":" Get Home   Contribute   "},{"id":23,"href":"/bigdata/hadoop/","title":"Hadoop","parent":"BigData","content":""},{"id":24,"href":"/plang/java/","title":"Java","parent":"编程语言","content":""},{"id":25,"href":"/plang/java/basic/","title":"Java 基础","parent":"Java","content":""},{"id":26,"href":"/","title":"Lin","parent":"","content":"Motivation 转眼间就要研究生毕业了（虽然我是2022届），看着21届的伙伴们都拿到了Offer，我这想要实习的心也躁动起来啦！在写简历、准备面试的过程中，我发现之前学习的好多知识都不知道跑到记忆的哪个角落里去了，看什么都似曾相识却又陌生遥远。为了笔试/面试顺利，可以拿到一个好的Offer，现在得开始复习（学习）了，特此以Doc的形式记录下自己的学习过程。\nOutlines  编程基础  操作系统OS 计算机网络 数据结构和算法   BigData  Spark Hadoop   编程语言  Python Scala Java   机器学习ML 数据库  MySQL Redis    "},{"id":27,"href":"/ml/","title":"Machine Learning","parent":"Lin","content":" Get Home   Contribute   "},{"id":28,"href":"/database/mysql/","title":"MySQL","parent":"数据库","content":""},{"id":29,"href":"/papers/","title":"Paper Review","parent":"Lin","content":" Get Home   Contribute   "},{"id":30,"href":"/plang/python/","title":"Python","parent":"编程语言","content":""},{"id":31,"href":"/database/redis/","title":"Redis","parent":"数据库","content":""},{"id":32,"href":"/plang/scala/","title":"Scala","parent":"编程语言","content":""},{"id":33,"href":"/bigdata/spark/","title":"Spark","parent":"BigData","content":""},{"id":34,"href":"/pbasic/os/","title":"操作系统OS","parent":"编程基础","content":""},{"id":35,"href":"/database/","title":"数据库","parent":"Lin","content":" Get Home   Contribute   "},{"id":36,"href":"/pbasic/dsalg/","title":"数据结构与算法","parent":"编程基础","content":""},{"id":37,"href":"/pbasic/","title":"编程基础","parent":"Lin","content":" Get Home   Contribute   "},{"id":38,"href":"/plang/","title":"编程语言","parent":"Lin","content":" Get Home   Contribute   "},{"id":39,"href":"/pbasic/cn/","title":"计算机网络","parent":"编程基础","content":" Get Home   Contribute   "}]