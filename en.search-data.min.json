[{"id":0,"href":"/papers/TPDS/","title":"TPDS","parent":"Paper Review","content":"背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。\n目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。\n方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：\n 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值\n2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。\n3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。\n4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。\n评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器\nLeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9\n"},{"id":1,"href":"/hadoop/overview/","title":"Hadoop Overview","parent":"Hadoop","content":"1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。\n 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景\n 特别适合写一次，读多次的场景\n大规模数据 流数据（写一次，读多次）\n商用硬件\n Hadoop不适用的场景\n 低延时数据访问 大量小文件 频繁修改文件\n  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。\n简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。\nHDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。\n进程：NameNode, SecondaryNameNode, DataNode\n数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。\n读取策略：尽量读取距离最近的副本。\n安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。\nHDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2\n通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。\n健壮性\n 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。\n集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。\n NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等\nEditlog 文件存储在磁盘中，顺序追加记录 NameNode每次重启时将Editlog里的操作日志读到内存中回放即可恢复元数据。\nfsimage磁盘文件 JournalNodes集群 主节点（Active NameNode）每次修改元数据都会生成一条Editlog，该log既写入磁盘文件也写入JournalNodes集群， 然后SecondaryNameNode从JournalNodes集群拉取Editlog并应用到自己的文件目录树中，跟主节点保持一致， 每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode将完整的元数据写入到磁盘文件fsimage，即checkpoint操作， 然后将fsimage上传到主节点，并清空Editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据， 然后再将新的Editlog里的少量修改放回内存中即可。 BlockSize: 64/128MB, numReplicas: 3\n流水线复制 当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。\n文件存储空间回收 文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，HDFS会将这个文件重命名转移到.Trash目录，保存时间可配置。\n减少副本系数：当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。\nNameNode高并发  NameNode写入Editlog的第一条原则：保证每一条log都有一个全局顺序递增的transactionid，标识其先后顺序。 写入Editlog包含两步：1. 写入本地磁盘。 2. 通过网络传输给JournalNodes集群。 分段加锁机制和Double-Buffer机制 设置两个内存缓冲区：一个缓冲区用于写入Editlog，另一个缓冲区用于读取后写入磁盘和JournalNodes集群，必要时交换两个缓冲区。 多线程并发吞吐量优化 缓冲数据批量输入磁盘+网络优化  DataNode 定期向NameNode发送心跳信号和块状态报告。\n 心跳信号：DataNode节点正常工作 块状态报告：包含该DataNode上所有数据块的列表  3. MapReduce 一种编程模型，用于大规模数据执行可靠容错的并行计算。\nMapReduce作业通常将输入数据集分割成独立的块，这些块由map任务以完全并行的方式进行处理。框架对映射的输出进行排序，然后将其输入到reduce任务中。通常，作业的输入和输出都存储在文件系统中，该框架负责调度任务、监视任务并重新执行失败的任务。 通常，计算节点和存储节点是相同的，MapReduce框架和Hadoop分布式文件系统在同一组节点上运行，这种配置允许框架在数据已经存在的节点上有效地调度任务，从而产生跨集群的非常高的聚合带宽。 MapReduce框架由单个主资源管理器、每个集群节点一个工作节点管理器和每个应用程序的MRAppMaster组成。\n(input) \u0026lt;k1, v1\u0026gt; -\u0026gt; map -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; combine -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; reduce -\u0026gt; \u0026lt;k3, v3\u0026gt; (output)\nMapReduce的主要构件\n Input： 分布式计算程序的数据输入源 Job：用户的每一个计算请求为一个Job Task：有JOb拆分而来的执行单位，分为Map Task和Reduce Task Map：指定一个映射函数，将一组键值对映射成一组新的键值对 Reduce：指定一个归约函数，用来保证所有映射的键值对中的每一个共享相同的键组 Output：计算之后的结果。  4. YARN 基本思想：将集群资源管理和作业调度/监控划分为单独的进程。 ResourceManager（RM）：全局资源管理 NodeManager（NM）：每台机器上的框架代理，负责监控容器及资源使用情况（CPU、内存、磁盘、网络）并像RM汇报。 ApplicationMaster（AM）：每个应用一个，与RM协商资源，与NM一起执行和监视任务。\n"},{"id":2,"href":"/SQL/dbsql/","title":"DBSQL","parent":"SQL","content":"1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；\n数据库管理系统DBMS：用来管理数据库的计算机软件；\nSQL：Structured Query Language 即结构化查询语言;\n使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。\nDBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。\nSQL  SQL可分为DDL、DML和DCL。\n DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  "},{"id":3,"href":"/scala/mvn-repo/","title":"Mvn Repo Modify","parent":"Scala","content":"可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.\n${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.\n\u0026lt;!-- path to the local repository default ${user.home}/.m2/repository --\u0026gt; \u0026lt;localRepository\u0026gt;/path/to/local/repo\u0026lt;/localRepository\u0026gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.\n\u0026lt;!-- \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;mirrorId\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;repositoryId\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Human readable name for this mirror\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://my.repository.com/repo/path\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; .... \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; --\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; "},{"id":4,"href":"/categories/","title":"Categories","parent":"Main","content":""},{"id":5,"href":"/hadoop/","title":"Hadoop","parent":"Main","content":""},{"id":6,"href":"/","title":"Main","parent":"","content":"Geekdoc is a simple Hugo theme for documentations. It is intentionally designed as a fast and lean theme and may not fit the requirements of complex projects. If a more feature-complete theme is required there are a lot of got alternatives out there. You can find a demo and the full documentation at https://geekdocs.de.\nFeatures  Clean and simple design Light and mobile-friendly Easy customization Zero initial configuration Handy shortcodes  "},{"id":7,"href":"/papers/","title":"Paper Review","parent":"Main","content":""},{"id":8,"href":"/scala/","title":"Scala","parent":"Main","content":""},{"id":9,"href":"/SQL/","title":"SQL","parent":"Main","content":""},{"id":10,"href":"/tags/","title":"Tags","parent":"Main","content":""}]