[{"id":0,"href":"/bigdata/spark/cache-checkpoint/","title":"Cache与Checkpoint","parent":"Spark","content":"  1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。\n1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：\n   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：\n 尽量保持RDD的默认存储级别（MEMORY_ONLY），这是CPU效率最高的选项，允许RDD上的操作尽可能快地运行。 如果不是，可尝试使用MEMORY_ONLY_SER并选择一个快的序列化库，以使对象的空间效率更高，但访问速度仍然相当快，仅适用于Java和Scala API。 尽量不要将RDD缓存到磁盘，除非用于计算RDD非常消耗资源或者可以过滤掉大量数据。否则，重新计算分区的速度可能与从磁盘读取分区的速度一样快。 如果需要快速的故障恢复能力，使用复制的存储级别(XXX_2)。所有存储级别都通过重新计算丢失的数据来提供完全的容错能力，但是复制的存储级别具有冗余备份，一般情况下不需要等待重新计算丢失的分区。  1.2 Cache细节 通常情况下，被频繁地重复使用RDD需要进行Cache以提高效率。因为用户只能与Driver程序打交道，因此Cache一个RDD需要用户在编程的时候显式的调用rdd.cache() 或者rdd.persist(storagelevel)进行缓存。 用户只能cache程序代码中显式存在的rdd，对于那些Transformation中\u0026quot;隐式\u0026quot;生成的RDD，如ShuffledRDD，MapPartitionsRDD是不能被cache的。    缓存RDD Partition\nSpark Cache RDD发生在第一次计算RDD时，在将要计算RDD Partition时（而不是已经计算得到一个record时），就去判断Partition是否需要被Cache，如果需要Cache的话，就先将Partition计算出来，然后缓存到内存。\n  取cached RDD Partition\n下次计算(一般是同一application 的下一个 job 计算)时如果用到 cached RDD，task 会直接去 blockManager 的 memoryStore 中读取。具体地讲，当要计算某个 rdd 中的 partition 时候(通过调用 rdd.iterator())会先去 blockManager 里 面查找是否已经被 cache 了，如果 partition 被 cache 在本地，就直接使用 blockManager.getLocal() 去本地 memoryStore 里读取。如果该 partition 被其他节点上 blockManager cache 了，会通过 blockManager.getRemote() 去其他节点上读取，读 取过程如下图。\n  获取 cached partitions 的存储位置 partition 被 cache 后其所在节点上的 blockManager 会通知 driver 上的 blockMangerMasterActor 说某 rdd 的 partition 已经被我 cache 了，这个信息会存储在 blockMangerMasterActor 的 blockLocations: HashMap中。等到 task 执行需要 cached rdd 的时候，会调用 blockManagerMaster 的 getLocations(blockId) 去询问某 partition 的存储位置，这个询问信息会发到 driver 那里，driver 查询 blockLocations 获得位 置信息并将信息送回。\n  读取其他节点上的 cached partition task 得到 cached partition 的位置信息后，将 GetBlock(blockId) 的请求通过 connectionManager 发送到目标节点。目标节点收到请求后从本地 blockManager 那里的 memoryStore 读取 cached partition，最后发送回来。\n    2. Checkpoint机制 Spark中的Checkpoint机制是设计来对RDD进行持久化存储的（除非手动删除，否则它将永久存在于文件系统中，一般是缓存到HDFS中），因此可以跨Application使用，Cache机制中缓存到内存或磁盘中的RDD在application退出时就被清理掉了。  对于需要很长运算时间或运算量很大的rdd，computing chain过长或依赖其他rdd很多的rdd，可以选择对其进行Checkpoint。用户需要显式的调用rdd.checkpoint来对某个rdd设置检查点，sparkcontext.setCheckpointDir(dir)设置检查点目录。\n2.1 Checkpoint细节 不同于Cache 机制是每计算出一个要 cache 的 partition 就直接将其 cache 到内存中，Checkpoint 机制是等到 job 结束后另外启动专门的 job 来完成 checkpoint 。也就是说需要 checkpoint 的 RDD 会被计算两次。因此，在使用 rdd.checkpoint() 的时候，建议加上 rdd.cache()，这样第二次运行的 job 就不用再去计算该 rdd ，而是直接读取 cache 后写磁盘。\nRDD 需要经过 [ Initialized --\u0026gt; marked for checkpointing --\u0026gt; checkpointing in progress --\u0026gt; checkpointed ] 这几个阶段才能被 checkpoin。\n  Initialized 首先 driver program 需要使用 rdd.checkpoint() 去设定需要 checkpoint的rdd，检查点路径用sc.setCheckpointDir(dir)设置（一般设置HDFS目录），设定后该 rdd 就接受RDDCheckpointData 管理。\n  marked for checkpointing 初始化后RDDCheckpointData 会将管理的 rdd 标记为 MarkedForCheckpoint。\n  checkpointing in progress 每个 job 运行结束后Spark会调用 finalRdd.doCheckpoint()，finalRdd 会顺着 computing chain 回溯扫描，碰到要 checkpoint 的 RDD 就将其标记为 CheckpointingInProgress，然后将写磁盘(比如写 HDFS)需要的配置文件 (如 core-site.xml 等)broadcast 到其他 worker 节点上的 blockManager。完成以后，启动一个 job 来完成 checkpoint(使 用 rdd.context.runJob(rdd, CheckpointRDD.writeToFile(path.toString, broadcastedConf)))。\n  checkpointed job 完成 checkpoint 后，将该 rdd 的 dependency 全部清掉，并设定该 rdd 状态为 checkpointed。然后为该 rdd 强加一个依赖，设置该 rdd 的 parent rdd 为 CheckpointRDD，该 CheckpointRDD 负责以后读取在文件系统上的 checkpoint 文件，生成该 rdd 的 partition。\n  当调用 rdd.iterator() 去计算该 rdd 的 partition 的时候，会调用 computeOrReadCheckpoint(split: Partition) 去查看该 rdd 是 否被 checkpoint 过了，如果是，就调用该 rdd 的 parent rdd 的 iterator() 也就是 CheckpointRDD.iterator()，CheckpointRDD 负责读取文件系统上的文件，生成该 rdd 的 partition。\n3. Cache与Checkpoint的异同 Cache\n Cache机制中RDD Partition被缓存到内存或磁盘（或内存+磁盘），数据由blockManager管理。 Application退出后Cache在磁盘/内存中的RDD Partition会被清空。 Cache不会破坏RDD的Lineage，即RDD Partition丢失后可以根据计算链重新计算。   Checkpoint\n Checkpoint机制中RDD Partition被持久化存储到文件系统（一般是HDFS）。 Application退出后Checkpoint的数据依旧存在，可以被其他应用使用。 Checkpoint会将RDD的依赖关系完全清除，并强加一个Parent RDD CheckpointRDD，需要时只能用CheckpointRDD从文件系统中读取数据，如果存储在文件系统上的数据被蓄意破坏，则需要重新启动该Application才能恢复计算。    Reference：\n RDD Programming Guide Apache Spark 设计与实现  "},{"id":1,"href":"/pbasic/os/os-fs/","title":"文件管理","parent":"操作系统OS","content":"  1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.1 文件控制块和索引节点 4.2 文件目录结构  4.2.1 单级目录结构 4.2.2 两级目录 4.3.1 多级目录   4.3 目录查询技术  4.3.1 线性检索法 4.3.1 Hash检索法     5. 文件存储空间管理  5.1 空闲表法和空闲链表法 5.2 位示图法 5.3 成组链接法   6. 文件共享与文件保护  6.1 文件共享 6.2 文件保护  6.2.1 磁盘容错技术     7. 数据一致性控制  7.1 事务 7.2 检查点 7.3 并发控制     1. 文件和文件系统 文件系统的管理功能是通过将其所管理的程序和数据组织成一系列文件来实现的。\n1.1 文件层次关系 1.1.1 数据项 在文件系统中，数据项是最低级的数据组织形式，包括基本数据项和组合数据项。基本数据项是用于描述一个对象的某种属性的字符集，是数据组织中可以命名的最小逻辑数据单位，即原子数据，又称为数据元素或字段。组合数据项是有若干基本数据项组成的，简称组项。\n1.1.2 记录 记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。\n1.1.3 文件 文件是指由创建者所定义的、具有文件名的一组相关记录的集合，可分为有结构文件（若干相关记录组成的文件）和无结构文件（文件被看做字符流）。文件具有自己的属性：文件类型、文件长度、文件的物理位置、文件的创建时间等。\n1.2 文件类型  普通文件：由ASCII码或二进制码组成的字符文件。 目录文件：由文件目录组成，用来管理和实现文件系统功能的系统文件，通过目录文件可对其他文件的信息进行检索。 特殊文件：特指系统中的各类I/O设备，可分为块设备文件和字符设备文件。  1.3 文件系统模型 文件系统模型可分为三个层次：对象及其属性；对对象进行操纵和管理的软件集合；文件系统接口。\n对象及其属性\n文件管理系统管理的对象有：\n 文件：文件管理的直接对象 目录：方便对文件的存取和索引，每个目录项中必须含有文件名及该文件所在的物理地址（指针） 磁盘存储空间：文件和目录必定占用存储空间   对对象操纵和管理的软件集合\n文件系统的核心部分，主要功能包括：\n 文件存储空间的管理 文件目录的管理 文件逻辑地址和物理地址的转换机制 文件读写的管理 文件共享和保护   文件系统接口\n 命令接口 程序接口：系统调用   1.4 文件操作  创建文件：分配必要的外存空间，建立目录项 删除文件：从目录中查找对应的目录项并使之成为空项，回收该文件占用的存储空间 读文件 写文件 截断文件 设置文件读/写位置  2. 文件的逻辑结构 文件逻辑结构是用户视角的文件组织形式，它独立于文件的物理特性（存储方式）。文件逻辑结构可分为记录式文件（有结构文件）和流式文件（字符流）。\n2.1 记录式文件 2.1.1 顺序文件 由一系列记录按照某种顺序排列所形成的文件，其中的记录通常是定长记录。\n 文件记录可以按照写入时间排序（串结构），也可以按照关键字排序（顺序结构）。 对串结构文件查找每次必须从头开始 对顺序结构文件查找可以使用如折半查找、插值查找等算法 删除或增加记录需要移动其他记录  2.1.2 索引文件 当记录的长度可变时，通常建立一张索引表，并为每个记录设置一个表项。\n 顺序存取和直接实现方便 当记录较多时索引表需要较多额外存储资源  2.1.3 索引顺序文件 为文件建立一张索引表，为每组记录的第一个记录设置一个表项，组内组织为顺序结构，\n 组间索引，组内顺序  2.2 直接文件和哈希文件 2.2.1 直接文件 根据记录的键值对线性表或链表进行检索，已找到指定记录的物理地址，即记录键值本身觉得记录的物理地址。\n2.2.2 哈希文件 利用Hash函数将记录键值转换为相应记录的地址，通过目录表可实现文件存储空间的动态分配。\n3. 外存分配方式 3.1 连续分配方式 连续分配要求为每个文件分配一组相邻的盘块。一组盘块的地址定义了磁盘上的一段线性地址。\n 顺序访问容易、速度快 要求连续的存储空间，必须事先知道文件的长度，容易产生外部碎片  3.2 链接分配 通过每个盘块上的链接指针将同属于一个文件的多个离散盘块链接成一个链表，离散分配，消除外部碎片，提高外存利用率，增删改查方便。\n 隐式链接：每个盘块保护文件开始、文件结束盘块和下一个盘块的指针。 显式链接：将盘块指针显式的放在内存的一张链接表（文件分配表，FAT）中。 为提高效率，可以将连续的盘块组合为簇，以簇为分配单位。   FAT需要占用较大的内存空间 不能支持高效的直接存取  3.3 索引分配 3.3.1 单级索引分配 将每个文件对应的盘块号集中存放，为每个文件分配一个索引块（表），再把分配给该文件的所有盘块号都记录在索引块中。\n 支持直接访问 不会产生外部碎片 对小文件需要块索引利用率极低  3.3.2 多级索引分配 一级索引表 -\u0026gt; 二级索引表 -\u0026gt; 三级索引表 -\u0026gt; \u0026hellip; -\u0026gt; 盘块号\n3.3.3 混合索引分配 将多种索引分配方式相结合而形成的一种分配方式。\n 直接地址 一次间接地址 多次间接地址  4. 目录管理 对目录管理的基本要求：\n 按名存取 提高目录的检索速度 文件共享 运行文件重名  4.1 文件控制块和索引节点 文件控制块FCB：文件与文件控制块一一对应，一个文件控制块就是一个文件目录项。文件控制块的有序集合称为文件目录，通常一个文件目录可以被看做是一个文件，称为目录文件。\nFCB通常包含三类信息：基本信息、存取控制信息和使用信息。\n 基本信息：文件名，文件物理位置，文件逻辑结构（流式文件or记录式文件），文件物理结构（顺序文件、链接文件、索引文件） 存取控制信息：文件的存取权限（user, group, other） 使用信息：文件建立日期，修改日期，当前使用信息等。  索引节点（i节点）：将文件名和文件描述信息分开，使文件描述信息单独形成一个称为索引节点的数据结构。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i节点的指针所构成。\n 磁盘索引节点：存储在磁盘上的所有节点，主要包括文件标识符、文件类型、存取权限、物理地址等。 内存索引节点：存放于内存中的所有节点，当文件打开时将磁盘索引节点拷贝到内存中，增加索引节点编号，状态，访问计数，链接指针等信息。  4.2 文件目录结构 4.2.1 单级目录结构 整个文件系统仅建立一张目录表。缺点：查找速度慢、不允许重名、不便于文件共享。\n4.2.2 两级目录 系统建立一个主文件目录（MFD），并为每个用户单独建立一个用户文件目录(UFD)。两级目录提高了目录检索速度，不同的用户文件可以重名，可实现不同用户访问共享文件。\n4.3.1 多级目录 树形目录结构，主目录称为根目录，数据文件称为树叶，其他目录均作为树的节点。为提高文件系统的灵活性，允许一个目录文件中的目录项机作为目录文件的FCB，又是数据文件的FCB，增加一位指示位即可。\n 路径名：从根目录到当前访问的文件 当前目录：用户当前访问的目录  绝对路径：唯一，从根目录开始 相对路径：不唯一    4.3 目录查询技术 4.3.1 线性检索法 根据目录结构顺序检索。\n4.3.1 Hash检索法 建立文件目录的Hash表，先将文件名变换为文件目录的索引值，再利用该索引值到目录中查找。\n 可能存在冲突：不同文件名相同Hash值 不支持模式匹配功能  5. 文件存储空间管理 5.1 空闲表法和空闲链表法 空闲表法属于连续分配方式，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表，每个空闲区对于一个空闲表项。 外存存储空间分配的基本单位是磁盘块，而不是字节。  空闲链表法属于离散分配方式，将所有空闲盘区组成一条空闲链，可分为空闲盘块链表和空闲盘区链表。\n5.2 位示图法 位示图利用二进制位来表示磁盘中盘块的使用情况，0表示空闲，1表示已分配。\n5.3 成组链接法 将空闲盘块分组，取前面的组存储空闲的盘块组，类似于多级目录的形式。最后一组的最后一个盘块用于结尾标志。\n6. 文件共享与文件保护 6.1 文件共享  基于索引节点的文件共享 基于符号链接的文件共享  6.2 文件保护 影响文件安全性的主要因素：\n 人为因素：人有意或无意行为导致的数据破坏或丢失 系统因素：系统出现异常导致的数据破坏或丢失，如磁盘出现故障或损坏 自然因素：数据随时间发生溢出或逐渐消失  可采取的措施：\n 存取控制机制防止人为因素造成的文件不安全性 磁盘容错技术防止磁盘故障所造成的文件不安全性 后备系统防止自然因素导致的文件不安全性  6.2.1 磁盘容错技术  磁盘镜像 磁盘双工 基于集群的容错：双机热备份，公用磁盘  7. 数据一致性控制 7.1 事务 事务时用于访问和修改各种数据项的程序单位，可以看做是一系列相关读写操作。\n事务记录：\n 事务名 数据项名 旧值 新值  7.2 检查点 引入检查点，对事务记录表中的事务记录的清理工作周期化，每各一段时间进行事务记录清理。\n7.3 并发控制 "},{"id":2,"href":"/pbasic/cn/cn-tcp/","title":"TCP协议","parent":"计算机网络","content":"1. TCP数据包 "},{"id":3,"href":"/pbasic/cn/cn-tcpudp/","title":"TCP与UDP协议的区别","parent":"计算机网络","content":"1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。\n2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。\n对比 "},{"id":4,"href":"/tags/Architecture/","title":"Architecture","parent":"Tags","content":""},{"id":5,"href":"/categories/","title":"Categories","parent":"Lin","content":""},{"id":6,"href":"/categories/CN/","title":"CN","parent":"Categories","content":""},{"id":7,"href":"/pbasic/cn/cn-arch/","title":"OSI与TCP/IP架构","parent":"计算机网络","content":"  1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。\n  物理层\n 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。\n   数据链路层\n 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。\n   网络层\n 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。\n   传输层\n 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。\n   会话层\n 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。\n   表示层\n 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。\n   应用层\n 主要是一些终端应用。如FTP、WEB等。\n   网络模型与物理设备\n实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。\n  网络接口层\n 指出主机必须通过某种协议与网络相连。\n   网络层\n 整个体系的关键部分，其功能是使主机可以把分组发往任何网络，并使分组独立的传向目标。这些分组可能经过不同的网络，到达顺序与发送顺序也可能不同。\n   传输层\n 使源端和目的端的机器上的对等实体可以进行会话。这一层定义了两个端到端的传输协议TCP和UDP。\n   应用层\n 包含所有上层协议，如SMTP, FTP, DNS, NNTP, HTTP, TELNET等。\n   3. 5层模型 5层模型中和OSI 7层模型和TCP/IP 4层模型的优点，既简洁又能将概念阐述清楚。\n"},{"id":8,"href":"/tags/","title":"Tags","parent":"Lin","content":""},{"id":9,"href":"/papers/mermaidtest/","title":"Mermaidtest","parent":"Paper Review","content":"Test Mermaid Pie   document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?}; B --|Yes| C[OK]; C -- D[Rethink]; D -- B; B ----|No| E[End];  "},{"id":10,"href":"/papers/TPDS/","title":"TPDS","parent":"Paper Review","content":"背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。\n目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。\n方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：\n 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值\n2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。\n3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。\n4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。\n评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器\nLeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9\n"},{"id":11,"href":"/bigdata/hadoop/overview/","title":"Overview","parent":"Hadoop","content":"1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。\n 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景\n 特别适合写一次，读多次的场景\n大规模数据 流数据（写一次，读多次）\n商用硬件\n Hadoop不适用的场景\n 低延时数据访问 大量小文件 频繁修改文件\n  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。\n简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。\nHDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。\n进程：NameNode, SecondaryNameNode, DataNode\n数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。\n读取策略：尽量读取距离最近的副本。\n安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。\nHDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2\n通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。\n健壮性\n 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。\n集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。\n NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等\nEditlog 文件存储在磁盘中，顺序追加记录 NameNode每次重启时将Editlog里的操作日志读到内存中回放即可恢复元数据。\nfsimage磁盘文件 JournalNodes集群 主节点（Active NameNode）每次修改元数据都会生成一条Editlog，该log既写入磁盘文件也写入JournalNodes集群， 然后SecondaryNameNode从JournalNodes集群拉取Editlog并应用到自己的文件目录树中，跟主节点保持一致， 每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode将完整的元数据写入到磁盘文件fsimage，即checkpoint操作， 然后将fsimage上传到主节点，并清空Editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据， 然后再将新的Editlog里的少量修改放回内存中即可。 BlockSize: 64/128MB, numReplicas: 3\n流水线复制 当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。\n文件存储空间回收 文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，HDFS会将这个文件重命名转移到.Trash目录，保存时间可配置。\n减少副本系数：当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。\nNameNode高并发  NameNode写入Editlog的第一条原则：保证每一条log都有一个全局顺序递增的transactionid，标识其先后顺序。 写入Editlog包含两步：1. 写入本地磁盘。 2. 通过网络传输给JournalNodes集群。 分段加锁机制和Double-Buffer机制 设置两个内存缓冲区：一个缓冲区用于写入Editlog，另一个缓冲区用于读取后写入磁盘和JournalNodes集群，必要时交换两个缓冲区。 多线程并发吞吐量优化 缓冲数据批量输入磁盘+网络优化  DataNode 定期向NameNode发送心跳信号和块状态报告。\n 心跳信号：DataNode节点正常工作 块状态报告：包含该DataNode上所有数据块的列表  3. MapReduce 一种编程模型，用于大规模数据执行可靠容错的并行计算。\nMapReduce作业通常将输入数据集分割成独立的块，这些块由map任务以完全并行的方式进行处理。框架对映射的输出进行排序，然后将其输入到reduce任务中。通常，作业的输入和输出都存储在文件系统中，该框架负责调度任务、监视任务并重新执行失败的任务。 通常，计算节点和存储节点是相同的，MapReduce框架和Hadoop分布式文件系统在同一组节点上运行，这种配置允许框架在数据已经存在的节点上有效地调度任务，从而产生跨集群的非常高的聚合带宽。 MapReduce框架由单个主资源管理器、每个集群节点一个工作节点管理器和每个应用程序的MRAppMaster组成。\n(input) \u0026lt;k1, v1\u0026gt; -\u0026gt; map -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; combine -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; reduce -\u0026gt; \u0026lt;k3, v3\u0026gt; (output)\nMapReduce的主要构件\n Input： 分布式计算程序的数据输入源 Job：用户的每一个计算请求为一个Job Task：有JOb拆分而来的执行单位，分为Map Task和Reduce Task Map：指定一个映射函数，将一组键值对映射成一组新的键值对 Reduce：指定一个归约函数，用来保证所有映射的键值对中的每一个共享相同的键组 Output：计算之后的结果。  4. YARN 基本思想：将集群资源管理和作业调度/监控划分为单独的进程。 ResourceManager（RM）：全局资源管理 NodeManager（NM）：每台机器上的框架代理，负责监控容器及资源使用情况（CPU、内存、磁盘、网络）并像RM汇报。 ApplicationMaster（AM）：每个应用一个，与RM协商资源，与NM一起执行和监视任务。\n"},{"id":12,"href":"/database/dbsql/","title":"数据库与SQL","parent":"数据库","content":"1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；\n数据库管理系统DBMS：用来管理数据库的计算机软件；\nSQL：Structured Query Language 即结构化查询语言;\n使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。\nDBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。\nSQL  SQL可分为DDL、DML和DCL。\n DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  "},{"id":13,"href":"/plang/scala/mvn-repo/","title":"Mvn Repo Modify","parent":"Scala","content":"可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.\n${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.\n\u0026lt;!-- path to the local repository default ${user.home}/.m2/repository --\u0026gt; \u0026lt;localRepository\u0026gt;/path/to/local/repo\u0026lt;/localRepository\u0026gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.\n\u0026lt;!-- \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;mirrorId\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;repositoryId\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Human readable name for this mirror\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://my.repository.com/repo/path\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; .... \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; --\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; "},{"id":14,"href":"/bigdata/","title":"BigData","parent":"Lin","content":" Get Home   Contribute   "},{"id":15,"href":"/bigdata/hadoop/","title":"Hadoop","parent":"BigData","content":""},{"id":16,"href":"/plang/java/","title":"Java","parent":"编程语言","content":""},{"id":17,"href":"/","title":"Lin","parent":"","content":"Motivation 转眼间就要研究生毕业了（虽然我是2022届），看着21届的伙伴们都拿到了Offer，我这想要实习的心也躁动起来啦！在写简历、准备面试的过程中，我发现之前学习的好多知识都不知道跑到记忆的哪个角落里去了，看什么都似曾相识却又陌生遥远。为了笔试/面试顺利，可以拿到一个好的Offer，现在得开始复习（学习）了，特此以Doc的形式记录下自己的学习过程。\nOutlines  编程基础  操作系统OS 计算机网络 数据结构和算法   BigData  Spark Hadoop   编程语言  Python Scala Java   机器学习ML 数据库  MySQL Redis    "},{"id":18,"href":"/ml/","title":"Machine Learning","parent":"Lin","content":" Get Home   Contribute   "},{"id":19,"href":"/database/mysql/","title":"MySQL","parent":"数据库","content":""},{"id":20,"href":"/papers/","title":"Paper Review","parent":"Lin","content":" Get Home   Contribute   "},{"id":21,"href":"/plang/python/","title":"Python","parent":"编程语言","content":""},{"id":22,"href":"/database/redis/","title":"Redis","parent":"数据库","content":""},{"id":23,"href":"/plang/scala/","title":"Scala","parent":"编程语言","content":""},{"id":24,"href":"/bigdata/spark/","title":"Spark","parent":"BigData","content":""},{"id":25,"href":"/pbasic/os/","title":"操作系统OS","parent":"编程基础","content":""},{"id":26,"href":"/database/","title":"数据库","parent":"Lin","content":" Get Home   Contribute   "},{"id":27,"href":"/pbasic/dsalg/","title":"数据结构与算法","parent":"编程基础","content":""},{"id":28,"href":"/pbasic/","title":"编程基础","parent":"Lin","content":" Get Home   Contribute   "},{"id":29,"href":"/plang/","title":"编程语言","parent":"Lin","content":" Get Home   Contribute   "},{"id":30,"href":"/pbasic/cn/","title":"计算机网络","parent":"编程基础","content":" Get Home   Contribute   "}]