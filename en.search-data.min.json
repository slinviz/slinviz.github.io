[{"id":0,"href":"/plang/java/basic/compare/","title":"定义比较","parent":"Java 基础","content":"Comparable vs. Comparator     java.lang.Comparable java.util.Comparator     类型 接口 接口   使用时机 定义类时实现 类定义完成后，重新定义比较器   功能 实现类的 自然序 可定义多种比较方式   覆盖方法 public int compareTo(T o) public int compare(T o1, T o2)   实现次数 只能实现一次（类定义时） 可定义多个比较器类    Comparable 接口 java.lang.Comparable 在类定义的时候实现，可用于设定对象的默认排序（自然序），需要覆写public int compareTo(T o)方法。\nimport java.lang.Comparable; import java.util.Comparator; import java.util.List; import java.util.ArrayList; import java.util.Collections; public class Person implements Comparable\u0026lt;Person\u0026gt; { String name; int age; public Person(String name, int age){ super(); this.name = name; this.age = age; } @Override public String toString(){ return \u0026#34;Person \u0026lt; \u0026#34; + this.name + \u0026#34; , \u0026#34; + this.age +\u0026#34; \u0026gt;\u0026#34;; } @Override public int compareTo(Person other){ return name.compareTo(other.name); } public static void main(String[] args){ List\u0026lt;Person\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Person p1 = new Person(\u0026#34;Tom\u0026#34;, 12); Person p2 = new Person(\u0026#34;Tim\u0026#34;, 34); Person p3 = new Person(\u0026#34;Sally\u0026#34;, 15); list.add(p1); list.add(p2); list.add(p3); System.out.println(\u0026#34;java.lang.Comparable --------------\u0026#34;); Collections.sort(list); for(Person elem: list){ System.out.println(elem); } } } 例如，运行上面的代码输出：\njava.lang.Comparable -------------- Person \u0026lt; Sally , 15 \u0026gt; Person \u0026lt; Tim , 34 \u0026gt; Person \u0026lt; Tom , 12 \u0026gt; Comparator 接口 java.util.Comparator 通常用于无法修改类定义的代码，而为该类实现一个或多个比较器，需要重新定义一个比较器类并覆写 public int compare(T o1, To2) 方法。\n显示定义比较器类  class PersonComparator implements Comparator\u0026lt;Person\u0026gt; { @Override public int compare(Person p1, Person p2){ return Integer.compare(p1.age, p2.age); } } ... // using Comparator  System.out.println(\u0026#34;java.util.Comparator ==============\u0026#34;); Collections.sort(list, new PersonComparator()); for(Person elem: list){ System.out.println(elem); } 定义该比较器后重新比较，可得\njava.util.Comparator ============== Person \u0026lt; Tom , 12 \u0026gt; Person \u0026lt; Sally , 15 \u0026gt; Person \u0026lt; Tim , 34 \u0026gt;   匿名匿名比较器类  // using Comparator  System.out.println(\u0026#34;java.util.Comparator2 ==============\u0026#34;); Collections.sort(list, new Comparator\u0026lt;Person\u0026gt;(){ @Override public int compare(Person p1, Person p2){ return p2.age - p1.age; } }); for(Person elem: list){ System.out.println(elem); } 定义该匿名比较器后重新比较，可得\njava.util.Comparator2 ============== Person \u0026lt; Tim , 34 \u0026gt; Person \u0026lt; Sally , 15 \u0026gt; Person \u0026lt; Tom , 12 \u0026gt;    "},{"id":1,"href":"/plang/java/jvm/","title":"JVM","parent":"Java","content":"  类加载机制 类加载过程  1. 加载 2. 验证 3. 准备 4. 解析 5. 初始化   类加载器  1. 类与类加载器 2. 双亲委派模型  双亲委派模型的工作过程   3. 破坏双亲委派模型   Reference   类加载机制  虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。\n 类的生命周期包括：加载、验证、准备、解析、初始化、使用和卸载，其中验证、准备、和解析统称为连接。\n加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的。解析阶段可以在初始化阶段之后（java运行时绑定），阶段间通常是相互交叉地混合式进行的。  必须立即对类进行初始化的5中情况：\n 遇到new, getstatic, putstatic, invokestatic 这个4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。即使用new关键字实例化对象、读取或者设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。 使用java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 初始化一个类的时候，如果发现其父类还没进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户指定要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 使用 JDK 1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。   对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。如下代码只会输出：SuperClass init!  class SuperClass { static { System.out.println(\u0026#34;SuperClass init!\u0026#34;); } public static int value = 123; } class SubClass extends SuperClass { static { System.out.println(\u0026#34;SubClass init!\u0026#34;); } } public class NotInitialization { public static void main(String[] args){ System.out.println(SubClass.value); } } 通过数组定义来引用类，不会触发此类的初始化。如下代码不会输出SuperClass init!。  public class NotInitialization { public static void main(String[] args){ SuperClass[] sca = new SuperClass[10]; } } 常量（final关键字修饰）在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 接口初始化时并不要求其父接口全部都初始化完成，只有在真正用到父接口的时候（如引用接口中定义的常量）才会初始化。   类加载过程 1. 加载  通过一个类的权限定名来获取定义此类的二进制字节流； 将这个字节流所代表的的静态存储结构转换为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。  数组本身不通过类加载器创建，它是由java虚拟机直接创建的。但数组类的元素类型最终需要靠类加载器去创建。  2. 验证 目的：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n 文件格式验证 元数据验证：对字节码描述的信息进行语义分析，保证其描述的信息符合java语言规范的要求 字节码验证：数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证  3. 准备 正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。此时内存分配仅包括类变量（被static修饰的变量），而不包括实例变量。另外这里的初始值通常情况下是数据类型的零值，特殊情况（被final修饰）则初始化为指定的值。\n4. 解析 虚拟机将常量池内的符号引用替换为直接引用的过程。\n 符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可，与虚拟机实现的内存布局无关。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是某个能间接定位到目标的句柄，与虚拟机实现的内存布局有关。  5. 初始化 真正开始执行类中定义的Java程序代码（或者说字节码）。初始化是执行类构造器\u0026lt; clinit \u0026gt;() 方法的过程。 \u0026lt; clinit \u0026gt;() 是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}）中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定，静态语句块中只能访问（读取值）定义在静态语句块之前的变量，在前面的静态语句块可以对定义在该静态语句块后面的类变量赋值（设置值），但不能访问。\npublic class Test{ static { i = 0; // 可以赋值后面定义的类变量  System.out.println(i); // 错误，不能访问定义在其之后的类变量  } static int i = 1; }  虚拟机会保证在子类的\u0026lt; clinit \u0026gt;() 方法执行之前，父类的\u0026lt; clinit \u0026gt;() 方法已经执行完毕。因此第一个被执行的\u0026lt; clinit \u0026gt;() 是java.lang.Object 的。 对于接口，执行\u0026lt; clinit \u0026gt;() 不需要先执行父接口的\u0026lt; clinit \u0026gt;() ，只有当父接口中定义的变量使用时，父接口才会初始化。 对实现接口的类来说，初始化时也可以不执行接口的\u0026lt; clinit \u0026gt;() 。 虚拟机保证类的\u0026lt; clinit \u0026gt;() 在多线程环境中被正确的加锁、同步。  类加载器 1. 类与类加载器 实现“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作的代码模块称为类加载器。\nJava中任意一个类都需要由加载它的类加载器和类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器都拥有一个独立的类命名空间。\n2. 双亲委派模型  启动类加载器：负责加载$JAVA_HOME/lib or -Xbootclasspath 中被虚拟机标识的类库到虚拟机内存中。启动类加载器无法被 Java程序直接引用。 扩展类加载器：由sun.misc.Launcher$ExtClassLoader 实现，负责加载$JAVA_HOME/lib/ext or java.ext.dirs 路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器：由sun.misc.Launcher$AppClassLoader 实现，负责加载用户类路径ClassPath上所指定的类库，开发者可以直接使用这个类加载器。一般情况下默认的类加载器就是应用程序类加载器。  除顶层的启动类加载器外，其余类加载器都应当有自己的父类加载器，父子关系一般通过组合来实现。\n双亲委派模型的工作过程  如果一个类加载器收到了类加载请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此最终所有的加载请求最终都会传到顶层的启动类加载器。 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需加载的类）时，子加载器才会尝试自己去加载。  protected synchronized Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // 首先，检查请求的类是否已经被加载过了  Class c = findLoadedClass(name); if(c == null){ try{ if(parent != null){ c = parent.loadClass(name, false); }else{ c = findBootstrapClassOrNull(name); } }catch (ClassNotFoundException e){ // 如果父类加载器抛出 ClassNotFountException  // 说明父类加载器无法完成加载请求  } if(c == null){ // 在父类加载器无法加载时再调用本身的findClass方法来加载  c = findClass(name); } } if(resolve){ resolveClass(c); } return c; } 3. 破坏双亲委派模型  JDK 1.2 之后不提倡用户去覆写loadClass()方法，而是将类加载逻辑写到findClass()中。 基础类调用用户代码，典型服务 JNDI。 线程上下文类加载器（Thread Context ClassLoader）。JNDI 服务使用这个线程上下文类加载器去加载所需要的JNDI的接口提供者（SPI）代码，也就是父类加载器请求子类加载器去完成类加载动作。Java 中所有涉及SPI的加载动作都采用这个加载方式，例如JNDI, JDBC, JCE, JAXB, JBI等。 用户对程序动态性的追求：代码热替换（HotSwap），模块热部署（Hot Deployment）等。 OSGI规范，每个程序模块（Bundle）都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。  OSGI环境下，类加载器不再是双亲委派模型中的树状结构，而是更加复杂的网状结构。\nReference  深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）  "},{"id":2,"href":"/bigdata/spark/storage/","title":"[转载]Apache Spark 内存管理详解","parent":"Spark","content":"本文是对原文Apache Spark 内存管理详解的转载并做了部分排版修改，后续会加入一些自己的理解和补充。   0. 序言 1. 堆内和堆外内存规划  1.1 堆内内存 1.2 堆外内存 1.3 内存管理接口   2. 内存空间分配  2.1 静态内存管理 2.2 统一内存管理   3. 存储内存管理  3.1 RDD 的持久化机制 3.2 RDD 缓存的过程 3.3 淘汰和落盘   4. 执行内存管理  4.1 多任务间内存分配 4.2 Shuffle 的内存占用   结束语 参考资源 Reference   0. 序言 Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文旨在梳理出 Spark 内存管理的脉络，抛砖引玉，引出读者对这个话题的深入探讨。本文中阐述的原理基于 Spark 2.1 版本，阅读本文需要读者有一定的 Spark 和 Java 基础，了解 RDD、Shuffle、JVM 等相关概念。\n在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能[1]。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。\n1. 堆内和堆外内存规划 作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。\n图 1 . 堆内和堆外内存示意图\n1.1 堆内内存 堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。\nSpark 对堆内内存的管理是一种逻辑上的”规划式”的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前 记录 这些内存，我们来看其具体流程：\n 申请内存 ：  Spark 在代码中 new 一个对象实例 JVM 从堆内内存分配空间，创建对象并返回对象引用 Spark 保存该对象的引用，记录该对象占用的内存   释放内存 ：  Spark 记录该对象释放的内存，删除该对象的引用 等待 JVM 的垃圾回收机制释放该对象占用的堆内内存    我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程——反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。\n对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期[2]。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。\n虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。\n1.2 堆外内存 为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现[3]），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。\n在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。\n1.3 内存管理接口 Spark 为存储内存和执行内存的管理提供了统一的接口——MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存:\n清单 1 . 内存管理接口的主要方法\n//申请存储内存 def acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean //申请展开内存 def acquireUnrollMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean //申请执行内存 def acquireExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode): Long //释放存储内存 def releaseStorageMemory(numBytes: Long, memoryMode: MemoryMode): Unit //释放执行内存 def releaseExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode): Unit //释放展开内存 def releaseUnrollMemory(numBytes: Long, memoryMode: MemoryMode): Unit 我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。\nMemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（ Unified Memory Manager ）方式，1.6 之前采用的静态管理（ Static Memory Manager ）方式仍被保留，可通过配置 spark.memory.useLegacyMode 参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。\n2. 内存空间分配 2.1 静态内存管理 在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置，堆内内存的分配如图 2 所示：\n图 2 . 静态内存管理图示——堆内 可以看到，可用的堆内内存的大小需要按照下面的方式计算：\n清单 2 . 可用堆内内存空间\n可用的存储内存 = systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction 可用的执行内存 = systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction 其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。\n堆外的空间分配较为简单，只有存储内存和执行内存，如图 3 所示。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。\n图 3 . 静态内存管理图示——堆外 静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成”一半海水，一半火焰”的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。\n2.2 统一内存管理 Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域，如图 4 和图 5 所示\n图 4 . 统一内存管理图示——堆内\n图 5 . 统一内存管理图示——堆外 其中最重要的优化在于动态占用机制，其规则如下：\n 设定基本的存储内存和执行内存区域（spark.storage.storageFraction 参数），该设定确定了双方各自拥有的空间的范围 双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block） 执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后”归还”借用的空间 存储内存的空间被对方占用后，无法让对方”归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂[4]  图 6 . 动态占用机制图示\n凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的[5]。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。\n3. 存储内存管理 3.1 RDD 的持久化机制 弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。\nTask 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。 堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理 （存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。\nRDD 的持久化由 Spark 的 Storage[7] 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。\n图 7 . Storage 模块示意图 在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别 ，而存储级别是以下 5 个变量的组合：\n清单 3 . 存储级别\nclass StorageLevel private( private var _useDisk: Boolean, //磁盘 private var _useMemory: Boolean, //这里其实是指堆内内存 private var _useOffHeap: Boolean, //堆外内存 private var _deserialized: Boolean, //是否为非序列化 private var _replication: Int = 1 //副本个数 ) 通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式：\n存储位置：磁盘／堆内内存／堆外内存。如 MEMORY_AND_DISK 是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP 则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。\n 存储形式：Block 缓存到存储内存后，是否为非序列化的形式。如 MEMORY_ONLY 是非序列化方式存储，OFF_HEAP 是序列化方式存储。 副本数量：大于 1 时需要远程冗余备份到其他节点。如 DISK_ONLY_2 需要远程备份 1 个副本。  3.2 RDD 缓存的过程 RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（ [Iterator(http://www.scala-lang.org/docu/files/collections-api/collections_43.html)] ）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项(Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。\nRDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。 将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开”（Unroll） 。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例[6]，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。\n因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图 8 所示。\n图 8. Spark Unroll 示意图 在图 3 和图 5 中可以看到，在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。\n3.3 淘汰和落盘 由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。\n存储内存的淘汰规则为：\n 被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存 新旧 Block 不能属于同一个 RDD，避免循环淘汰 旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题 遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。 落盘的流程则比较简单，如果其存储级别符合_useDisk 为 true 的条件，再根据其_deserialized 判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。  4. 执行内存管理 4.1 多任务间内存分配 Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。\n4.2 Shuffle 的内存占用 执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：\n Shuffle Write  若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。 若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。   Shuffle Read  在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。 如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。     在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。\nShuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划[9]，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。\nTungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：\n 页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。 页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。 有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升[10]。  Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。\n结束语 Spark 的内存管理是一套复杂的机制，且 Spark 的版本更新比较快，笔者水平有限，难免有叙述不清、错误的地方，若读者有好的建议和更深的理解，还望不吝赐教。\n参考资源  Spark Cluster Mode Overview Spark Sort Based Shuffle 内存分析 Spark OFF_HEAP Unified Memory Management in Spark 1.6 Tuning Spark: Garbage Collection Tuning Spark Architecture 《Spark 技术内幕：深入解析 Spark 内核架构于实现原理》第 8 章 Storage 模块详解 Spark Sort Based Shuffle 内存分析 Project Tungsten: Bringing Apache Spark Closer to Bare Metal Spark Tungsten-sort Based Shuffle 分析 探索 Spark Tungsten 的秘密 Spark Task 内存管理（on-heap\u0026amp;off-heap）  Reference  Apache Spark 内存管理详解  "},{"id":3,"href":"/bigdata/hadoop/hdfs/","title":"HDFS","parent":"Hadoop","content":"  HDFS 架构  1. NameNode  1.1 fsimage 和 editlog   2. SecondaryNameNode 3. DataNode 4. 数据流水线复制 5. 安全模式 6. 文件存储空间回收 7. HDFS 的健壮性   NameNode 高并发保障技术  1. 双缓存（Double-Buffer）机制 2. 分段加锁机制  2.1 加锁 2.2 多线程并发 2.3 批量数据刷磁盘和网络优化     部署 Hadoop 集群  0. 安装和配置环境变量 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 2. 启动集群 2.1 格式化 NameNode 2.2 启动 Hadoop 集群 3. 创建目录并存储文件   Reference   HDFS 架构 HDFS 是 Hadoop 的分布式文件系统，非常适合存储大文件和写入一次读取多次的文件，具有高吞吐量、高容错等特性，支持扩展到上千台商业服务器上。目前许多大数据处理平台（例如 Spark，Hive，Hbase等）都将 HDFS 作为底层的文件存储。\nHDFS 采用 Master/Slave 架构，主要由单个 NameNode（Master）和多个 DataNode（Slave）组成，为了提高 NameNode 的效率，还引入了 SecondaryNameNode。\nHDFS 具有以下特点：\n 核心架构的目标：实现错误检测和快速、自动的恢复（硬件错误是常态不是异常）； 简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题； HDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。  1. NameNode  NameNode 负责管理整个HDFS集群的元数据和执行有关文件系统命名空间的操作：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等。 NameNode 负责监控 DataNode 的状态。DataNode 定期向 NameNode 发送心跳和块状态抱够。 NameNode 还负责接收来自 Client 的各种请求，并作出相应的应答。  HDFS 的文件系统命名空间 的层次结构与大多数文件系统类似 (如 Linux)， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。NameNode 负责维护文件系统名称空间，记录对名称空间或其属性的任何更改。  HDFS 的元数据存储在 NameManger 的 内存中，同时持久化保存在本地磁盘文件fsimage（命名空间镜像文件）和 editlog（操作日志文件）中。  HDFS 把文件分成固定大小的块 Block，并根据冗余系数（默认replication 为3）存储到集群中。数据块副本存放策略是机架感知：大多数情况下副本系数为3，HDFS 的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。读取策略是尽量读取距离近的副本。\nHadoop 1.x : blocksize = 64M Hadoop 2.x : blocksize = 128M 1.1 fsimage 和 editlog fsimage 是内存命名空间元数据在外存的镜像文件。editlog 文件则记录着用户多文件的各自操作记录，当客户端对 HDFS 中的文件进行新增或者修改等操作是，操作记录首先被记入 editlog 文件中，当操作成功后将相应的元数据更新到内存中，以防止发生意外导致丢失内存中的数据。editlog 只能顺序追加记录，fsimage和editlog两个文件结合可以构造出完整的内存数据.NameNode 每次重启时将editlog里的操作日志读到内存中回放即可恢复元数据。\n2. SecondaryNameNode 为了保证当 NameNode 出现故障之后不丢失数据或能快速恢复 HDFS 的元数据，引入了 SecondaryNameNode，它主要负责定期合并 fsimage 和 editlog ，维护和 NameNode 相同的元数据。必要时候可以作为 NameNode 的热备份。\n在高可用（HA）情况下，主节点（Active NameNode）每次修改元数据都会生成一条 editlog 记录，该日志记录既写入磁盘文件（NameNode 本地的editlog 文件）也写入JournalNodes集群，然后 SecondaryNameNode 从 JournalNodes 集群拉取操作日志并应用到自己的文件目录树中，跟主节点保持一致，每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode 将完整的元数据写入到自己的磁盘文件fsimage，即checkpoint操作，之后再将 fsimage 上传到主节点（Active NameNode），并清空editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据，然后再将新的editlog里的少量修改操作记录放回内存中即可。\n3. DataNode  DataNode 是 HDFS 中实际存储和读写数据块的节点，一个 Block 会在多个 DataNode 中进行冗余备份，而一个 DataNode 对于一个块最多只包含一个备份。 DataNode 还负责提供来自客户端的读写请求，执行块的创建，删除等操作。 DataNode 会定期向 NameNode 发送心跳信号和块状态报告。  心跳信号（Heartbeat）：表明当前 DataNode 节点正常工作 块状态报告（Block Report）：包含该DataNode上所有数据块的列表   DataNode 之间也会相互通信，执行数据块的复制任务，同时在客户端执行写操作的时候，DataNode 之间需要相互配置，以保证写操作的一致性。 DataNode 还会接收和执行来自 NameNode 的命令，如删除某些数据块或把数据块复制到另一个 DataNode。  4. 数据流水线复制 当Client 向 HDFS 文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从 NameNode 获取一个 Datanode 的列表用于存放副本； 然后客户端开始向第一个 Datanode 传输数据，第一个 Datanode 一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个 Datanode 节点； 第二个Datanode 也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个 Datanode。 最后，第三个 Datanode 接收数据并存储在本地。   因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个 Datanode 复制到下一个。\n通信协议\nHDFS 的通信协议都是建立在TCP/IP协议之上，Client 与 NameNode 之间使用ClientProtocol，DataNode 与 NameNode 之间使用DatanodeProtocal。\n 5. 安全模式 处于安全模式的 NameNode 是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数，当 NameNode 检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（参数可配置）的数据块被 NameNode 检测确认是安全之后（加上一个额外的30秒等待时间），NameNode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他 DataNode上。\n6. 文件存储空间回收  文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从 HDFS 中删除。实际上，HDFS 会将这个文件重命名转移到.Trash 目录，保存时间可配置，默认是6个小时。 减少副本系数：当一个文件的副本系数被减小后，NameNode 会选择过剩的副本删除。下次心跳检测时会将该信息传递给 DataNode。DataNode遂即移除相应的数据块，释放存储空间。  7. HDFS 的健壮性  磁盘数据错误，心跳检测和重新复制：当 DataNode 宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制； 集群均衡：自动将数据移动到其它空闲的 DataNode 上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据； 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个 HDFS 命名空间下，客户端获取和进行检验，如果不对则读取其它副本； 元数据磁盘错误恢复：支持维护多个fsimage 和editlog，修改同步到副本上。  NameNode 高并发保障技术 1. 双缓存（Double-Buffer）机制 NameNode 在写入editlog的过程中如果只对同一块内存缓冲，同时存在大量写入和读出是不可能的，因为不能并发读写同一块共享内存数据！因此 HDFS 在读写editlog时采取了 Double-Buffer 双缓冲机制，将一块内存缓冲分成两个部分：\n 一部分用于写入操作日志 另一部分用于读取后写入磁盘和 JournalNodes 集群  2. 分段加锁机制 2.1 加锁  首先各个线程依次第一次获取锁，生成顺序递增的txid，然后将edit log写入内存双缓冲的区域1，接着就立马第一次释放锁; 趁着这个空隙，后面的线程就可以再次立马第一次获取锁，然后立即写自己的edit log到内存缓冲；写内存那么快，可能才耗时几十微妙，接着就立马第一次释放锁； 接着各个线程竞争第二次获取锁，有线程获取到锁之后，就判断是否有其他线程在写磁盘和网络？如果没有，那么这个幸运儿线程直接交换双缓冲的区域1和区域2，接着第二次释放锁。这个过程相当快速，内存里判断几个条件，耗时不了几微秒； 现在内存缓冲区已经被交换了，后面的线程可以立马快速的依次获取锁，然后将edit log写入内存缓冲的区域2，而内存缓冲区域1中的数据被锁定了，不能写；  2.2 多线程并发 接着，之前那个幸运儿线程将内存缓冲的区域1中的数据读取出来（此时没线程写区域1了，都在写区域2），将里面的edti log都写入磁盘文件，以及通过网络写入JournalNodes集群。这个过程可是很耗时的！但是做过优化了，在写磁盘和网络的过程中，是不持有锁的！因此后面的线程可以快速的第一次获取锁后，立马写入内存缓冲的区域2，然后释放锁。这个时候大量的线程都可以快速的写入内存，没有阻塞和卡顿！  2.3 批量数据刷磁盘和网络优化 在幸运儿线程把数据写磁盘和网络的过程中，排在后面的大量线程快速的第一次获取锁，写内存缓冲区域2，释放锁，之后，这些线程第二次获取到锁后会发现有人在写磁盘，所以会立即释放锁，然后休眠1秒后再次尝试获取锁。此时大量的线程并发过来的话，都会在这里快速的第二次获取锁，然后发现有人在写磁盘和网络，快速的释放锁，休眠。这个过程不会长时间的阻塞其他线程！因为都会快速的释放锁，所以后面的线程还是可以迅速的第一次获取锁后写内存缓冲！而且这时，一定会有很多线程发现，好像之前那个幸运儿线程的txid是排在自己之后的，那么肯定就把自己的edit log从缓冲里写入磁盘和网络了。这些线程甚至都不会休眠等待，直接就会返回后去干别的事情了，压根儿不会卡在这里。 然后那个幸运儿线程写完磁盘和网络之后，就会唤醒之前休眠的那些线程。那些线程会依次排队再第二次获取锁后进入判断，发现没有线程在写磁盘和网络了！然后就会再判断，有没有排在自己之后的线程已经将自己的edti log写入磁盘和网络了。如果有的话，就直接返回了。没有的话，那么就成为第二个幸运儿线程，交换两块缓冲区，区域1和区域2交换一下。然后释放锁，自己开始将区域2的数据写入磁盘和网络。这个时候后面的线程如果要写edits log的，还是可以第一次获取锁后立马写内存缓冲再释放锁，以此类推。  部署 Hadoop 集群 由于机器有限，这里将 Hadoop 的主要组件 HDFS、MapReduce 和 YARN 都部署到了同一台机器上，并且重点关注启动 HDFS 并存储文件到 HDFS 的过程。\n0. 安装和配置环境变量 从 Apache Hadoop Releases 页面下载相应的 Hadoop 文件包，这里下载的是hadoop-2.7.7。下载完成之后解压并配置相应的环境变量 HADOOP_HOME 并将 ${HADOOP_HOME}/bin 将入到系统搜索路径 PATH 中。注意，JDK 等也需要配置。\n$ tar -zxf hadoop-2.7.7.tar.gz -C /usr/local 1. 修改/增加 HDFS/MapReduce/YARN 相关配置 修改 ${HADOOP_HOME}/etc/hadoop 目录下的 Hadoop 相关配置文件，主要包括 core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml 等。注意，集群的节点在 ${HADOOP_HOME}/etc/hadoop/slaves 中配置。\n在多机分布式模式下，还需要将配置文件分发到各个节点。\ncore-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/usr/local/hadoop/tmp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   hdfs-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   mapred-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.framework.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;yarn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   yarn-site.xml  \u0026lt;configuration\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.hostname\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;localhost\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    2. 启动集群 2.1 格式化 NameNode 在启动集群之前，建议先在 NameNode上执行 hdfs namenode -format 命令格式化 HDFS 文件系统。格式化完毕后可以看到在 ${hadoop.tmp.dir} 目录下生成了 dfs/name 目录，其中包括 fsimage 和 seen_txid （transactionid）。\n$ hdfs namenode -format # format the DFS filesystem # The contents in ${hadoop.tmp.dir} after above command . └── tmp └── dfs └── name └── current ├── VERSION ├── fsimage_0000000000000000000 ├── fsimage_0000000000000000000.md5 └── seen_txid 2.2 启动 Hadoop 集群 格式化完成后即可运行 ${HADOOP_HOME}/sbin/start-all.sh 脚本一次性启动集群的所有组件，包括 HDFS 的 NameNode, SecondaryNameNode, DataNode 和 YARN 的 ResourceManager, NodeManager 进程。\n# Start HDFS MapReduce and YARN $ ${HADOOP_HOME}/sbin/start-all.sh # Process $ jps 70689 SecondaryNameNode 70803 ResourceManager 70582 DataNode 70889 NodeManager 70495 NameNode 71870 Jps 因为这里将所有组件都部署到了同一台机器下，所有可以在${hadoop.tmp.dir} 目录下看到为 NameNode, SecondaryNameNode, DataNode 创建的目录。\n NameNode : name SecondaryNameNode : namesecondary DataNode : data  nm-local-dir 目录是 NodeManager 创建的目录，用于缓存用户程序和相应的配置文件。\n对于 NameNode, SecondaryNameNode ，它们主要是存储和维护 HDFS 的元数据 fsimage 和操作日志 editlog，而 DataNode 主要是存储实际的数据块 Block，此处暂时还未向文件系统写入数据，因此暂时没有对应的数据块文件。\n3. 创建目录并存储文件 经过以上几步后集群就以及正常启动了，下面下 HDFS 中写入一个文件。首先，创建一个 data 目录，然后将 test.txt 上传到文件系统中，最后使用 hdfs dfs cat data/test.txt 查看文件的内容。\n$ hdfs dfs -mkdir -p data $ hdfs dfs -put test.txt data/ $ hdfs dfs -cat data/test.txt 从浏览器中查看 HDFS 的相关信息，如集群节点的状态等，也可以直接在浏览器中浏览文件系统的内容，如下，虽然只存了很小的一个文件（33B），但 HDFS 还是分配了一个 128M 的数据块。\n再次查看 ${hadoop.tmp.dir} 目录， 可以发现 dfs/data 目录的子目录中已经写入了数据块文件，它们存储的就是刚才上传到 HDFS 中的 test.txt 的实际数据。因为这里设置的 replication 为1，并且test.txt也只需要一个数据块即可存储，所以这里只能看到一个数据块文件（和保存它的元数据信息文件）。\nReference  https://juejin.cn/post/6844903992066048014 https://zhuanlan.zhihu.com/p/37219709 https://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-HDFS.md https://www.cnblogs.com/52mm/p/p13.html https://juejin.cn/post/6844903713966915598  "},{"id":4,"href":"/plang/scala/basic/","title":"Scala 基本数据类型和流程控制","parent":"Scala","content":"  Scala 基本数据类型   Scala 基本数据类型 Byte, Short, Int, Long, Float, Double, Char, Boolean, String, RichInt, RichDouble, StringOps\n格式化字符串\nprintf(\u0026#34;Hello, %s! You are %d years old.%n\u0026#34;, name, age) print(f\u0026#34;Hello, ${name}! In six months, you\u0026#39;ll be ${age+0.5}%7.2f years old.%n\u0026#34;) print(s\u0026#34;$$$price\u0026#34;) println(raw\u0026#34;\\n is a new line\u0026#34;) ; // \\n is a new line  在 Scala 中，变量或函数的类型总是写在变量或函数名称的后面。 在 Scala 中， 仅当同一行代码中存在多条语句时才需要用分号;隔开。 Scala 中的操作符实际上是方法，Java中不能对操作符进行重载，但Scala允许定义操作符。   Scala中的类通常都有一个伴生对象，里面定义的方法类似于java中的静态方法。\n"},{"id":5,"href":"/bigdata/hadoop/yarn/","title":"YARN","parent":"Hadoop","content":"集群资源管理者-YARN YARN（Yet Another Resource Negotiator）是 Hadoop 2.0 引入的集群资源管理系统。用户可以将多种服务框架部署在YARN上，由YARN进行统一的管理和资源分配。\nYARN 框架 ResourceManager-RM RM 是整个集群资源的主要管理者和协调者，RM 负责对用户提交的应用程序分配资源。资源分配根据应用程序优先级，队列容量，ACLs，数据位置等信息做出决策，然后以共享的、安全的、多租户的方式制定策略，调度集群资源。\nNodeManager-NM NM 负责管理当前节点的管理者，负责节点资源监视和节点健康跟踪，它还负责当前节点内所有容器的生命周期管理。具体如下：\n NM 启动时向 RM 注册并定时发送心跳信息，等待 RM 的命令； 维护Container生命周期，监控container的资源使用情况； 管理任务运行时的相关依赖，根据ApplicationMaster的需要，在启动container之前将程序及其依赖拷贝到本地。  ApplicationMaster-AM 在用户提交一个Application时，YARN 会启动一个轻量级进程ApplicationMaster， 负责协调来自RM的资源，并通过NM监视容器内资源的使用情况，同时负责任务的监控与容错。具体如下：\n 根据Application运行状态动态决定资源需求； 向RM申请资源并监控申请的资源的使用情况； 跟踪任务进度和状态，报告资源使用情况和应用的进度信息； 复杂任务的容错。  Container Container是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、网络、磁盘等。当AM向RM申请资源时，RM为AM返回的资源使用Container表示的。YARN会为每个任务分配一个 Container，该任务只能使用该Container中描述的资源。AM可以在Container中运行任何类型的任务。如MapReduce中的Map Task和Reduce Task。\nYARN 工作原理 概述  Client通过 RM 向YARN提交Application； RM 选择一个 NM， 然后启动一个 Container 运行 ApplicationMaster； ApplicationMaster 根据实际需求向 RM 申请更多的 Container 资源，（如果任务很小，AM 会选择在自己的 JVM 中运行任务）； AM 根据获取到的 Container 资源执行分布式任务计算。  详述 "},{"id":6,"href":"/pbasic/os/os/","title":"操作系统","parent":"操作系统OS","content":"1. 什么是操作系统？  操作系统是管理计算机硬件和软件资源的程序，是计算机的基石。 OS本质上是配置在计算机硬件上的第一层软件，用于管理计算机硬件和软件资源。 OS做为用户和计算机硬件系统之间的接口，屏蔽了硬件层的复杂性。操作系统就像是硬件使用的负责人，统筹着各种相关事项。 操作系统内核是操作系统的核心部分，它负责系统的内存管理，硬件设备管理，文件系统管理和应用程序管理。内核是连接应用程序和硬件之间的桥梁，决定着系统的性能和稳定性。  2. 什么是系统调用？ 根据进程访问资源的特点，可以将进程在系统上的运行分为两个级别：\n 用户态：用户态运行的进程可以直接读取用户程序的数据 系统态：系统态运行的进程几乎可以访问计算机的任何资源，不受限制  一般情况下用户程序都是运行在用户态，当需要调用操作系统的系统态级别的子功能的时候就需要系统调用了。也就是说用户程序中凡是与系统态级别的资源的操作，如文件管理、进程控制、内存管理等，就需要通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。\n系统调用按功能大致可分为：\n 设备管理：完成设备的请求或释放，以及设备的启动等功能。 文件管理：完成文件读、写、创建和删除等功能。 内存管理：完成内存的分配，回收，虚拟地址转换等功能。 进程控制：完成进程的创建，撤销，阻塞以及唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。  "},{"id":7,"href":"/pbasic/os/os-process/","title":"进程和线程","parent":"操作系统OS","content":"  1. 基本概念 2. 进程和线程的区别 3. 进程的状态 4. 进程间通信方式  4.1 管道/匿名管道 4.2 有名管道 4.3 信号 4.4 消息队列 4.5 信号量 4.6 共享内存 4.7 套接字   5. 线程间同步 6. 进程调度算法  6.1 先到先服务（FCFS）调度算法 6.2 短作业优先（SJF）调度算法 6.3 时间片轮转（RR）调度算法 6.4 多级反馈队列调度算法 6.5 优先级调度算法   Reference:   1. 基本概念   进程（Process）\n进程是一个动态的概念，通常指的是进程实体 = PCB + 程序段 + 数据段。PCB主要包括程序计数器，程序上下文，程序资源（文件、信号等）等。\n  线程（Thread）\n线程实际上是进程内部的一条执行序列（执行流），执行序列是指一组有序指令加数据的集合，执行序列是以函数为单位的。线程是一种轻量级的进程。线程一定是在进程内部进行活动的，并且每一个线程都拥有一个独立的计数器、进程栈和一组进程寄存器。强调一点，进程调度的对象是线程，而不是进程。\n  协程（Coroutine） 协程是一种用户态的轻量级线程，调度由用户控制，拥有自己独立的寄存器上下文和栈。协程的切换效率比线程还要高，协程和线程的区别包括：\n   线程是由CPU调度，而协程是由用户调度 线程存在安全问题，协程比线程较安全 线程使用同步机制，协程使用异步机制  管程（Monitor）\n管程是一种程序设计语言结构部分，是代表共享资源的数据结构，以及对该共享数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块。管程被请求和释放 资源的进程所调用。本质上，管程是一种抽象数据结构（ADT）。  2. 进程和线程的区别  进程是系统资源分配的最小单位，线程是CPU调度的最小单位 一个进程可以包含多个线程，一个线程只能属于一个进程 进程创建的资源消耗比线程创建的资源消耗大很多 进程切换的效率比线程切换的效率低很多 系统中的进程相互独立，而同一个进程内的线程只有自己的程序计数器和栈区，其他空间共享 进程间通信必须借助外部手段，同一个进程内线程间通信可以借助共享空间 进程间不存在安全问题，同一个进程内的线程间存在安全问题  3. 进程的状态 一般情况下，将进程分为以下5中状态：\n 创建（New）: 进程正在被创建，尚未到达就绪转态 就绪（Ready）：准备运行状态，除了处理器以外的所有资源均已获得，一旦得到处理器资源即可运行 运行（Running）：进程正在处理器上运行 阻塞（waiting）：进程正在等待某一事件而暂停或等待某一资源可用或等待I/O操作完成。即使处理器空闲，进程也不能运行 结束（Terminated）：进程正在从系统中消失，可能是正常结束也可能是其他原因中断退出  4. 进程间通信方式 系统中的进程相互独立，通信需要借助外部手段。大概有7种方式实现进程间通信：\n4.1 管道/匿名管道 匿名管道\n4.2 有名管道 4.3 信号 4.4 消息队列 4.5 信号量 4.6 共享内存 4.7 套接字 5. 线程间同步 6. 进程调度算法 6.1 先到先服务（FCFS）调度算法 6.2 短作业优先（SJF）调度算法 6.3 时间片轮转（RR）调度算法 6.4 多级反馈队列调度算法 6.5 优先级调度算法 Reference:  https://blog.csdn.net/love10_1314/article/details/97282627 《计算机操作系统》 汤小丹，第三版 进程间通信IPC (InterProcess Communication)  "},{"id":8,"href":"/plang/java/basic/object/","title":"Object 类","parent":"Java 基础","content":"java.lang.Object 是Java类的最顶层，也是Java中唯一一个没有父类的类。其他的类要么显式的声明继承自其他类，要么隐式的继承Object类。  Java 中Object类不做为接口的父类。因为Java中的接口不能从java中的类继承，至少不能直接继承。 明确指明某个类继承自Object，即class SomeClass extends Object后，该类不能再继承其他类，Java仅支持单继承。   Object类中定义的方法如下：\n  document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object{ +equales() boolean +hashCode() int +toString() String +getClass() Class~~ #finalize() void #clone() Object +notify() void +notifyAll() void +wait() void +wait(long timeout) void +wait(long timeout, int nanos) void }  equals与==  ==：作用是判断两个对象的地址是否相等，即这两个对象是否是同一个对象。对于基本类型，其比较的是值，对于对象比较的是地址。 equales方法：判断两个对象是否相等，有两种情况：  类没有覆写该方法，调用该方法时等价于使用== 类覆写了equales()方法，一般覆写后是判断两个对象的内容是否相等。    覆写equales()方法时一定要覆写hashCode()方法\nhashCode() 方法返回该对象的哈希码给调用者。\n 如果两个对象相等，那么它们的哈希码一定是相等的 反过来，两个对象具有相同的哈希码，这两个对象却不一定是相等的 hashCode() 默认行为是对堆上的对象产生独特值，如果没有覆写，那么这两个对象无论如何都不会相等 同时覆写这两个方法可以保证对象的功能兼容于Hash集合   Reference:\n Do Interfaces really inherit the Object class in Java? Java：Object类详解  "},{"id":9,"href":"/plang/java/basic/exceptions/","title":"Java Error和Exception","parent":"Java 基础","content":"Java中如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。此时JVM会抛出一个封装了错误信息的对象，方法会立刻退出同时不返回任何值。\nJava 中的“异常”可以分为Error（错误）和Exception（异常）两大类，它们都是Throwable的子类。其中：\n Error： Java运行时系统的内部错误或资源耗尽。当出现这样的错误，JVM会告知用户出现错误，并终止程序。 Exception： 异常可分为编译阶段的CheckedException和程序正常运行过程中抛出的RuntimeException两大类。  CheckedException：继承自java.lang.Exception类，一般是外部错误，发生在编译阶段，Java编译期会强制程序去捕获此类异常（要求使用try{}catch{}finally{}显式的去包裹可能出现这类异常的代码段）。 RuntimeException：运行时异常，如空指针，数组索引越界等，还有CheckedException，出现这类异常一定是程序错误。      document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  classDiagram class Object class Throwable class Error class Exception class RuntimeException Object 异常处理  throw 主动从方法中抛出异常交给上层调用处理。 throws 声明函数可能出现的异常。      throw throws     使用位置 方法内部 方法声明后   功能 抛出具体的异常对象，执行到throw方法调用接收，返回异常给上层调用 声明可能出现的异常，让调用者知道该方法可能出现的异常   是否处理异常 不处理，抛出异常给上层调用 不处理，指明可能出现的异常    使用对比：\nthrow\nclass ThrowExample{ public void throwTest() { try{ ... throw new ArithmeticException(\u0026#34;Divided zero!\u0026#34;); } catch(ArithmeticException ex){ ex.printStackTrace(); } } }   throws\nclass ThrowsExample{ public void throwsTest() throws NumberFormatException, NullPointerException { // method body  ... } }    Reference:\nhttps://mermaid-js.github.io/mermaid/#/classDiagram\n"},{"id":10,"href":"/pbasic/dsalg/leetcode/","title":"Leetcode刷题记录","parent":"数据结构与算法","content":"1. 滑动窗口 解决有序数列连续和问题。限定窗口滑动方向，例如左右窗口只能向右滑动，区间设置为左闭右开。那么左窗口滑动缩小区间，右窗口滑动扩大窗口。\n"},{"id":11,"href":"/bigdata/spark/cache-checkpoint/","title":"Cache与Checkpoint","parent":"Spark","content":"  1. Cache机制  1.1 Cache策略 1.2 Cache细节   2. Checkpoint机制  2.1 Checkpoint细节   3. Cache与Checkpoint的异同   在Spark中需要Cache与Checkpoint机制的很重要原因是Spark的计算链(Computing chain | RDD Lineage)可能会很长，计算某些RDD也可能会花费很长的时间和消耗较多的资源，如果Task失败可能会导致整个计算链需要重新计算，因此采用Cache和Checkpoint机制可以保证访问重复数据可以很快的完成，同时也提高了容错性。\n1. Cache机制 1.1 Cache策略 在Spark中，RDD可以在第一次计算得到的时候根据用户设定的Storage Level将各个Partition缓存到内存或磁盘，当下一次需要使用到该RDD时可以直接使用而不需要重新计算。目前Spark支持将RDD缓存到内存和磁盘，在缓存的时候也可以选择先进行序列化后在缓存，常用缓存策略如下表：\n   Storage Level Meaning     MEMORY_ONLY 默认存储级别。将RDD存储在JVM堆（内存）中，如果内存不足，某些Partition可能不会被缓存，在需要时要重新计算   MEMORY_AND_DISK 将RDD存储在内存中，如果内存不足，剩余的部分存到磁盘中   MEMORY_ONLY_SER (Java and Scala) 以序列化的形式存储到内存中，不能存放的Partition在需要时对其进行重新计算   MEMORY_AND_DISK_SER (Java and Scala) 与MEMORY_ONLY_SER类似，但将不能存放到内存的Partition溢出到磁盘上   DISK_ONLY 只将RDD存放到磁盘   MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc 与对应的存储级别相似，不过集群中需要存储2份   OFF_HEAP (experimental) 与MEMORY_ONLY_SER类似，但是将数据存储在堆外存储器中，这需要启用堆外内存。    Spark 官方建议的采用的缓存策略：\n 尽量保持RDD的默认存储级别（MEMORY_ONLY），这是CPU效率最高的选项，允许RDD上的操作尽可能快地运行。 如果不是，可尝试使用MEMORY_ONLY_SER并选择一个快的序列化库，以使对象的空间效率更高，但访问速度仍然相当快，仅适用于Java和Scala API。 尽量不要将RDD缓存到磁盘，除非用于计算RDD非常消耗资源或者可以过滤掉大量数据。否则，重新计算分区的速度可能与从磁盘读取分区的速度一样快。 如果需要快速的故障恢复能力，使用复制的存储级别(XXX_2)。所有存储级别都通过重新计算丢失的数据来提供完全的容错能力，但是复制的存储级别具有冗余备份，一般情况下不需要等待重新计算丢失的分区。  1.2 Cache细节 通常情况下，被频繁地重复使用RDD需要进行Cache以提高效率。因为用户只能与Driver程序打交道，因此Cache一个RDD需要用户在编程的时候显式的调用rdd.cache() 或者rdd.persist(storagelevel)进行缓存。 用户只能cache程序代码中显式存在的rdd，对于那些Transformation中\u0026quot;隐式\u0026quot;生成的RDD，如ShuffledRDD，MapPartitionsRDD是不能被cache的。    缓存RDD Partition\nSpark Cache RDD发生在第一次计算RDD时，在将要计算RDD Partition时（而不是已经计算得到一个record时），就去判断Partition是否需要被Cache，如果需要Cache的话，就先将Partition计算出来，然后缓存到内存。\n  取cached RDD Partition\n下次计算(一般是同一application 的下一个 job 计算)时如果用到 cached RDD，task 会直接去 blockManager 的 memoryStore 中读取。具体地讲，当要计算某个 rdd 中的 partition 时候(通过调用 rdd.iterator())会先去 blockManager 里 面查找是否已经被 cache 了，如果 partition 被 cache 在本地，就直接使用 blockManager.getLocal() 去本地 memoryStore 里读取。如果该 partition 被其他节点上 blockManager cache 了，会通过 blockManager.getRemote() 去其他节点上读取，读 取过程如下图。\n  获取 cached partitions 的存储位置 partition 被 cache 后其所在节点上的 blockManager 会通知 driver 上的 blockMangerMasterActor 说某 rdd 的 partition 已经被我 cache 了，这个信息会存储在 blockMangerMasterActor 的 blockLocations: HashMap中。等到 task 执行需要 cached rdd 的时候，会调用 blockManagerMaster 的 getLocations(blockId) 去询问某 partition 的存储位置，这个询问信息会发到 driver 那里，driver 查询 blockLocations 获得位 置信息并将信息送回。\n  读取其他节点上的 cached partition task 得到 cached partition 的位置信息后，将 GetBlock(blockId) 的请求通过 connectionManager 发送到目标节点。目标节点收到请求后从本地 blockManager 那里的 memoryStore 读取 cached partition，最后发送回来。\n    2. Checkpoint机制 Spark中的Checkpoint机制是设计来对RDD进行持久化存储的（除非手动删除，否则它将永久存在于文件系统中，一般是缓存到HDFS中），因此可以跨Application使用，Cache机制中缓存到内存或磁盘中的RDD在application退出时就被清理掉了。  对于需要很长运算时间或运算量很大的rdd，computing chain过长或依赖其他rdd很多的rdd，可以选择对其进行Checkpoint。用户需要显式的调用rdd.checkpoint来对某个rdd设置检查点，sparkcontext.setCheckpointDir(dir)设置检查点目录。\n2.1 Checkpoint细节 不同于Cache 机制是每计算出一个要 cache 的 partition 就直接将其 cache 到内存中，Checkpoint 机制是等到 job 结束后另外启动专门的 job 来完成 checkpoint 。也就是说需要 checkpoint 的 RDD 会被计算两次。因此，在使用 rdd.checkpoint() 的时候，建议加上 rdd.cache()，这样第二次运行的 job 就不用再去计算该 rdd ，而是直接读取 cache 后写磁盘。\nRDD 需要经过 [ Initialized --\u0026gt; marked for checkpointing --\u0026gt; checkpointing in progress --\u0026gt; checkpointed ] 这几个阶段才能被 checkpoin。\n  Initialized 首先 driver program 需要使用 rdd.checkpoint() 去设定需要 checkpoint的rdd，检查点路径用sc.setCheckpointDir(dir)设置（一般设置HDFS目录），设定后该 rdd 就接受RDDCheckpointData 管理。\n  marked for checkpointing 初始化后RDDCheckpointData 会将管理的 rdd 标记为 MarkedForCheckpoint。\n  checkpointing in progress 每个 job 运行结束后Spark会调用 finalRdd.doCheckpoint()，finalRdd 会顺着 computing chain 回溯扫描，碰到要 checkpoint 的 RDD 就将其标记为 CheckpointingInProgress，然后将写磁盘(比如写 HDFS)需要的配置文件 (如 core-site.xml 等)broadcast 到其他 worker 节点上的 blockManager。完成以后，启动一个 job 来完成 checkpoint(使 用 rdd.context.runJob(rdd, CheckpointRDD.writeToFile(path.toString, broadcastedConf)))。\n  checkpointed job 完成 checkpoint 后，将该 rdd 的 dependency 全部清掉，并设定该 rdd 状态为 checkpointed。然后为该 rdd 强加一个依赖，设置该 rdd 的 parent rdd 为 CheckpointRDD，该 CheckpointRDD 负责以后读取在文件系统上的 checkpoint 文件，生成该 rdd 的 partition。\n  当调用 rdd.iterator() 去计算该 rdd 的 partition 的时候，会调用 computeOrReadCheckpoint(split: Partition) 去查看该 rdd 是 否被 checkpoint 过了，如果是，就调用该 rdd 的 parent rdd 的 iterator() 也就是 CheckpointRDD.iterator()，CheckpointRDD 负责读取文件系统上的文件，生成该 rdd 的 partition。\n3. Cache与Checkpoint的异同 Cache\n Cache机制中RDD Partition被缓存到内存或磁盘（或内存+磁盘），数据由blockManager管理。 Application退出后Cache在磁盘/内存中的RDD Partition会被清空。 Cache不会破坏RDD的Lineage，即RDD Partition丢失后可以根据计算链重新计算。 需要cache的 RDD 是在第一次计算得到时以Partition为单位进行缓存的。   Checkpoint\n Checkpoint机制中RDD Partition被持久化存储到文件系统（一般是HDFS）。 Application退出后Checkpoint的数据依旧存在，可以被其他应用使用。 Checkpoint会将RDD的依赖关系完全清除，并强加一个Parent RDD CheckpointRDD，需要时只能用CheckpointRDD从文件系统中读取数据，如果存储在文件系统上的数据被蓄意破坏，则需要重新启动该Application才能恢复计算。 Checkpoint发生在当前job结束后重新启动一个新的job来完成检查点的存储工作。    Reference：\n RDD Programming Guide Apache Spark 设计与实现  "},{"id":12,"href":"/pbasic/os/os-fs/","title":"文件管理","parent":"操作系统OS","content":"  1. 文件和文件系统  1.1 文件层次关系  1.1.1 数据项 1.1.2 记录 1.1.3 文件   1.2 文件类型 1.3 文件系统模型 1.4 文件操作   2. 文件的逻辑结构  2.1 记录式文件  2.1.1 顺序文件 2.1.2 索引文件 2.1.3 索引顺序文件   2.2 直接文件和哈希文件  2.2.1 直接文件 2.2.2 哈希文件     3. 外存分配方式  3.1 连续分配方式 3.2 链接分配 3.3 索引分配  3.3.1 单级索引分配 3.3.2 多级索引分配 3.3.3 混合索引分配     4. 目录管理  4.1 文件控制块和索引节点 4.2 文件目录结构  4.2.1 单级目录结构 4.2.2 两级目录 4.3.1 多级目录   4.3 目录查询技术  4.3.1 线性检索法 4.3.1 Hash检索法     5. 文件存储空间管理  5.1 空闲表法和空闲链表法 5.2 位示图法 5.3 成组链接法   6. 文件共享与文件保护  6.1 文件共享 6.2 文件保护  6.2.1 磁盘容错技术     7. 数据一致性控制  7.1 事务 7.2 检查点 7.3 并发控制   Reference   1. 文件和文件系统 文件系统的管理功能是通过将其所管理的程序和数据组织成一系列文件来实现的。\n1.1 文件层次关系 1.1.1 数据项 在文件系统中，数据项是最低级的数据组织形式，包括基本数据项和组合数据项。基本数据项是用于描述一个对象的某种属性的字符集，是数据组织中可以命名的最小逻辑数据单位，即原子数据，又称为数据元素或字段。组合数据项是有若干基本数据项组成的，简称组项。\n1.1.2 记录 记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。\n1.1.3 文件 文件是指由创建者所定义的、具有文件名的一组相关记录的集合，可分为有结构文件（若干相关记录组成的文件）和无结构文件（文件被看做字符流）。文件具有自己的属性：文件类型、文件长度、文件的物理位置、文件的创建时间等。\n1.2 文件类型  普通文件：由ASCII码或二进制码组成的字符文件。 目录文件：由文件目录组成，用来管理和实现文件系统功能的系统文件，通过目录文件可对其他文件的信息进行检索。 特殊文件：特指系统中的各类I/O设备，可分为块设备文件和字符设备文件。  1.3 文件系统模型 文件系统模型可分为三个层次：对象及其属性；对对象进行操纵和管理的软件集合；文件系统接口。\n对象及其属性\n文件管理系统管理的对象有：\n 文件：文件管理的直接对象 目录：方便对文件的存取和索引，每个目录项中必须含有文件名及该文件所在的物理地址（指针） 磁盘存储空间：文件和目录必定占用存储空间   对对象操纵和管理的软件集合\n文件系统的核心部分，主要功能包括：\n 文件存储空间的管理 文件目录的管理 文件逻辑地址和物理地址的转换机制 文件读写的管理 文件共享和保护   文件系统接口\n 命令接口 程序接口：系统调用   1.4 文件操作  创建文件：分配必要的外存空间，建立目录项 删除文件：从目录中查找对应的目录项并使之成为空项，回收该文件占用的存储空间 读文件 写文件 截断文件 设置文件读/写位置  2. 文件的逻辑结构 文件逻辑结构是用户视角的文件组织形式，它独立于文件的物理特性（存储方式）。文件逻辑结构可分为记录式文件（有结构文件）和流式文件（字符流）。\n2.1 记录式文件 2.1.1 顺序文件 由一系列记录按照某种顺序排列所形成的文件，其中的记录通常是定长记录。\n 文件记录可以按照写入时间排序（串结构），也可以按照关键字排序（顺序结构）。 对串结构文件查找每次必须从头开始 对顺序结构文件查找可以使用如折半查找、插值查找等算法 删除或增加记录需要移动其他记录  2.1.2 索引文件 当记录的长度可变时，通常建立一张索引表，并为每个记录设置一个表项。\n 顺序存取和直接实现方便 当记录较多时索引表需要较多额外存储资源  2.1.3 索引顺序文件 为文件建立一张索引表，为每组记录的第一个记录设置一个表项，组内组织为顺序结构，\n 组间索引，组内顺序  2.2 直接文件和哈希文件 2.2.1 直接文件 根据记录的键值对线性表或链表进行检索，已找到指定记录的物理地址，即记录键值本身觉得记录的物理地址。\n2.2.2 哈希文件 利用Hash函数将记录键值转换为相应记录的地址，通过目录表可实现文件存储空间的动态分配。\n3. 外存分配方式 3.1 连续分配方式 连续分配要求为每个文件分配一组相邻的盘块。一组盘块的地址定义了磁盘上的一段线性地址。\n 顺序访问容易、速度快 要求连续的存储空间，必须事先知道文件的长度，容易产生外部碎片  3.2 链接分配 通过每个盘块上的链接指针将同属于一个文件的多个离散盘块链接成一个链表，离散分配，消除外部碎片，提高外存利用率，增删改查方便。\n 隐式链接：每个盘块保护文件开始、文件结束盘块和下一个盘块的指针。 显式链接：将盘块指针显式的放在内存的一张链接表（文件分配表，FAT）中。 为提高效率，可以将连续的盘块组合为簇，以簇为分配单位。   FAT需要占用较大的内存空间 不能支持高效的直接存取  3.3 索引分配 3.3.1 单级索引分配 将每个文件对应的盘块号集中存放，为每个文件分配一个索引块（表），再把分配给该文件的所有盘块号都记录在索引块中。\n 支持直接访问 不会产生外部碎片 对小文件需要块索引利用率极低  3.3.2 多级索引分配 一级索引表 -\u0026gt; 二级索引表 -\u0026gt; 三级索引表 -\u0026gt; \u0026hellip; -\u0026gt; 盘块号\n3.3.3 混合索引分配 将多种索引分配方式相结合而形成的一种分配方式。\n 直接地址 一次间接地址 多次间接地址  4. 目录管理 对目录管理的基本要求：\n 按名存取 提高目录的检索速度 文件共享 运行文件重名  4.1 文件控制块和索引节点 文件控制块FCB：文件与文件控制块一一对应，一个文件控制块就是一个文件目录项。文件控制块的有序集合称为文件目录，通常一个文件目录可以被看做是一个文件，称为目录文件。\nFCB通常包含三类信息：基本信息、存取控制信息和使用信息。\n 基本信息：文件名，文件物理位置，文件逻辑结构（流式文件or记录式文件），文件物理结构（顺序文件、链接文件、索引文件） 存取控制信息：文件的存取权限（user, group, other） 使用信息：文件建立日期，修改日期，当前使用信息等。  索引节点（i节点）：将文件名和文件描述信息分开，使文件描述信息单独形成一个称为索引节点的数据结构。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i节点的指针所构成。\n 磁盘索引节点：存储在磁盘上的所有节点，主要包括文件标识符、文件类型、存取权限、物理地址等。 内存索引节点：存放于内存中的所有节点，当文件打开时将磁盘索引节点拷贝到内存中，增加索引节点编号，状态，访问计数，链接指针等信息。  4.2 文件目录结构 4.2.1 单级目录结构 整个文件系统仅建立一张目录表。缺点：查找速度慢、不允许重名、不便于文件共享。\n4.2.2 两级目录 系统建立一个主文件目录（MFD），并为每个用户单独建立一个用户文件目录(UFD)。两级目录提高了目录检索速度，不同的用户文件可以重名，可实现不同用户访问共享文件。\n4.3.1 多级目录 树形目录结构，主目录称为根目录，数据文件称为树叶，其他目录均作为树的节点。为提高文件系统的灵活性，允许一个目录文件中的目录项机作为目录文件的FCB，又是数据文件的FCB，增加一位指示位即可。\n 路径名：从根目录到当前访问的文件 当前目录：用户当前访问的目录  绝对路径：唯一，从根目录开始 相对路径：不唯一    4.3 目录查询技术 4.3.1 线性检索法 根据目录结构顺序检索。\n4.3.1 Hash检索法 建立文件目录的Hash表，先将文件名变换为文件目录的索引值，再利用该索引值到目录中查找。\n 可能存在冲突：不同文件名相同Hash值 不支持模式匹配功能  5. 文件存储空间管理 5.1 空闲表法和空闲链表法 空闲表法属于连续分配方式，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表，每个空闲区对于一个空闲表项。 外存存储空间分配的基本单位是磁盘块，而不是字节。  空闲链表法属于离散分配方式，将所有空闲盘区组成一条空闲链，可分为空闲盘块链表和空闲盘区链表。\n5.2 位示图法 位示图利用二进制位来表示磁盘中盘块的使用情况，0表示空闲，1表示已分配。\n5.3 成组链接法 将空闲盘块分组，取前面的组存储空闲的盘块组，类似于多级目录的形式。最后一组的最后一个盘块用于结尾标志。\n6. 文件共享与文件保护 6.1 文件共享  基于索引节点的文件共享 基于符号链接的文件共享  6.2 文件保护 影响文件安全性的主要因素：\n 人为因素：人有意或无意行为导致的数据破坏或丢失 系统因素：系统出现异常导致的数据破坏或丢失，如磁盘出现故障或损坏 自然因素：数据随时间发生溢出或逐渐消失  可采取的措施：\n 存取控制机制防止人为因素造成的文件不安全性 磁盘容错技术防止磁盘故障所造成的文件不安全性 后备系统防止自然因素导致的文件不安全性  6.2.1 磁盘容错技术  磁盘镜像 磁盘双工 基于集群的容错：双机热备份，公用磁盘  7. 数据一致性控制 7.1 事务 事务时用于访问和修改各种数据项的程序单位，可以看做是一系列相关读写操作。\n事务记录：\n 事务名 数据项名 旧值 新值  7.2 检查点 引入检查点，对事务记录表中的事务记录的清理工作周期化，每各一段时间进行事务记录清理。\n7.3 并发控制 Reference  《计算机操作系统》 汤小丹，第三版  "},{"id":13,"href":"/pbasic/cn/cn-tcp/","title":"TCP协议","parent":"计算机网络","content":"  1. TCP 数据包 2. TCP 三次握手 3. TCP 四次挥手 4. TCP 如何保证传输可靠  4.1 ARQ 协议 4.2 滑动窗口和流量控制 4.3 拥塞控制  4.3.1 慢开始 4.3.2 拥塞控制 4.3.3 快重传和快恢复       1. TCP 数据包 TCP数据包主要由报头和数据（可选）组成，其报头长度在20B-60B，具体结构如下图：\n2. TCP 三次握手 TCP连接需要进行三次握手的目的是建立可靠的通信通道，需要确认发送方和接收方的收发都是正常的。\n 第一次握手：client什么都不能确认；server确认自己接收正常，client发送正常 第二次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常，client发送正常 第三次握手：client确认自己接收正常和发送正常，server接收正常和发送正常；server确认自己接收正常和发送正常，client接收正常和发送正常  3. TCP 四次挥手 TCP断开连接需要进行四次挥手，原因在于TCP建立的连接是双向通道，双方之间既可以向对方发送数据也可以接收对方发送的数据，相当于是建立了两条单向通道，当一方发起断开连接的请求并受到对方的确认后会进入半关闭状态，需要等到另一方发送完数据并发出释放连接的请求，释放请求确认后才能完全关闭TCP连接。\n4. TCP 如何保证传输可靠  应用数据被分割成TCP认为最适合传输的数据块 TCP对发送的每一个数据包进行编号，接收方对收到的数据包进行排序，然后就有序的数据包交给应用层处理 校验和：TCP计算报头和数据的校验和，并将其放在报头中一起发送，接收方对收到的数据进行校验，如果校验出错则会丢弃这个数据包并不确认收到这个数据包 TCP接收端会丢弃重复的数据 流量控制：TCP使用大小可变的滑动窗口协议来进行流量控制，每一方都有固定大小的缓存空间，双方只接受缓存空间内容纳的数据。 拥塞控制机制：当网络拥塞时，减少数据发送 ARQ协议：每发送一个分组就停止发送，等待对方发送确认。收到确认后再发送下一个分组。 超时重传：TCP每个发送一个段就启动一个计时器，当超过时间未收到确认就重传该段。  4.1 ARQ 协议 自动重传请求通过确认和超时两个机制在不可靠服务的基础上实现可靠的信息传输。\n  停止等待ARQ协议\n 基本原理：每发送完一个分组就停止发送，等待收到对方的收到确认后再发送下一个分组，超时未收到确认则重新发送此分组 接收方收到重复的分组直接丢弃并发送收到确认 确认丢失：确认信息在传输过程中丢失，发送方重发分组，接收方丢弃分组并发送确认 确认迟到：确认信息在传输过程中迟到，发送方重发分组，接收方丢弃分组并发送确认，发送方丢弃重复的确认信息    连续ARQ协议\n 发送窗口：发送发维持一个发送窗口，发送窗口内的分组都可以发送而不必等待对方的确认消息 累积确认：接收方对按序到达的最后一个分组发送确认，表明到这个分组为止所有分组都已正确收到 回退N：不能向发送方反映接收方已收到的所有分组信息，若丢失则需要重新发送丢失的分组    4.2 滑动窗口和流量控制 TCP利用滑动窗口来实现流量控制。流量控制是为了控制发送方的发送速率，保证接收方来得及接收。TCP报头的窗口字段可以用来控制发送方的窗口大小，设置为0则发送方不能发送数据。\n4.3 拥塞控制 拥塞控制是为了防止过多的数据注入到网络中，使得网络中的路由器或链路过载。拥塞控制是一个全局的过程，涉及网络中的所有主机，路由器，以及其他与降低网络传输有关的因素。\n流量控制是对点到点通信量的控制，解决的是端到端的问题，即抑制发送方的发送速率使得接收方来得及处理收到的数据。  为了进行拥塞控制，TCP 发送方要维护一个拥塞窗口(cwnd)的状态变量，拥塞窗口的大小取决于网络的拥塞程度，是动态变化的。发送方让自己的发送窗口为拥塞窗口和接收方的接收窗口中较小的一个， 即 发送窗口 = min(拥塞窗口，接收方接收窗口)。\nTCP 拥塞控制采用了以下四种算法，慢开始、拥塞避免、快重传和快恢复。\n4.3.1 慢开始 从小到大逐渐增大拥塞窗口，每经过一个传播轮次，cwnd加倍，cwnd = cwnd * 2。\n4.3.2 拥塞控制 让拥塞窗口逐渐增大，每经过一个往返时间RTT就将拥塞窗口加1，cwnd = cwnd + 1。\n4.3.3 快重传和快恢复 快重传和恢复（FRR）能迅速恢复丢失的数据包。一般情况下，如果数据包丢失了，TCP会启用计时器来要求传输暂停，暂停期间没有新的或复制的数据发送。\n有了快重传和快恢复，接收方在收到一个不按顺序的数据段，它会立刻给发送方发送一个重复确认，如果发送方连续收到3个重复确认，它会假定重复确认指出的数据段丢失了，并立即重传这些丢失的数据段。\n只有单独的数据包丢失时，快速重传和恢复能最有效地工作；当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。\n"},{"id":14,"href":"/pbasic/cn/cn-tcpudp/","title":"TCP与UDP协议的区别","parent":"计算机网络","content":"1. TCP TCP提供面向连接的稳定可靠的服务。在数据传输之前需要先建立连接(三次握手)，数据传输结束后需要释放连接(四次挥手)，TCP不提供广播或多播服务。TCP的可靠体现在数据传输之前需要三次握手建立连接，在数据传输时有确认、窗口、重传、拥塞控制机制、在数据传输接收后经历四次挥手断开连接，释放资源。当难免增加开销，如确认、流量控制、计时器和连接管理等。TCP一般用于文件传输、收发邮件和远程登录等。\n2. UDP UDP提供非连接的不可靠服务。UDP在传输数据之前不需要建立连接，远程主机在收到UDP报文后也不需要给出任何确认。虽然UDP不提供可靠交付，但是其在一些场景中是最有效的工作方式，一般用于及时通信，如QQ语音、QQ视频、直播等。\n对比 "},{"id":15,"href":"/tags/Architecture/","title":"Architecture","parent":"Tags","content":""},{"id":16,"href":"/categories/","title":"Categories","parent":"Lin","content":""},{"id":17,"href":"/categories/CN/","title":"CN","parent":"Categories","content":""},{"id":18,"href":"/pbasic/cn/cn-arch/","title":"OSI与TCP/IP架构","parent":"计算机网络","content":"  1. OSI网络7层模型 2. TCP/IP 4层模型 3. 5层模型   1. OSI网络7层模型 OSI计算机网络体系分为7层，从下往上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层，每一层都定义了相互通信的协议。每个层只会处理与其相邻的上下层（如果有的话）的信息，包括从上往下封装需要发送的信息以及从下往上解封装收到的信息并交给上层处理。\n  物理层\n 主要定义物理设备标准，如网线的接口类型，光纤的接口类型。主要作用是传输比特率（数模转换/模数转换），这一层的数据称为比特。 工作设备是网线、集线器等。\n   数据链路层\n 对从网络层和物理层接收的数据进行MAC地址的封装与解封装。这一层的数据称为帧，工作设备是网桥、交换机等。\n   网络层\n 主要对数据进行IP地址的封装与解封装。这一层的数据称为报文（数据包），工作设备是路由器。\n   传输层\n 定义数据传输协议和端口，对数据进行分段传输和到达重组（目的地进行）。这一层的数据称为段。\n   会话层\n 通过传输层（端口号）建立数据传输通道。在计算机系统之间发起或接受会话请求。\n   表示层\n 主要对数据进行解释、加密与解密、压缩与解压缩等，把数据转换成人所能理解的，如图像、声音等。\n   应用层\n 主要是一些终端应用。如FTP、WEB等。\n   网络模型与物理设备\n实际上，OSI网络模型可以看做是从软件层面定义网络架构，而这是建立在各种物理设备之上的，如光纤、双绞线、集线器、交换机、网桥、路由器等。所谓的物理层和物理设备并不是一个层面上的概念。  2. TCP/IP 4层模型 TCP/IP协议不是TCP和IP这两个协议的总称，而是指因特网整个互联网协议。从下往上包括网络结构层、网络层、传输层和应用层。\n  网络接口层\n 指出主机必须通过某种协议与网络相连。\n   网络层\n 整个体系的关键部分，其功能是使主机可以把分组发往任何网络，并使分组独立的传向目标。这些分组可能经过不同的网络，到达顺序与发送顺序也可能不同。\n   传输层\n 使源端和目的端的机器上的对等实体可以进行会话。这一层定义了两个端到端的传输协议TCP和UDP。\n   应用层\n 包含所有上层协议，如SMTP, FTP, DNS, NNTP, HTTP, TELNET等。\n   3. 5层模型 5层模型中和OSI 7层模型和TCP/IP 4层模型的优点，既简洁又能将概念阐述清楚。\n"},{"id":19,"href":"/tags/","title":"Tags","parent":"Lin","content":""},{"id":20,"href":"/papers/mermaidtest/","title":"Mermaidtest","parent":"Paper Review","content":"Test Mermaid Pie   document.addEventListener(\"DOMContentLoaded\", function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?}; B --|Yes| C[OK]; C -- D[Rethink]; D -- B; B ----|No| E[End];  "},{"id":21,"href":"/papers/TPDS/","title":"TPDS","parent":"Paper Review","content":"背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。\n目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。\n方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：\n 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值\n2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。\n3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。\n4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。\n评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器\nLeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9\n"},{"id":22,"href":"/bigdata/hadoop/overview/","title":"Overview","parent":"Hadoop","content":"1. Hadoop 大规模分布式计算框架，支持扩展到数千台服务器，每台服务器都提供本地存储和计算，自带应用层故障检测和故障处理。\n 高可靠性 高扩展性 高效性 高容错性 低成本  Hadoop的适用场景\n 特别适合写一次，读多次的场景\n大规模数据 流数据（写一次，读多次）\n商用硬件\n Hadoop不适用的场景\n 低延时数据访问 大量小文件 频繁修改文件\n  Hadoop的3大核心  HDFS MapReduce YARN   Hadoop的4大模块  Hadoop Common：支持其他Hadoop模块的公共使用程序 Hadoop HDFS：提供对应用程序数据高吞吐访问的分布式文件系统 Hadoop MapReduce：基于yarn的大型数据集并行处理系统 Hadoop yarn：作业调度和集群资源调度框架    2. HDFS Master/Slave架构，核心架构目标：错误检测和快速、自动的恢复（硬件错误是常态不是异常）。\n简单的一致性模型：文件经创建、写入和关闭后就不需要改变（一次写、多次读），简化了数据一致性问题。\nHDFS中的文件都是一次性写入的，并且严格要求任何时候只能有一个写入者。\n进程：NameNode, SecondaryNameNode, DataNode\n数据块副本存放策略（机架感知）：大多数情况下副本系数为3，HDFS的存放策略将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。\n读取策略：尽量读取距离最近的副本。\n安全模式：处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的；在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。接下来它会确定还有哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他Datanode上。\nHDFS不允许在同一个DataNode上存放多个相同的Block，因此副本可设置的最大数量为DataNode的数量。 当副本数大于3，则之后的副本随机选取存放的机架，每个机架可存放的副本上限为(replicas-1)/racks + 2\n通信协议：HDFS的通信协议都是建立在TCP/IP协议之上，client与NameNode之间使用ClientProtocol，DataNode与NameNode之间使用DatanodeProtocal。\n健壮性\n 磁盘数据错误，心跳检测和重新复制：当DataNode宕机或者副本遭到破坏，副本系数增加等，经NameNode不断检测判断后启动重新复制。\n集群均衡：自动将数据移动到其它空闲的DataNode上；当某些文件请求增加，可启动计划重新创建新的副本并平衡集群数据。 数据完整性：计算数据块检验和，并将检验和以隐藏文件的形式存储到同一个HDFS命名空间下，客户端获取和进行检验，如果不对则读取其它副本。 元数据磁盘错误：支持维护多个fsimage 和Editlog，修改同步到副本上。\n NameNode 管理整个HDFS集群的元数据：文件目录树，权限设置，副本数，BlockID，客户端对文件系统的访问等\nEditlog 文件存储在磁盘中，顺序追加记录 NameNode每次重启时将Editlog里的操作日志读到内存中回放即可恢复元数据。\nfsimage磁盘文件 JournalNodes集群 主节点（Active NameNode）每次修改元数据都会生成一条Editlog，该log既写入磁盘文件也写入JournalNodes集群， 然后SecondaryNameNode从JournalNodes集群拉取Editlog并应用到自己的文件目录树中，跟主节点保持一致， 每隔一段时间dfs.namenode.checkpoint.period SecondaryNameNode将完整的元数据写入到磁盘文件fsimage，即checkpoint操作， 然后将fsimage上传到主节点，并清空Editlog，如果此时主节点重启，则只需将fsimage读入内存即可恢复元数据， 然后再将新的Editlog里的少量修改放回内存中即可。 BlockSize: 64/128MB, numReplicas: 3\n流水线复制 当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。\n文件存储空间回收 文件删除和恢复：当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，HDFS会将这个文件重命名转移到.Trash目录，保存时间可配置。\n减少副本系数：当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。\nNameNode高并发  NameNode写入Editlog的第一条原则：保证每一条log都有一个全局顺序递增的transactionid，标识其先后顺序。 写入Editlog包含两步：1. 写入本地磁盘。 2. 通过网络传输给JournalNodes集群。 分段加锁机制和Double-Buffer机制 设置两个内存缓冲区：一个缓冲区用于写入Editlog，另一个缓冲区用于读取后写入磁盘和JournalNodes集群，必要时交换两个缓冲区。 多线程并发吞吐量优化 缓冲数据批量输入磁盘+网络优化  DataNode 定期向NameNode发送心跳信号和块状态报告。\n 心跳信号：DataNode节点正常工作 块状态报告：包含该DataNode上所有数据块的列表  3. MapReduce 一种编程模型，用于大规模数据执行可靠容错的并行计算。\nMapReduce作业通常将输入数据集分割成独立的块，这些块由map任务以完全并行的方式进行处理。框架对映射的输出进行排序，然后将其输入到reduce任务中。通常，作业的输入和输出都存储在文件系统中，该框架负责调度任务、监视任务并重新执行失败的任务。 通常，计算节点和存储节点是相同的，MapReduce框架和Hadoop分布式文件系统在同一组节点上运行，这种配置允许框架在数据已经存在的节点上有效地调度任务，从而产生跨集群的非常高的聚合带宽。 MapReduce框架由单个主资源管理器、每个集群节点一个工作节点管理器和每个应用程序的MRAppMaster组成。\n(input) \u0026lt;k1, v1\u0026gt; -\u0026gt; map -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; combine -\u0026gt; \u0026lt;k2, v2\u0026gt; -\u0026gt; reduce -\u0026gt; \u0026lt;k3, v3\u0026gt; (output)\nMapReduce的主要构件\n Input： 分布式计算程序的数据输入源 Job：用户的每一个计算请求为一个Job Task：有JOb拆分而来的执行单位，分为Map Task和Reduce Task Map：指定一个映射函数，将一组键值对映射成一组新的键值对 Reduce：指定一个归约函数，用来保证所有映射的键值对中的每一个共享相同的键组 Output：计算之后的结果。  4. YARN 基本思想：将集群资源管理和作业调度/监控划分为单独的进程。 ResourceManager（RM）：全局资源管理 NodeManager（NM）：每台机器上的框架代理，负责监控容器及资源使用情况（CPU、内存、磁盘、网络）并像RM汇报。 ApplicationMaster（AM）：每个应用一个，与RM协商资源，与NM一起执行和监视任务。\n"},{"id":23,"href":"/database/dbsql/","title":"数据库与SQL","parent":"数据库","content":"1 基本概念 数据库DB：可以用计算机进行高效访问的，可以进行加工和处理的有组织的数据集合；\n数据库管理系统DBMS：用来管理数据库的计算机软件；\nSQL：Structured Query Language 即结构化查询语言;\n使用数据库管理系统的好处：共享数据、海量数据管理、容错、故障恢复、自动化。\nDBMS   层次数据库HDB： 数据以层次结构（树形结构）进行组织； 关系数据库RDB： 二维表形式组织数据； 面向对象数据库OODB： 把数据及对数据的操作集合起来以对象为单位进行管理； XML数据库 XMLDB： 以XML形式进行数据组织和高速处理； 键值存储系统KVS： 使用主键（Key）和值（Value）的组合的数据库。   RDBMS表结构 列（字段）：数据项目 行（记录）：数据 关系数据库必须以行为单位进行数据读写。\nSQL  SQL可分为DDL、DML和DCL。\n DDL：数据定义语言。用来创建或删除存储数据用的数据库以及数据库中的表等对象。包含CREATE, DROP, ALTER 等指令； DML：数据操纵语言。查询或变更表中的记录。包含SELECT, INSERT, UPDATE, DELETE 等指令； DCL：数据控制语言。用来却或取消对数据库中的数据进行的变更和对RDBMS的用户权限管理。包含COMMIT, ROLLBACK, GRANT, REVOKE 等指令。   SQL的基本语法规则  SQL语句以分号; 结尾； SQL语句不区分关键字大小写：习惯上关键字将大写； SQL中常数（字符串、日期、数字等）书写方式是固定的； 单词需要用半角空格或者换行来分隔。  "},{"id":24,"href":"/plang/scala/mvn-repo/","title":"Mvn Repo Modify","parent":"Scala","content":"可以直接修改${M2_HOME}/conf/settings.xml,也可以复制到${HOME}/.m2/,然后修改setting.xml文件.\n${M2_HOME}/conf/setting.xml # 全局配置 ${user.home}/.m2/setting.xml # 用户配置 # 两个配置文件允许同时存在,同时存在时内容会被合并-用户配置优先 本地默认仓库 在setting.xml中找到localRepository选项,然后修改路径即可.\n\u0026lt;!-- path to the local repository default ${user.home}/.m2/repository --\u0026gt; \u0026lt;localRepository\u0026gt;/path/to/local/repo\u0026lt;/localRepository\u0026gt; 远程仓库 修改远程仓库地址需要在mirrors中的mirror选项中进行配置.\n\u0026lt;!-- \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;mirrorId\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;repositoryId\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Human readable name for this mirror\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://my.repository.com/repo/path\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;mirror\u0026gt; .... \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; --\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; "},{"id":25,"href":"/bigdata/","title":"BigData","parent":"Lin","content":" Get Home   Contribute   "},{"id":26,"href":"/bigdata/hadoop/","title":"Hadoop","parent":"BigData","content":""},{"id":27,"href":"/plang/java/","title":"Java","parent":"编程语言","content":""},{"id":28,"href":"/plang/java/basic/","title":"Java 基础","parent":"Java","content":""},{"id":29,"href":"/","title":"Lin","parent":"","content":"Motivation 转眼间就要研究生毕业了（虽然我是2022届），看着21届的伙伴们都拿到了Offer，我这想要实习的心也躁动起来啦！在写简历、准备面试的过程中，我发现之前学习的好多知识都不知道跑到记忆的哪个角落里去了，看什么都似曾相识却又陌生遥远。为了笔试/面试顺利，可以拿到一个好的Offer，现在得开始复习（学习）了，特此以Doc的形式记录下自己的学习过程。\nOutlines  编程基础  操作系统OS 计算机网络 数据结构和算法   BigData  Spark Hadoop   编程语言  Python Scala Java   机器学习ML 数据库  MySQL Redis    "},{"id":30,"href":"/ml/","title":"Machine Learning","parent":"Lin","content":" Get Home   Contribute   "},{"id":31,"href":"/database/mysql/","title":"MySQL","parent":"数据库","content":""},{"id":32,"href":"/papers/","title":"Paper Review","parent":"Lin","content":" Get Home   Contribute   "},{"id":33,"href":"/plang/python/","title":"Python","parent":"编程语言","content":""},{"id":34,"href":"/database/redis/","title":"Redis","parent":"数据库","content":""},{"id":35,"href":"/plang/scala/","title":"Scala","parent":"编程语言","content":""},{"id":36,"href":"/bigdata/spark/","title":"Spark","parent":"BigData","content":""},{"id":37,"href":"/pbasic/os/","title":"操作系统OS","parent":"编程基础","content":""},{"id":38,"href":"/database/","title":"数据库","parent":"Lin","content":" Get Home   Contribute   "},{"id":39,"href":"/pbasic/dsalg/","title":"数据结构与算法","parent":"编程基础","content":""},{"id":40,"href":"/pbasic/","title":"编程基础","parent":"Lin","content":" Get Home   Contribute   "},{"id":41,"href":"/plang/","title":"编程语言","parent":"Lin","content":" Get Home   Contribute   "},{"id":42,"href":"/pbasic/cn/","title":"计算机网络","parent":"编程基础","content":" Get Home   Contribute   "}]