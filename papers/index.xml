<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper Review on Lin&#39;s Doc Site</title>
    <link>https://slinviz.github.io/papers/</link>
    <description>Recent content in Paper Review on Lin&#39;s Doc Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://slinviz.github.io/papers/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TC</title>
      <link>https://slinviz.github.io/papers/TC/</link>
      <pubDate>Sun, 07 Mar 2021 19:47:54 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TC/</guid>
      <description>模型压缩 紧凑的模型结构  用小卷积核1x1替代大的卷积核，如3x3。可以现在减少模型参数。 Filters prunning。删除不重要的或者冗余的卷积核。  粗细粒度聚合数据点 粗粒度-》n细粒度-》n*m原始训练数据</description>
    </item>
    
    <item>
      <title>TKDE</title>
      <link>https://slinviz.github.io/papers/TKDE/</link>
      <pubDate>Sun, 07 Mar 2021 19:47:48 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TKDE/</guid>
      <description>背景 迭代机器学习算法通常需要海量的训练数据对模型进行多次迭代训练，最终才可能获得可以接受的模型。 显然，随着模型的逐步训练，训练集中只有越来越少的样本对模型参数更新产生影响，直接体现就是loss越来越小， 或者说小批量随机梯度下降算法中用于模型参数更新的梯度值越来越小，最后趋近于0。 也就是说此时训练集中很大一部分训练样本对模型参数更新的影响已经很小，甚至于没有影响。因此在迭代训练中 依然对其进行forward-backward操作其实是在浪费计算资源，如果有合适的方法将这部分数据样本移除，那么就 可以显著减少计算负载，减少模型训练的时间。
核心思想 删除对模型参数更新影响小的训练样本，选择对模型更新影响较大的部分训练数据进行模型训练，即减少每轮迭代的训练数据。
关键问题  如何度量某个训练样本对模型更新的影响？ 如何高效的识别和删除对模型参数更新影响小的数据样本？  解决方法   如何度量某个训练样本对模型更新的影响？   解决方案：将相似的训练样本聚集到一起，生成单个特别的样本（聚合数据点），用这个生成的样本对模型参数更新的影响来近似代表着些相似的 训练样本对模型参数更新的影响。比如10000个训练样本，之前对每个样本分别计算其影响值，现在将100个相似的样本放在一起，生成 100个聚合数据点，这样就只用算着100个聚合点的影响值就可以了。
注意：生成的聚合数据点只用于近似计算影响值，而不会参与到实际的模型训练过程中。 还有就是对聚合数据点的生成和使用应该尽可能的快，防止增加额外的开销。
图像分类中，将图像的像素展开成一个向量，然后使用Incremental SVD进行降维，降维后使用 LSH，局部敏感哈希进行划分， 最后对划分在同一组中的特征求均值，得到均值向量作为聚合数据点的特征向量。
在Spark平台下，可以将具有相同的标签的数据划分为一个RDD的Partition，然后并行的对每个Partition计算聚合数据点，最后在进行合并。
 如何高效的识别和删除对模型参数更新影响小的数据样本？   关键：影响值的计算，可以选用loss也可以选用梯度的绝对值之和。 然而计算梯度的开销较大，而且最后的结果跟用loss计算的结果相差不大。
阈值：判断冗余数据的阈值：1. 设定百分比，比如50% 则删除50%的数据。 2. 将影响值从小到大排序，将累计和小于总和的1%的前x个样本作为 冗余数据删除。
在BigDL中，每个Executor复杂处理一个Partition的训练样本，而根据每个Executor分配的CPU核数用多线程进行计算。 存在的问题是某些线程可能会删除更多的数据，因此最后需要将各个线程筛选过后的样本聚合后重新平均地划分到各个线程中， 以减少出现计算快的线程需要等待慢的线程很久。
核心集：构建比原数据集更小的数据集来近似代表原数据集 重要性采样：根据梯度值对训练样本进行重要性采样 </description>
    </item>
    
    <item>
      <title>Mermaidtest</title>
      <link>https://slinviz.github.io/papers/mermaidtest/</link>
      <pubDate>Fri, 26 Feb 2021 22:50:38 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/mermaidtest/</guid>
      <description>Test Mermaid Pie   document.addEventListener(&#34;DOMContentLoaded&#34;, function(event) { mermaid.initialize({ flowchart: { useMaxWidth: true } }); });  pie title Pets adopted by volunteers &#34;Dogs&#34; : 386 &#34;Cats&#34; : 85 &#34;Rats&#34; : 15  Journel sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end  Graph graph TD A[Start] -- B{Is it?</description>
    </item>
    
    <item>
      <title>TPDS</title>
      <link>https://slinviz.github.io/papers/TPDS/</link>
      <pubDate>Fri, 26 Feb 2021 19:42:14 +0800</pubDate>
      
      <guid>https://slinviz.github.io/papers/TPDS/</guid>
      <description>背景 边缘异构环境下，由于设备异构（如硬件、软件栈等）导致基于Gossip的深度学习模型训练收敛速度慢和额外延迟。
目的 提出新的方法，旨在加速边缘异构环境下基于Gossip的深度学习模型训练。
方法 核心思想：让慢的节点跟上快的节点，根据每个边缘计算节点的性能，动态调整该节点需要处理（训练）的数据，即计算能力较差的节点只需要处理对模型参数更新影响大的那一小部分数据，使得整个系统中各节点训练步调基本一致，减少模型训练的时间。 关键：
 如何识别和删除训练过程中对模型参数更新影响较小那部分数据？ 随着模型的训练，冗余的数据比例增大，且冗余数据随模型训练会有所迁移，如何解决？  1. 聚合数据点的应用 根据训练数据间的相似性，将高度相似的数据聚合在一起，使用它们的平均来近似表示这部分高度相似的数据。 对每个节点上的数据单独生成压缩点，并且只在训练开始之前生成一次。 为了减少生成聚合数据点的开销，先对原始数据进行降维，然后根据降维后的数据的相似性进行划分，最后根据划分结果生成聚合数据点。 降维：SVD，Incremental SVD， Hash 划分：LSH，K-Means 聚合：均值
2. 节点性能评估模块 负责评估当前节点的性能。具体地，采集当前节点完成一个迭代所需要的时间，并像Gossip训练平衡模块报告结果。
3. Gossip训练平衡模块 根据各个节点性能评估模块报告的信息，以运行最快的节点为基础，计算其它个节点需要删除的冗余数据的比例并反馈给各节点。
4. 精度感知的训练模块 评估指标：当前模型在聚合数据点的损失值 聚合数据点的损失值以批量的形式计算。 使用聚合数据点评估训练数据对当前模型参数更新的影响，排序后删除影响较小的部分训练数据，比例由Gossip训练平衡模块确定。
Redis 通信优化 所有节点均与Redis通信，为每个节点建立一个与之关联的键，用于存储该节点本次迭代的梯度。 在一个sorted set存储每个节点的时间开销&amp;lt;node, timecost&amp;gt; ， 每个节点拉去花费时间最少的节点机器时间开销， 然后根据自己的时间开销计算需要删除的数据的比例。 zrange key 0 1 withscores
评估 1CPU（Intel E5-2695） + 2GPU（12GB TiTAN Xp, 11G GeForce RTX 2080Ti） 服务器
LeNet AlexNet SqueezeNet MobileNet-v2 MNIST CIFAR10 lr=0.01 bs=64 momentum=0.9</description>
    </item>
    
  </channel>
</rss>